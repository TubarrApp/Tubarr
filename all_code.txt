package cfg

import (
	keys "tubarr/internal/domain/keys"

	"github.com/spf13/viper"
)

// initFilesDirs initializes files and directories into Viper
func initFilesDirs() {
	// Video directory
	rootCmd.PersistentFlags().StringP(keys.VideoDir, "v", ".", "Video directory")
	viper.BindPFlag(keys.VideoDir, rootCmd.PersistentFlags().Lookup(keys.VideoDir))

	// Metadata directory
	rootCmd.PersistentFlags().StringP(keys.MetaDir, "m", ".", "Metadata directory location (NOT CURRENTLY IMPLEMENTED)")
	viper.BindPFlag(keys.MetaDir, rootCmd.PersistentFlags().Lookup(keys.MetaDir))

	// Channels to check
	rootCmd.PersistentFlags().StringP(keys.ChannelFile, "c", "", "File of channels to check for new videos")
	viper.BindPFlag(keys.ChannelFile, rootCmd.PersistentFlags().Lookup(keys.ChannelFile))

	// Metarr preset file
	rootCmd.PersistentFlags().String(keys.MetarrPreset, "", "Metarr preset file location")
	viper.BindPFlag(keys.MetarrPreset, rootCmd.PersistentFlags().Lookup(keys.MetarrPreset))

	// Output filetype
	rootCmd.PersistentFlags().StringP(keys.MoveOnComplete, "o", "", "Location to move file to upon completion")
	viper.BindPFlag(keys.MoveOnComplete, rootCmd.PersistentFlags().Lookup(keys.MoveOnComplete))

	// Filetype to output
	rootCmd.PersistentFlags().String(keys.OutputFiletype, "", "Filetype to output as")
	viper.BindPFlag(keys.OutputFiletype, rootCmd.PersistentFlags().Lookup(keys.OutputFiletype))
}

// initDownloaderSettings initializes downloader settings
func initDownloaderSettings() {
	// Cookie source
	rootCmd.PersistentFlags().String(keys.CookieSource, "", "Browser to grab cookies from for sites requiring authentication (e.g. firefox)")
	viper.BindPFlag(keys.CookieSource, rootCmd.PersistentFlags().Lookup(keys.CookieSource))

	rootCmd.PersistentFlags().String(keys.CookiePath, "", "Specify a custom cookie file to use")
	viper.BindPFlag(keys.CookiePath, rootCmd.PersistentFlags().Lookup(keys.CookiePath))

	// External downloader (e.g. aria2c)
	rootCmd.PersistentFlags().String(keys.ExternalDownloader, "", "External downloader to use for yt-dlp (e.g. aria2c)")
	viper.BindPFlag(keys.ExternalDownloader, rootCmd.PersistentFlags().Lookup(keys.ExternalDownloader))

	rootCmd.PersistentFlags().String(keys.ExternalDownloaderArgs, "", "Arguments for external downloader (e.g. \"-x 16 -s 16\")")
	viper.BindPFlag(keys.ExternalDownloader, rootCmd.PersistentFlags().Lookup(keys.ExternalDownloader))
}

func initDLSettings() {
	// Filtering
	rootCmd.PersistentFlags().String(keys.FilterOpsInput, "", "Ignore releases if fields contain _ (e.g. 'title:frogs' ignores videos with frogs detected in the title)")
	viper.BindPFlag(keys.FilterOpsInput, rootCmd.PersistentFlags().Lookup(keys.FilterOpsInput))
}

// initProgramSettings initializes program settings into Viper
func initProgramSettings() {
	// Debugging
	rootCmd.PersistentFlags().IntP(keys.DebugLevel, "d", 0, "Set the logging level")
	viper.BindPFlag(keys.DebugLevel, rootCmd.PersistentFlags().Lookup(keys.DebugLevel))
}
package cfg

import (
	"strings"

	"golang.org/x/text/cases"
	"golang.org/x/text/language"
)

// AutoPreset is the entrypoint for command presets
func AutoPreset(url string) []string {
	args := make([]string, 0)
	switch {
	case strings.Contains(url, "censored.tv"):
		return censoredTvPreset(args, url)
	default:
		return defaultArgs(args)
	}
}

// censoredTvPreset sets common presets for censored.tv links
func censoredTvPreset(args []string, url string) []string {

	// Titles come appended with " (1)"
	// Ids come appended with "-1"
	// Filenames come appended with "_1"

	splitUrl := strings.Split(url, "/")
	creator := ""

	for i, entry := range splitUrl {
		if !strings.HasSuffix(entry, ".com") {
			continue
		}
		if len(splitUrl) >= i+1 {
			creator = strings.ReplaceAll(splitUrl[i+1], "-", " ")
		}
	}

	if creator != "" { // Should ensure the segment directly after .com/ was grabbed

		titleCase := cases.Title(language.English)
		creator = titleCase.String(creator)

		switch strings.ToLower(creator) {
		case "atheism is unstoppable": // Special case for Atheism-is-Unstoppable
			creator = "Atheism-is-Unstoppable"
		}

		args = append(args, "--meta-ops",
			"author:"+"set:"+creator,
			"actor:"+"set:"+creator,
			"publisher:"+"set:"+creator,
			"uploader:"+"set:"+creator,
			"channel:"+"set:"+creator)

		args = append(args, "--meta-overwrite")
	}

	args = append(args, "--meta-ops", "title:trim-suffix: (1)", "fulltitle:trim-suffix: (1)", "id:trim-suffix:-1", "display_id:trim-suffix:-1")
	args = append(args, "--filename-replace-suffix", "_1:")

	return args
}

// defaultArgs provides default Metarr arguments
func defaultArgs(args []string) []string {

	// Currently returns no arguments

	return args
}
package cfg

import (
	"fmt"
	"os"
	"strings"
	consts "tubarr/internal/domain/constants"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"

	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

var rootCmd = &cobra.Command{
	Use:   "tubarr",
	Short: "Tubarr is a video and metatagging tool",
	RunE: func(cmd *cobra.Command, args []string) error {
		if cmd.Flags().Lookup("help").Changed {
			return nil // Stop further execution if help is invoked
		}
		viper.Set("execute", true)
		return execute()
	},
}

// init sets the initial Viper settings
func init() {

	// Files and directories
	initFilesDirs()

	// Download settings
	initDownloaderSettings()

	// Settings for actual downloads (e.g. filtering out videos from downloading)
	initDLSettings()

	// Program settings like debug level etc.
	initProgramSettings()

}

// Execute is the primary initializer of Viper
func Execute() error {

	fmt.Println()

	err := rootCmd.Execute()
	if err != nil {
		logging.E(0, "Failed to execute cobra")
		return err

	}
	return nil
}

// execute more thoroughly handles settings created in the Viper init
func execute() error {
	if viper.IsSet(keys.MetarrPreset) {
		if metarrPreset := viper.GetString(keys.MetarrPreset); metarrPreset != "" {

			if info, err := os.Stat(metarrPreset); err != nil {
				return fmt.Errorf("metarr preset does not exist")
			} else {
				if info.IsDir() {
					return fmt.Errorf("metarr preset must be a file")
				}
			}
		}
	}

	if err := verifyAndReadChannelFile(); err != nil {
		return err
	}

	if err := verifyCookieSource(); err != nil {
		return err
	}

	verifyOutputFiletype()

	verifyLogLevel()

	if err := verifyFilterOps(); err != nil {
		return err
	}

	return nil
}

// verifyCookieSource verifies the cookie source is valid for yt-dlp
func verifyCookieSource() error {
	if IsSet(keys.CookieSource) {
		cookieSource := GetString(keys.CookieSource)

		switch cookieSource {
		case "brave", "chrome", "edge", "firefox", "opera", "safari", "vivaldi", "whale":
			logging.I("Using %s for cookies", cookieSource)
		default:
			return fmt.Errorf("invalid cookie source set. yt-dlp supports firefox, chrome, vivaldi, opera, edge, and brave")
		}
	}
	return nil
}

// verifyChannelFile verifies the channel file is valid
func verifyAndReadChannelFile() error {
	if viper.IsSet(keys.ChannelFile) {
		channelFile := GetString(keys.ChannelFile)

		cFile, err := os.OpenFile(channelFile, os.O_RDWR, 0644)
		if err != nil {
			return fmt.Errorf("failed to open file '%s'", channelFile)
		}
		defer cFile.Close()

		content, err := os.ReadFile(channelFile)
		if err != nil {
			logging.E(0, "Unable to read file '%s'", channelFile)
		}
		channelsCheckNew := strings.Split(string(content), "\n")
		viper.Set(keys.ChannelCheckNew, channelsCheckNew)
		return nil
	}
	return fmt.Errorf("please set the file of URLs for Tubarr to download from")
}

// verifyOutputFiletype verifies the output filetype
func verifyOutputFiletype() {
	if viper.IsSet(keys.OutputFiletype) {
		o := GetString(keys.OutputFiletype)
		if !strings.HasPrefix(o, ".") {
			o = "." + o
			viper.Set(keys.OutputFiletype, o)
			viper.Set(keys.OutputFiletype, o)
		}

		for _, ext := range consts.AllVidExtensions {
			if o == ext {
				logging.I("Outputting files as %s", o)
				return // Must return on match or overwrites with ""
			}
		}
		viper.Set(keys.OutputFiletype, "")
	}
}

// verifyLogLevel verifies logging level settings, saves into logging.Level var
func verifyLogLevel() {
	dLevel := GetInt(keys.DebugLevel)
	switch {
	case dLevel <= 0:
		logging.Level = 0
	case dLevel >= 5:
		logging.Level = 5
	default:
		logging.Level = dLevel
	}
}

// verifyFilterOps verifies the user input filters
func verifyFilterOps() error {
	if viper.IsSet(keys.FilterOpsInput) {

		filters := viper.GetStringSlice(keys.FilterOpsInput)
		var dlFilters = make([]*models.DLFilter, len(filters))

		for _, filter := range filters {
			pair := strings.Split(filter, ":")
			if len(pair) != 2 {
				return fmt.Errorf("please enter filters in format 'field:contains_text'")
			}
			dlFilters = append(dlFilters, &models.DLFilter{
				Field: pair[0],
				Omit:  pair[1],
			})
		}
		if len(dlFilters) > 0 {
			viper.Set(keys.FilterOps, dlFilters)
		}
	}
	return nil
}
package cfg

import (
	"fmt"
	"os"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"

	"github.com/BurntSushi/toml"
	"github.com/spf13/viper"
)

func parseTomlFile() (*models.Config, error) {
	if !viper.IsSet(keys.TomlPath) {
		logging.D(3, "No config file sent in")
		return nil, nil
	}

	path := viper.GetString(keys.TomlPath)
	checkPath, err := os.Stat(path)

	switch {
	case err != nil:
		return nil, err
	case checkPath.IsDir():
		return nil, fmt.Errorf("toml file passed in as directory '%s', should be file", path)
	case !checkPath.Mode().IsRegular():
		return nil, fmt.Errorf("'%s' is not a regular file", path)
	case checkPath.Size() == 0:
		return nil, fmt.Errorf("file '%s' is empty", path)
	}

	var config models.Config

	if _, err := toml.DecodeFile(path, &config); err != nil {
		return nil, err
	}

	return &config, nil
}
package cfg

import (
	"fmt"
	"net/http"
	"net/url"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

// validateConfig validates entries in the config file
func validateConfig(c *models.Config) (err error) {
	if c == nil {
		return fmt.Errorf("model is null")
	}

	// Trim invalid URLs
	if c.RawURLs.URLs, err = validateURLs(c.RawURLs.URLs); err != nil {
		logging.E(0, err.Error())
	}

	// Check sites
	for siteName, site := range c.Sites {
		if site == nil {
			delete(c.Sites, siteName)
			logging.E(0, "Site entered null")
			continue
		}
		for chanName, channel := range c.Channels {
			if channel == nil {
				delete(c.Channels, chanName)
				logging.E(0, "Channel entered null")
				continue
			}
			if cUrl := validateURL(channel.URL); cUrl == "" {
				logging.E(0, "Channel URL '%s' invalid, removing channel...", channel)
				delete(c.Channels, chanName)
			} else {
				channel.URL = cUrl
			}
			channel.SkipTitles = append(channel.SkipTitles, site.Settings.SkipTitles...)
		}
		if len(c.Channels) == 0 {
			delete(c.Sites, siteName)
		}
	}
	cleanupConfig(c)
	return nil
}

// validateURLs validates a list of URLs
func validateURLs(rawUrls []string) (valid []string, err error) {

	var failed []string

	count := len(rawUrls)
	for _, line := range rawUrls {
		if line == "" || line == "\n" {
			continue
		}

		if r := validateURL(line); r != "" {
			valid = append(valid, r)
		} else {
			failed = append(failed, r)
			count--
		}
	}

	if len(valid) == 0 {
		return nil, fmt.Errorf("no valid URLs passed in. URL list: %v", rawUrls)
	}

	if len(failed) > 0 {
		logging.E(0, "Got %d valid URLs. Other URLs seem to be invalid: %v", count, failed)
	} else {
		logging.S(0, "Retrieved %d valid URLs", count)
	}

	return valid, nil
}

// validateURL validates a single URL
func validateURL(rawUrl string) string {
	if rawUrl == "" {
		return ""
	}

	u, err := url.Parse(rawUrl)
	if err != nil {
		logging.E(0, "Error '%v' parsing URL '%s', returning empty", err, rawUrl)
		return ""
	}

	resp, err := http.Get(u.String())
	if err != nil {
		logging.E(0, "Encountered error validating URL '%s': Err: %v", u.String(), err)
		return ""
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		logging.E(0, "Invalid response status '%s' for URL '%s'", resp.Status, u.String())
		return ""
	}

	return u.String()
}

func cleanupConfig(c *models.Config) {
	if len(c.Sites) == 0 {
		c.Sites = nil
	}
	if len(c.Channels) == 0 {
		c.Channels = nil
	}
	if len(c.RawURLs.URLs) == 0 {
		c.RawURLs.URLs = nil
	}
}
package cfg

import (
	"github.com/spf13/viper"
)

// Set sets the value for the key in the override register. Set is case-insensitive for a key. Will be used instead of values obtained via flags, config file, ENV, default, or key/value store.
func Set(key string, value any) {

	viper.Set(key, value)
}

// Get can retrieve any value given the key to use. Get is case-insensitive for a key. Get has the behavior of returning the value associated with the first place from where it is set. Viper will check in the following order: override, flag, env, config file, key/value store, default
// Get returns an interface. For a specific value use one of the Get____ methods.
func Get(key string) any {
	return viper.Get(key)
}

// GetBool returns the value associated with the key as a boolean.
func GetBool(key string) bool {
	return viper.GetBool(key)
}

// GetInt returns the value associated with the key as an integer.
func GetInt(key string) int {
	return viper.GetInt(key)
}

// GetUint64 returns the value associated with the key as an unsigned integer.
func GetUint64(key string) uint64 {
	return viper.GetUint64(key)
}

// GetFloat64 returns the value associated with the key as a float64.
func GetFloat64(key string) float64 {
	return viper.GetFloat64(key)
}

// GetString returns the value associated with the key as a string.
func GetString(key string) string {
	return viper.GetString(key)
}

// GetStringSlice returns the value associated with the key as a slice of strings.
func GetStringSlice(key string) []string {
	return viper.GetStringSlice(key)
}

// IsSet checks to see if the key has been set in any of the data locations.
// IsSet is case-insensitive for a key.
func IsSet(key string) bool {
	return viper.IsSet(key)
}
package command

import (
	"os/exec"
	"tubarr/internal/cfg"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
)

type MetaDLRequest struct {
	DLs []*models.DLs
}

func NewMetaDLRequest(dls []*models.DLs) *MetaDLRequest {
	return &MetaDLRequest{
		DLs: dls,
	}
}

// RequestMetaCommand builds and returns the argument for downloading metadata
// files for the given URL
func (mdl *MetaDLRequest) RequestMetaCommand() {

	jsonDir := "."
	if cfg.IsSet(keys.JsonDir) {
		jsonDir = cfg.GetString(keys.JsonDir)
	}

	var buildArgs []string
	buildArgs = append(buildArgs, "--skip-download", "--write-json", "-P", jsonDir)

	if cfg.IsSet(keys.RestrictFilenames) {
		buildArgs = append(buildArgs, "--restrict_filenames", cfg.GetString(keys.RestrictFilenames))
	}

	if cfg.IsSet(keys.DLRetries) {
		buildArgs = append(buildArgs, "--retries", cfg.GetString(keys.DLRetries))
	}

	buildArgs = append(buildArgs, "--print", "after_write:%(info_json)s")

	for _, dl := range mdl.DLs {
		args := buildArgs
		args = append(args, dl.URL)
		dl.JSONCommand = exec.Command("yt-dlp", args...)
	}
}
package command

import (
	"fmt"
	"os"
	"os/exec"
	"strconv"
	"strings"
	"tubarr/internal/cfg"
	preset "tubarr/internal/cfg/presets"
	consts "tubarr/internal/domain/constants"
	enums "tubarr/internal/domain/enums"
	keys "tubarr/internal/domain/keys"
	tags "tubarr/internal/domain/tags"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

type MetarrCommand struct {
	Commands map[string][]string
}

// NewMetarrCommandBuilder returns a new command builder to build and run Metarr commands
func NewMetarrCommandBuilder() *MetarrCommand {
	return &MetarrCommand{
		Commands: make(map[string][]string),
	}
}

// MakeMetarrCommands builds the command list for Metarr
func (mc *MetarrCommand) MakeMetarrCommands(d []*models.DLs) ([]*exec.Cmd, error) {
	if len(d) == 0 {
		return nil, fmt.Errorf("no downloaded file models")
	}

	if _, err := exec.LookPath("metarr"); err != nil {
		return nil, fmt.Errorf("metarr command not found in PATH: %w", err)
	}

	if err := mc.ParsePresets(d); err != nil {
		return nil, fmt.Errorf("failed to parse command presets")
	}

	commands := make([]*exec.Cmd, 0, len(mc.Commands))
	for _, args := range mc.Commands {
		command := exec.Command("metarr", args...)
		commands = append(commands, command)
	}

	return commands, nil
}

// ParseMetarrPreset parses the Metarr from a preset file
func (mc *MetarrCommand) ParsePresets(d []*models.DLs) error {

	logging.I("Sending to Metarr for metadata insertion")

	mPresetFilepath := cfg.GetString(keys.MetarrPreset)
	if mPresetFilepath != "" {
		if _, err := os.Stat(mPresetFilepath); err != nil {
			logging.E(0, "Preset file not accessible: (%v) Clearing key...", err)
			cfg.Set(keys.MetarrPreset, "")
		}
	}

	if mc.Commands == nil {
		mc.Commands = make(map[string][]string)
	}

	for _, model := range d {
		if model == nil {
			continue
		}

		args := []string{}

		var (
			outputPath, outputExt string
		)

		if cfg.IsSet(keys.MoveOnComplete) {
			outputPath = cfg.GetString(keys.MoveOnComplete)
		}

		if cfg.IsSet(keys.OutputFiletype) {
			outputExt = cfg.GetString(keys.OutputFiletype)
		}

		args = append(args, "-V", model.VideoPath)
		args = append(args, "-J", model.JSONPath)

		if mPresetFilepath != "" { // Parse preset file
			content, err := os.ReadFile(mPresetFilepath)
			if err != nil {
				return fmt.Errorf("error reading file '%s': %w", mPresetFilepath, err)
			}
			cStr := string(content)

			args = append(args, mc.metaOps(cStr)...)
			args = append(args, mc.dateTagFormat(cStr)...)
			args = append(args, mc.renameStyle(cStr)...)

			if outputPath == "" {
				if rtn, err := mc.outputLocation(cStr); err == nil {
					args = append(args, rtn...)
				}
			}
			if outputExt == "" {
				if rtn, err := mc.outputExtension(cStr); err == nil {
					args = append(args, rtn...)
				}
			}
		} else { // Fallback to auto-preset detection
			args = preset.AutoPreset(model.URL)
		}

		if outputPath != "" {
			args = append(args, "-o", outputPath)
		}

		if outputExt != "" {
			args = append(args, "--ext", outputExt)
		}

		if cfg.IsSet(keys.DebugLevel) {
			dLevel := cfg.GetInt(keys.DebugLevel)
			args = append(args, "-d", strconv.Itoa(dLevel))
		}

		mc.Commands[model.VideoPath] = args
	}
	return nil
}

// dateTagFormat builds the date tag format to prefix filenames with
func (mc *MetarrCommand) dateTagFormat(c string) []string {

	lines, exists := mc.getFieldContent(c, tags.MetarrFilenameDate, enums.L_SINGLE)
	var args = make([]string, 0, len(lines)*2)

	if exists && len(lines) > 0 {

		lines[0] = strings.TrimSpace(lines[0])

		switch lines[0] {
		case "Ymd", "ymd", "mdY", "mdy", "dmY", "dmy":
			args = append(args, "--filename-date-tag", lines[0])
		default:
			logging.E(0, "Date tag format entry syntax is incorrect, should be in a format such as Ymd (for yyyy-mm-dd) or ymd (for yy-mm-dd) and so on...")
		}
	}
	return args
}

// metaOps adds the commands for manipulating metadata
func (mc *MetarrCommand) metaOps(c string) []string {

	var shouldOW bool

	lines, exists := mc.getFieldContent(c, tags.MetarrMetaOps, enums.L_MULTI)
	var args = make([]string, 0, len(lines)*2)

	if exists && len(lines) > 0 {
		for _, line := range lines {
			if line == "" {
				continue
			}

			entry := strings.Split(line, ":")
			if len(entry) < 3 {
				logging.E(0, "Error in new metadata field entry, entry shorter than 3 (should be at least 'field:operation:value')")
			} else {
				args = append(args, "--meta-ops", line)
				if entry[1] == "set" {
					shouldOW = true
				}
			}
		}
	}

	if shouldOW {
		args = append(args, "--meta-overwrite")
	}

	return args
}

// renameStyle is the chosen style of renaming, e.g. spaces, underscores
func (mc *MetarrCommand) renameStyle(c string) []string {

	lines, exists := mc.getFieldContent(c, tags.MetarrRenameStyle, enums.L_SINGLE)
	var args = make([]string, 0, len(lines)*2)

	if exists && len(lines) > 0 {
		lines[0] = strings.TrimSpace(lines[0])

		switch lines[0] {
		case "spaces", "underscores", "skip":
			args = append(args, "-r", lines[0])
		default:
			logging.E(0, "Rename style entry syntax is incorrect, should be spaces, underscores, or skip.")
			args = append(args, "-r", "skip")
		}
	}
	return args
}

// outputLocation designates the output directory
func (mc *MetarrCommand) outputLocation(c string) ([]string, error) {

	lines, exists := mc.getFieldContent(c, tags.MetarrOutputDir, enums.L_SINGLE)
	var args = make([]string, 0, len(lines)*2)

	if exists && len(lines) > 0 {
		if lines[0] != "" {
			dir, err := os.Stat(lines[0])
			if err != nil {
				return args, fmt.Errorf("error with output directory: %w", err)
			} else if os.IsNotExist(err) {
				return args, fmt.Errorf("target output directory does not exist: %w", err)
			}

			if !dir.IsDir() {
				return args, fmt.Errorf("output location is not a directory")
			}

			args = append(args, "-o", lines[0])
		}
	}
	return args, nil
}

// outputExtension is the filetype extension to output files as
func (mc *MetarrCommand) outputExtension(c string) ([]string, error) {

	lines, exists := mc.getFieldContent(c, tags.MetarrOutputExt, enums.L_SINGLE)
	var args = make([]string, 0, len(lines)*2)

	if exists && len(lines) > 0 {
		lines[0] = strings.TrimSpace(lines[0])
		lines[0] = strings.TrimPrefix(lines[0], ".")

		filled := false
		for _, ext := range consts.AllVidExtensions {
			if ext == lines[0] {
				args = append(args, "--ext", ext)
				filled = true
			}
		}
		if !filled {
			return args, fmt.Errorf("incorrect file extension '%s' entered for yt-dlp", lines[0])
		}
	}
	return args, nil
}

// removeEmptyLines strips empty lines from the result
func (mc *MetarrCommand) removeEmptyLines(input []string) []string {
	var lines = make([]string, 0, len(input))
	for _, line := range input {
		if line == "" || line == "\r" { // \n delimiter already removed by strings.Split
			continue
		}
		lines = append(lines, line)
	}
	return lines
}

// getFieldContent extracts the content inside the field
func (mc *MetarrCommand) getFieldContent(c, tag string, selectType enums.LineSelectType) ([]string, bool) {
	if tagLoc := strings.Index(c, tag); tagLoc != -1 {

		content := c[tagLoc+len(tag)+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx]
		}

		content = cleanNewLines(content)
		gotLines := strings.Split(content, "\n")

		lines := mc.removeEmptyLines(gotLines)

		if len(lines) > 0 {
			if selectType == enums.L_SINGLE {
				return []string{lines[0]}, true
			}
			// Returns multi
			return lines, true
		}
		logging.D(2, "Lines grabbed empty for tag '%s' and content '%s'", tag, c)
		return nil, false
	}
	logging.D(2, "Tag '%s' not found in content '%s'", tag, c)
	return nil, false
}

// cleanNewLines normalizes the newline patterns across different OS's
func cleanNewLines(s string) string {
	rep := strings.NewReplacer("\r\n", "\n", "\r", "\n")
	rep.Replace(s)
	return s
}
package command

import (
	"fmt"
	"os/exec"
	"strings"
	"tubarr/internal/cfg"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

type VideoDLRequest struct {
	DL *models.DLs
}

func NewVideoDLRequest(d *models.DLs) *VideoDLRequest {
	return &VideoDLRequest{
		DL: d,
	}
}

// BuildVideoFetchCommand builds the command for yt-dlp
func (vf *VideoDLRequest) VideoFetchCommand() error {
	if vf.DL == nil {
		return fmt.Errorf("model passed in null, returning no command")
	}

	if _, err := exec.LookPath("yt-dlp"); err != nil {
		return fmt.Errorf("yt-dlp command not found: %w", err)
	}

	if vf.DL.URL == "" {
		return fmt.Errorf("url passed in blank")
	}

	var args []string
	dl := vf.DL

	switch {
	case strings.Contains(dl.URL, "censored.tv"):
		// Not implemented
	default:
		// Use default
	}

	if cfg.IsSet(keys.RestrictFilenames) {
		args = append(args, "--restrict-filenames", "-o", cfg.GetString(keys.RestrictFilenames))
	}

	if cfg.IsSet(keys.DLRetries) {
		args = append(args, "--retries", cfg.GetString(keys.DLRetries))
	}

	args = append(args, "--print", "after_move:%(filepath)s")

	if cfg.IsSet(keys.CookieSource) {
		args = append(args, "--cookies-from-browser", cfg.GetString(keys.CookieSource))
	}
	// else if cookieFile != "" {
	// 	args = append(args, "--cookies", cookieFile)
	// }

	if cfg.IsSet(keys.ExternalDownloader) {
		args = append(args, "--external-downloader", cfg.GetString(keys.ExternalDownloader))
	}

	if cfg.IsSet(keys.ExternalDownloaderArgs) {
		args = append(args, "--external-downloader-args", cfg.GetString(keys.ExternalDownloaderArgs))
	}

	args = append(args, dl.URL)

	logging.D(1, "Built argument list: %v", args)
	dl.VideoCommand = exec.Command("yt-dlp", args...)

	return nil
}

// writeJsonLocation writes the target directory for the JSON file
// func writeJsonLocation(s string) []string {
// 	if s != "" {
// 		return []string{"--write-info-json", "-P", s}
// 	}
// 	return nil
// }
package command

import (
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
	"tubarr/internal/cfg"
	consts "tubarr/internal/domain/constants"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
	utils "tubarr/internal/utils/fs/write"
	logging "tubarr/internal/utils/logging"
)

var (
	muDl sync.Mutex
)

// DownloadVideos takes in a list of URLs and downloads them
func DownloadVideos(requests []*models.DLs) ([]*models.DLs, error) {
	if len(requests) == 0 {
		return nil, nil
	}

	muDl.Lock()
	defer muDl.Unlock()

	// Get configuration values
	var (
		dlFiles        []*models.DLs
		successfulURLs []string
	)

	vDir := cfg.GetString(keys.VideoDir)

	for _, request := range requests {
		if request == nil {
			continue
		}

		cmd := request.VideoCommand
		if cmd == nil {
			continue
		}

		// Create pipes for stdout and stderr
		stdout, err := cmd.StdoutPipe()
		if err != nil {
			logging.E(0, "Failed to create stdout pipe: %v", err)
			continue
		}
		stderr, err := cmd.StderrPipe()
		if err != nil {
			logging.E(0, "Failed to create stderr pipe: %v", err)
			continue
		}

		// Channel to receive the output filename
		filenameChan := make(chan string, 1)
		doneChan := make(chan struct{})

		// Start output scanner in goroutine
		go func() {
			defer close(doneChan)
			scanner := bufio.NewScanner(io.MultiReader(stdout, stderr))
			for scanner.Scan() {
				line := scanner.Text()
				fmt.Println(line)

				// Capture the actual output filename
				if strings.HasPrefix(line, "/") {
					lineExt := filepath.Ext(line)

					var match bool
					for _, ext := range consts.AllVidExtensions {
						logging.D(2, "Comparing extension %s to %s", ext, lineExt)
						if lineExt == ext {
							match = true
							select {
							case filenameChan <- line:
							default:
								// Channel already has a filename
							}
						}
						if !match {
							logging.D(1, "Did not find yt-dlp supported video format in output %s", line)
						}
					}
				}
				if err := scanner.Err(); err != nil {
					logging.E(0, "Scanner error: %v", err)
				}
			}
		}()

		// Start command
		logging.I("Executing download command: %s", cmd.String())
		if err := cmd.Start(); err != nil {
			logging.E(0, "Failed to start download: %v", err)
			close(filenameChan)
			continue
		}

		// Wait for command to complete
		if err := cmd.Wait(); err != nil {
			logging.E(0, "Download failed: %v", err)
			close(filenameChan)
			continue
		}

		// Wait for scanner to finish
		<-doneChan
		close(filenameChan)

		// Get output filename
		outputFilename := ""
		select {
		case filename := <-filenameChan:
			outputFilename = filename
		default:
			logging.E(0, "No output filename captured for URL: %s", request.URL)
			continue
		}

		// Short wait time for filesystem sync
		time.Sleep(1 * time.Second)

		// Set filenames
		request.VideoPath = outputFilename

		// Verify the download
		if err := verifyDownload(request.VideoPath, request.JSONPath); err != nil {
			logging.E(0, "Download verification failed: %v", err)
			continue
		}

		logging.S(0, "Successfully downloaded files:\nVideo: %s\nJSON: %s",
			request.VideoPath, request.JSONPath)

		dlFiles = append(dlFiles, request)
		successfulURLs = append(successfulURLs, request.URL)
	}

	if len(dlFiles) == 0 {
		return nil, fmt.Errorf("no files successfully downloaded")
	}

	// Update grabbed URLs file
	grabbedURLsPath := filepath.Join(vDir, "grabbed-urls.txt")
	if err := utils.AppendURLsToFile(grabbedURLsPath, successfulURLs); err != nil {
		logging.E(0, "Failed to update grabbed-urls.txt: %v", err)
		// Don't return error because downloads were successful
	}
	return dlFiles, nil
}

// verifyDownload checks if the specified files exist and are non-empty
func verifyDownload(videoPath, jsonPath string) error {
	// Check video file
	videoInfo, err := os.Stat(videoPath)
	if err != nil {
		return fmt.Errorf("video file verification failed: %w", err)
	}
	if videoInfo.Size() == 0 {
		return fmt.Errorf("video file is empty: %s", videoPath)
	}

	// Check JSON file
	jsonData, err := os.ReadFile(jsonPath)
	if err != nil {
		return fmt.Errorf("failed to read JSON file: %w", err)
	}

	if !json.Valid(jsonData) {
		return fmt.Errorf("invalid JSON content in file: %s", jsonPath)
	}

	return nil
}
package command

import (
	"fmt"
	"path/filepath"
	"strings"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

// ExecuteMetaDownload initiates a yt-dlp meta download command
func ExecuteMetaDownload(dl *models.DLs) error {

	cmd := dl.JSONCommand

	rtn, err := cmd.Output()
	if err != nil {
		fmt.Errorf("failed to run download metadata command for URL '%s': %w", dl.URL, err)
	}

	if len(rtn) == 0 {
		fmt.Errorf("failed to capture output from command for URL '%s'? Got: %v", dl.URL, rtn)
	}

	logging.I("retrieved JSON filename %s", string(rtn))

	jsonDir := dl.JSONDir
	if !strings.HasSuffix(jsonDir, "/") {
		jsonDir += "/"
	}

	dl.JSONPath = filepath.Join(jsonDir, string(rtn))
	logging.I("Saved JSON file path '%s' for URL '%s'", dl.JSONPath, dl.URL)

	return nil
}
package command

import (
	"fmt"
	"os"
	"os/exec"
	logging "tubarr/internal/utils/logging"
)

// RunMetarr runs a Metarr command with a built argument list
func RunMetarr(commands []*exec.Cmd) error {
	if len(commands) == 0 {
		return fmt.Errorf("no commands passed in")
	}

	var err error = nil
	for _, command := range commands {
		if len(command.String()) == 0 {
			logging.E(0, "Command string is empty? %s", command.String())
			continue
		}
		logging.I("Running command: %s", command.String())

		command.Stderr = os.Stderr
		command.Stdout = os.Stdout
		command.Stdin = os.Stdin

		if err = command.Run(); err != nil {
			logging.E(0, "Encountered error running command '%s': %w", command.String(), err)
		}
	}
	return err // Returns nil by default unless an error is grabbed
}
package domain

// Colors
const (
	ColorReset  = "\033[0m"
	ColorRed    = "\033[91m"
	ColorGreen  = "\033[92m"
	ColorYellow = "\033[93m"
	ColorBlue   = "\033[34m"
	ColorPurple = "\033[35m"
	ColorCyan   = "\033[96m"
	ColorWhite  = "\033[37m"
)

const (
	RedError     string = ColorRed + "[ERROR] " + ColorReset
	GreenSuccess string = ColorGreen + "[SUCCESS] " + ColorReset
	YellowDebug  string = ColorYellow + "[DEBUG] " + ColorReset
	BlueInfo     string = ColorCyan + "[Info] " + ColorReset
)
package domain

// File prefix and suffix
const (
	OldTag  = "_metarrbackup"
	TempTag = "tmp_"
)

// Webpage tags
var (
	WebDateTags        = []string{"release-date", "upload-date", "date", "date-text", "text-date"}
	WebDescriptionTags = []string{"description", "longdescription", "long-description", "summary", "synopsis", "check-for-urls"}
	WebCreditsTags     = []string{"creator", "uploader", "uploaded-by", "uploaded_by"}
	WebTitleTags       = []string{"video-title", "video-name"}
)

// Video files
var (
	AllVidExtensions = []string{".3gp", ".avi", ".f4v", ".flv", ".m4v", ".mkv",
		".mov", ".mp4", ".mpeg", ".mpg", ".ogm", ".ogv",
		".ts", ".vob", ".webm", ".wmv"}
)
package domain

var (
	ContractionsSpaced = map[string]string{
		"ain t":     "aint",
		"can t":     "cant",
		"don t":     "dont",
		"didn t":    "didnt",
		"hasn t":    "hasnt",
		"haven t":   "havent",
		"won t":     "wont",
		"wouldn t":  "wouldnt",
		"shouldn t": "shouldnt",
		"couldn t":  "couldnt",
		"wasn t":    "wasnt",
		"weren t":   "werent",
		"let s":     "lets",
		"hadn t":    "hadnt",
		"who s":     "whos",
		"what s":    "whats",
		"when s":    "whens",
		"where s":   "wheres",
		"why s":     "whys",
		"how s":     "hows",
		"there s":   "theres",
		"that s":    "thats",
		"it d":      "itd",
		"she d":     "shed",
		"she s":     "shes",
		"he d":      "hed",
		"he s":      "hes",
		"it ll":     "itll",
		"should ve": "shouldve",
		"could ve":  "couldve",
		"would ve":  "wouldve",
	}

	ContractionsUnderscored = map[string]string{
		"ain_t":     "aint",
		"can_t":     "cant",
		"don_t":     "dont",
		"didn_t":    "didnt",
		"hasn_t":    "hasnt",
		"haven_t":   "havent",
		"won_t":     "wont",
		"wouldn_t":  "wouldnt",
		"shouldn_t": "shouldnt",
		"couldn_t":  "couldnt",
		"wasn_t":    "wasnt",
		"weren_t":   "werent",
		"let_s":     "lets",
		"hadn_t":    "hadnt",
		"who_s":     "whos",
		"what_s":    "whats",
		"when_s":    "whens",
		"where_s":   "wheres",
		"why_s":     "whys",
		"how_s":     "hows",
		"there_s":   "theres",
		"that_s":    "thats",
		"it_d":      "itd",
		"she_d":     "shed",
		"she_s":     "shes",
		"he_d":      "hed",
		"he_s":      "hes",
		"it_ll":     "itll",
		"should_ve": "shouldve",
		"could_ve":  "couldve",
		"would_ve":  "wouldve",
	}
)
package domain

const (
	JActor     = "actor"
	JAuthor    = "author"
	JArtist    = "artist"
	JComposer  = "composer"
	JCreator   = "creator"
	JDirector  = "director"
	JPerformer = "performer"
	JProducer  = "producer"
	JPublisher = "publisher"
	JStudio    = "studio"
	JUploader  = "uploader"
	JWriter    = "writer"
)

const (
	JComment          = "comment"
	JDescription      = "description"
	JFallbackTitle    = "title"
	JLongDescription  = "longdescription"
	JLong_Description = "long_description"
	JSubtitle         = "subtitle"
	JSummary          = "summary"
	JSynopsis         = "synopsis"
	JTitle            = "fulltitle"
)

const (
	JCreationTime        = "creation_time"
	JDate                = "date"
	JFormattedDate       = "formatted_date"
	JOriginallyAvailable = "originally_available_at"
	JReleaseDate         = "release_date"
	JUploadDate          = "upload_date"
	JYear                = "year"
	JReleaseYear         = "release_year"
)

const (
	JDomain        = "domain"
	JReferer       = "referer"
	JURL           = "url"
	JWebpageDomain = "webpage_url_domain"
	JWebpageURL    = "webpage_url"
)
package domain

// Log file keys
const (
	LogFinished = "FINISHED: "
	LogError    = "ERROR: "
	LogFailure  = "FAILED: "
	LogSuccess  = "Success: "
	LogInfo     = "Info: "
	LogWarning  = "Warning: "
	LogBasic    = ""
)
package domain

const (
	// Core Descriptive Metadata
	NTitle         = "title"
	NOriginalTitle = "originaltitle"
	NSortTitle     = "sorttitle"
	NTagline       = "tagline"
	NDescription   = "description"
	NPlot          = "plot"
	NOutline       = "outline"
	NShowTitle     = "showtitle"
	NSubtitle      = "subtitle"

	// Cast and Crew Metadata
	NActors   = "actor"
	NDirector = "director"
	NWriter   = "writer"
	NComposer = "composer"
	NProducer = "producer"

	// Genre, Category, and Rating Metadata
	NGenre      = "genre"
	NMood       = "mood"
	NMPAA       = "mpaa"
	NVotes      = "votes"
	NRatingsURL = "ratingurl"

	// Date and Release Metadata
	NAired        = "aired"
	NPremiereDate = "premiered"
	NYear         = "year"

	// Episodic Metadata
	NSeason       = "season"
	NEpisode      = "episode"
	NEpisodeTitle = "episodetitle"

	// Technical Information
	NCountry   = "country"
	NLanguage  = "language"
	NRated     = "rated"
	NEncodedBy = "encodedby"
	NRuntime   = "runtime"
	NRating    = "rating"

	// Production Metadata
	NProductionCompany = "productioncompany"
	NStudio            = "studio"
	NCoverArtist       = "coverartist"
	NPublisher         = "publisher"
	NCompilation       = "compilation"

	// Artwork, Media Assets, and Related Links
	NThumb    = "thumb"
	NFanart   = "fanart"
	NTrailer  = "trailer"
	NCoverArt = "cover_art"

	// Sorting and Alternate Display Titles
	NShowSortTitle = "showsorttitle"

	// Miscellaneous
	NComment = "comment"
	NTop250  = "top250"
	NTrack   = "track"
	NAlbum   = "album"
	NLicence = "license"
	NRights  = "rights"
	NURL     = "url"
)
package domain

type LineSelectType int

const (
	L_SINGLE LineSelectType = iota
	L_MULTI  LineSelectType = iota
)
package domain

// Terminal keys
const (
	VideoDir string = "video-dir"
	MetaDir  string = "metadata-dir"
	JsonDir  string = "json-dir"

	InputExts    string = "input-exts"
	InputPreset  string = "preset"
	MetarrPreset string = "metarr-preset"
	ChannelFile  string = "check-channels"
	CookieSource string = "cookie-source"
	CookiePath   string = "cookie-file"

	ExternalDownloader     string = "external-downloader"
	ExternalDownloaderArgs string = "external-downloader-args"
	MoveOnComplete         string = "move-on-complete"

	OutputFiletype string = "ext"

	FilterOpsInput    string = "filter-ops"
	TomlPath          string = "config-file"
	RestrictFilenames string = "restrict_filenames"
	DLRetries         string = "dl-retries"
)

// Primary program
const (
	Context    string = "Context"
	WaitGroup  string = "WaitGroup"
	SingleFile string = "SingleFile"
)

// Check channels for new uploads
const (
	ChannelCheckNew string = "CheckChannelsForNew"
)

const (
	FilterOps string = "filterOps"
)

// Filename edits
const (
	FileNaming string = "ytdlp-naming-style"
)

// Logging
const (
	DebugLevel string = "debug-level"
)

// Web related
const (
	Configuration string = "configuration"
	ValidURLs     string = "validUrls"
)
package domain

// Preset tag in file
const (
	MetarrFilenameDate       = "[filename-date-tag]"
	MetarrFilenameReplaceSfx = "[filename-replace-suffix]"
	MetarrMetaOps            = "[meta-ops]"
	MetarrRenameStyle        = "[rename-style]"
	MetarrOutputDir          = "[output-directory]"
	MetarrOutputExt          = "[output-extension]"
)
package models

import "os/exec"

// DLRequest represents a download request
type DLRequest struct {
	URL             string
	DownloadArchive string
	Command         *exec.Cmd
}

type DLs struct {
	VideoCommand *exec.Cmd
	VideoPath    string
	VideoDir     string

	JSONCommand *exec.Cmd
	JSONPath    string
	JSONDir     string

	Metamap map[string]interface{}

	URL string
}

type DLFilter struct {
	Field string
	Omit  string
}

type Metadata struct {
	Title       string `json:"title"`
	Description string `json:"description"`
}
package models

// Config represents the top-level configuration structure
type Config struct {
	Sites    map[string]*Site    `toml:"sites"`
	Channels map[string]*Channel `toml:"channels"`
	RawURLs  *RawURLs            `toml:"raw-urls"`
}

// Site represents a video site configuration
type Site struct {
	Channels []string     `toml:"channels"`
	Settings SiteSettings `toml:"settings"`
}

// SiteSettings contains site-specific settings
type SiteSettings struct {
	SkipTitles        []string `toml:"skip:title"`
	Retries           int      `toml:"retries"`
	RestrictFilenames string   `toml:"restrict_filenames"`
}

// Channel represents a channel configuration
type Channel struct {
	URL        string   `toml:"url"`
	Directory  string   `toml:"directory"`
	SkipTitles []string `toml:"skip:title"`
	Settings   ChannelSettings
}

// SiteSettings contains channel-specific settings
type ChannelSettings struct {
	SkipTitles        []string `toml:"skip:title"`
	Retries           int      `toml:"retries"`
	RestrictFilenames string   `toml:"restrict_filenames"`
}

// RawURLs contains direct video/channel URLs
type RawURLs struct {
	URLs []string `toml:"url"`
}
package process

import (
	"sync"
	builder "tubarr/internal/command/builder"
	execute "tubarr/internal/command/execute"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

// ProcessMetaDownloads is the entry point for processing metadata downloads
func ProcessMetaDownloads(dls []*models.DLs) []*models.DLs {

	mdl := builder.NewMetaDLRequest(dls)
	mdl.RequestMetaCommand()

	wg := sync.WaitGroup{}
	validDls := make([]*models.DLs, 0, len(dls))
	mu := sync.Mutex{}

	wg.Add(1)
	go func() {
		defer wg.Done()
		for _, dl := range dls {
			if err := execute.ExecuteMetaDownload(dl); err != nil {
				logging.E(0, "Got error downloading meta for '%s': %v", dl.URL, err.Error())
			}
			if valid, err := validateJson(dl); err != nil {
				logging.E(0, "JSON validation failed for '%s': %v", dl.URL, err.Error())
				continue
			} else if !valid {
				logging.D(2, "Filtered out download for URL '%s'", dl.URL)
				continue
			}

			mu.Lock()
			validDls = append(validDls, dl)
			mu.Unlock()
		}
	}()
	wg.Wait()

	return validDls
}
package process

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"tubarr/internal/cfg"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
)

// validateJson checks if the JSON is valid and if it passes filter checks
func validateJson(dl *models.DLs) (valid bool, err error) {

	if dl.JSONDir == "" {
		return false, fmt.Errorf("json directory cannot be empty")
	}

	jInfo, err := os.Stat(dl.JSONPath)
	if err != nil {
		return false, err
	}

	switch {
	case jInfo.IsDir():
		return false, fmt.Errorf("json path should be path to json file, not directory")
	case filepath.Ext(jInfo.Name()) != ".json":
		return false, fmt.Errorf("json file should end in .json")
	case !jInfo.Mode().IsRegular():
		return false, fmt.Errorf("json not a regular file")
	}

	f, err := os.Open(dl.JSONPath)
	if err != nil {
		return false, err
	}
	defer f.Close()

	decoder := json.NewDecoder(f)
	if err := decoder.Decode(dl.Metamap); err != nil {
		return false, fmt.Errorf("failed to decode JSON: %w", err)
	}

	if valid, err = filterRequests(dl); err != nil {
		return false, err
	}

	return valid, nil
}

// filterRequests uses user input filters to check if the video should be downloaded
func filterRequests(dl *models.DLs) (valid bool, err error) {

	if cfg.IsSet(keys.FilterOps) {
		filters, ok := cfg.Get(keys.FilterOps).([]*models.DLFilter)
		if !ok {
			return false, fmt.Errorf("wrong type sent in, got %T", filters)
		}

		if len(filters) > 0 {
			for _, filter := range filters {
				if val, exists := dl.Metamap[filter.Field]; exists {
					if val == filter.Omit {
						return false, err
					}
				}
			}
		}
	}
	return true, nil
}
package process

import (
	build "tubarr/internal/command/builder"
	execute "tubarr/internal/command/execute"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

func ProcessVideoDownloads(dls []*models.DLs) {

	valid := make([]*models.DLs, len(dls))

	for _, dl := range dls {
		vcb := build.NewVideoDLRequest(dl)
		if err := vcb.VideoFetchCommand(); err != nil {
			logging.E(0, err.Error())
			continue
		}
		valid = append(valid, dl)
	}

	if len(valid) == 0 {
		logging.E(0, "No valid downloads to process")
		return
	}

	execute.DownloadVideos(valid)
}
package utils

import (
	"fmt"
	"net/http"
	"net/url"
	"strings"
	config "tubarr/internal/cfg"
	keys "tubarr/internal/domain/keys"
	logging "tubarr/internal/utils/logging"

	"github.com/browserutils/kooky"
	_ "github.com/browserutils/kooky/browser/all"
	"github.com/browserutils/kooky/browser/chrome"
	"github.com/browserutils/kooky/browser/firefox"
	"github.com/browserutils/kooky/browser/safari"
)

// GetBrowserCookies sets cookies input by the user. Useful for getting URLs
// from websites which require authentication!

var (
	allStores  []kooky.CookieStore
	allCookies []*http.Cookie
)

// initializeCookies initializes all browser cookie stores
func initializeCookies() {
	allStores = kooky.FindAllCookieStores()
	allCookies = []*http.Cookie{}
}

// GetBrowserCookies retrieves cookies for a given URL, using a specified cookie file if provided.
func getBrowserCookies(url string) ([]*http.Cookie, error) {
	baseURL, err := extractBaseDomain(url)
	if err != nil {
		return nil, fmt.Errorf("failed to extract base domain: %v", err)
	}

	if config.IsSet(keys.CookiePath) {
		cookieFilePath := config.GetString(keys.CookiePath)

		// If a cookie file path is provided, use it
		if cookieFilePath != "" {
			logging.D(2, "Reading cookies from specified file: %s", cookieFilePath)
			kookyCookies, err := readCookieFile(cookieFilePath)
			if err != nil {
				return nil, fmt.Errorf("failed to read cookies from file: %v", err)
			}
			return convertToHTTPCookies(kookyCookies), nil
		}
	}

	// Otherwise, proceed to use browser cookie stores
	if allStores == nil || allCookies == nil || len(allCookies) == 0 {
		initializeCookies()
	}

	attemptedBrowsers := make(map[string]bool, len(allStores))

	for _, store := range allStores {
		browserName := store.Browser()
		logging.D(2, "Attempting to read cookies from %s", browserName)
		attemptedBrowsers[browserName] = true

		cookies, err := store.ReadCookies(kooky.Valid, kooky.Domain(baseURL))
		if err != nil {
			logging.D(2, "Failed to read cookies from %s: %v", browserName, err)
			continue
		}

		if len(cookies) > 0 {
			logging.I("Successfully read %d cookies from %s for domain %s", len(cookies), browserName, baseURL)
			allCookies = append(allCookies, convertToHTTPCookies(cookies)...)
		} else {
			logging.D(2, "No cookies found for %s", browserName)
		}
	}

	// Log summary of attempted browsers
	logging.I("Attempted to read cookies from the following browsers: %v", keysFromMap(attemptedBrowsers))

	if len(allCookies) == 0 {
		logging.I("No cookies found for '%s', proceeding without cookies", url)
	} else {
		logging.I("Found a total of %d cookies for '%s'", len(allCookies), url)
	}

	return allCookies, nil
}

// convertToHTTPCookies converts kooky cookies to http.Cookie format
func convertToHTTPCookies(kookyCookies []*kooky.Cookie) []*http.Cookie {
	httpCookies := make([]*http.Cookie, len(kookyCookies))
	for i, c := range kookyCookies {
		httpCookies[i] = &http.Cookie{
			Name:   c.Name,
			Value:  c.Value,
			Path:   c.Path,
			Domain: c.Domain,
			Secure: c.Secure,
		}
	}
	return httpCookies
}

// extractBaseDomain parses a URL and extracts its base domain
func extractBaseDomain(urlString string) (string, error) {
	parsedURL, err := url.Parse(urlString)
	if err != nil {
		return "", err
	}

	parts := strings.Split(parsedURL.Hostname(), ".")
	if len(parts) > 2 {
		return strings.Join(parts[len(parts)-2:], "."), nil
	}
	return parsedURL.Hostname(), nil
}

// keysForMap helper function to get keys from a map
func keysFromMap(m map[string]bool) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}

// readCookieFile reads cookies from the specified cookie file
func readCookieFile(cookieFilePath string) ([]*kooky.Cookie, error) {
	var store kooky.CookieStore
	var err error

	// Attempt to identify and read cookies based on known browser stores
	if strings.Contains(cookieFilePath, "firefox") || strings.Contains(cookieFilePath, "cookies.sqlite") {
		store, err = firefox.CookieStore(cookieFilePath)
	} else if strings.Contains(cookieFilePath, "safari") || strings.Contains(cookieFilePath, "Cookies.binarycookies") {
		store, err = safari.CookieStore(cookieFilePath)
	} else if strings.Contains(cookieFilePath, "chrome") || strings.Contains(cookieFilePath, "Cookies") {
		store, err = chrome.CookieStore(cookieFilePath)
	} else {
		return nil, fmt.Errorf("unsupported cookie file format")
	}

	if err != nil {
		return nil, fmt.Errorf("failed to create cookie store: %w", err)
	}

	// Read cookies from the store
	cookies, err := store.ReadCookies()
	if err != nil {
		return nil, fmt.Errorf("failed to read cookies: %w", err)
	}

	return cookies, nil
}
package utils

import (
	"bufio"
	"fmt"
	"net/http"
	"os"
	"strings"
	"tubarr/internal/cfg"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"

	"github.com/gocolly/colly"
)

// GetNewReleases checks a channel URL for URLs which have not yet been recorded as downloaded
func GetNewReleases(vDir, jDir string) []*models.DLs {

	uniqueURLs := make(map[string]struct{})
	urlsToCheck := cfg.GetStringSlice(keys.ChannelCheckNew)

	for _, url := range urlsToCheck {
		if url == "" {
			continue
		}

		cookies, err := getBrowserCookies(url)
		if err != nil {
			logging.E(0, "Could not get cookies for %s: %v", url, err)
			continue
		}

		urls, err := newEpisodeURLs(url, cookies)
		if err != nil {
			logging.E(0, "Could not grab episodes from %s: %v", url, err)
			continue
		}

		// Add unique URLs to map
		for _, newURL := range urls {
			if newURL != "" {
				uniqueURLs[newURL] = struct{}{}
			}
		}
	}
	// Convert map to slice
	var newRequests = make([]*models.DLs, 0, len(uniqueURLs))
	for url := range uniqueURLs {
		newRequests = append(newRequests, &models.DLs{
			URL: url,

			VideoDir: vDir,
			JSONDir:  jDir,
		})
	}

	// Log results
	if len(newRequests) > 0 {
		logging.I("Grabbed %d new download requests: %v", len(newRequests), uniqueURLs)
	}

	return newRequests
}

// newEpisodeURLs checks for new episode URLs that are not yet in grabbed-urls.txt
func newEpisodeURLs(targetURL string, cookies []*http.Cookie) ([]string, error) {

	c := colly.NewCollector()
	uniqueEpisodeURLs := make(map[string]struct{})

	for _, cookie := range cookies {
		c.SetCookies(targetURL, []*http.Cookie{cookie})
	}

	// Video URL link pattern
	switch {
	case strings.Contains(targetURL, "bitchute.com"):
		logging.I("Detected bitchute.com link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/video/") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})

	case strings.Contains(targetURL, "censored.tv"):
		logging.I("Detected censored.tv link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/episode/") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})

	case strings.Contains(targetURL, "odysee.com"):
		logging.I("Detected Odysee link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			parts := strings.Split(link, "/")
			if len(parts) > 1 {
				lastPart := parts[len(parts)-1]
				if strings.Contains(link, "@") && strings.Contains(link, lastPart+"/") {
					uniqueEpisodeURLs[link] = struct{}{}
				}
			}
		})

	case strings.Contains(targetURL, "rumble.com"):
		logging.I("Detected Rumble link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/v") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})

	default:
		logging.I("Using default link detection")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/watch") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})
	}

	// Visit the target URL
	err := c.Visit(targetURL)
	if err != nil {
		return nil, fmt.Errorf("error visiting webpage (%s): %v", targetURL, err)
	}
	c.Wait()

	// Convert unique URLs map to slice
	var episodeURLs = make([]string, 0, len(uniqueEpisodeURLs))
	for url := range uniqueEpisodeURLs {
		episodeURLs = append(episodeURLs, url)
	}

	// Load existing URLs from grabbed-urls.txt
	existingURLs, err := loadGrabbedURLsFromFile("grabbed-urls.txt")
	if err != nil {
		return nil, fmt.Errorf("error reading grabbed URLs file: %v", err)
	}

	// Filter out URLs that are already in grabbed-urls.txt
	var newURLs = make([]string, 0, len(episodeURLs))
	for _, url := range episodeURLs {
		normalizedURL := normalizeURL(url)
		exists := false

		for existingURL := range existingURLs {
			if normalizeURL(existingURL) == normalizedURL {
				exists = true
				break
			}
		}
		if !exists {
			newURLs = append(newURLs, url)
		}
	}
	if len(newURLs) == 0 {
		logging.I("No new videos at %s", targetURL)
		return nil, nil
	}
	return newURLs, nil
}

// loadGrabbedURLsFromFile reads URLs from a file and returns them as a map for quick lookup
func loadGrabbedURLsFromFile(filename string) (map[string]struct{}, error) {

	var (
		filepath string
	)

	videoDir := cfg.GetString(keys.VideoDir)

	switch strings.HasSuffix(videoDir, "/") {
	case false:
		filepath = videoDir + "/" + filename
	default:
		filepath = videoDir + filename
	}

	file, err := os.Open(filepath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	urlMap := make(map[string]struct{})
	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		url := scanner.Text()
		urlMap[url] = struct{}{}
	}

	if err := scanner.Err(); err != nil {
		return nil, err
	}

	return urlMap, nil
}

// normalizeURL standardizes URLs for comparison by removing protocol and any trailing slashes
func normalizeURL(inputURL string) string {
	// Remove http:// or https://
	cleanURL := strings.TrimPrefix(inputURL, "https://")
	cleanURL = strings.TrimPrefix(cleanURL, "http://")

	// Remove any trailing slash
	cleanURL = strings.TrimSuffix(cleanURL, "/")

	return cleanURL
}
package utils

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	consts "tubarr/internal/domain/constants"
	logging "tubarr/internal/utils/logging"
)

// BackupFile creates a backup copy of the original file before modifying it.
// helps save important data if the program fails in some way
func BackupFile(file *os.File) error {

	// Get the original filename
	originalFilePath := file.Name()

	backupFilePath := generateBackupFilename(originalFilePath)
	logging.D(3, "Creating backup of file '%s' as '%s'", originalFilePath, backupFilePath)

	// Open the backup file for writing
	backupFile, err := os.Create(backupFilePath)
	if err != nil {
		return fmt.Errorf("failed to create backup file: %w", err)
	}
	defer backupFile.Close()

	// Seek to the beginning of the original file
	_, err = file.Seek(0, io.SeekStart)
	if err != nil {
		return fmt.Errorf("failed to seek to beginning of original file: %w", err)
	}

	// Copy the content of the original file to the backup file
	_, err = io.Copy(backupFile, file)
	if err != nil {
		return fmt.Errorf("failed to copy content to backup file: %w", err)
	}

	logging.D(3, "Backup successfully created at '%s'", backupFilePath)
	return nil
}

// generateBackupFilename creates a backup filename by appending "_backup" to the original filename
func generateBackupFilename(originalFilePath string) string {
	ext := filepath.Ext(originalFilePath)
	base := strings.TrimSuffix(originalFilePath, ext)
	return fmt.Sprintf(base + consts.OldTag + ext)
}

// RenameToBackup renames the passed in file
func RenameToBackup(filename string) error {

	if filename == "" {
		logging.E(0, "filename was passed in to backup empty")
	}

	backupName := generateBackupFilename(filename)

	if err := os.Rename(filename, backupName); err != nil {
		return fmt.Errorf("failed to backup filename '%s' to '%s'", filename, backupName)
	}
	return nil
}
package utils

import (
	"bufio"
	"fmt"
	"os"
	"path/filepath"
	logging "tubarr/internal/utils/logging"
)

// appendURLsToFile appends new URLs to the specified file
func AppendURLsToFile(filename string, urls []string) error {
	if len(urls) == 0 {
		return nil
	}

	logging.D(2, "Appending URLs to file %s: %v", filename, urls)

	// Ensure the directory exists
	dir := filepath.Dir(filename)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return fmt.Errorf("failed to create directory for %s: %w", filename, err)
	}

	file, err := os.OpenFile(filename, os.O_APPEND|os.O_WRONLY|os.O_CREATE, 0644)
	if err != nil {
		return fmt.Errorf("failed to open file %s: %w", filename, err)
	}
	defer file.Close()

	written := make(map[string]bool)

	// Load existing URLs from the file into the map
	existingFile, err := os.Open(filename)
	if err == nil {
		defer existingFile.Close()
		scanner := bufio.NewScanner(existingFile)
		for scanner.Scan() {
			written[scanner.Text()] = true
		}
		if err := scanner.Err(); err != nil {
			return fmt.Errorf("error reading existing URLs: %w", err)
		}
	}

	// Append only new URLs to the file
	writer := bufio.NewWriter(file)
	for _, url := range urls {
		if url != "" && !written[url] {
			if _, err := writer.WriteString(url + "\n"); err != nil {
				return fmt.Errorf("error writing URL to file: %w", err)
			}
			written[url] = true
		}
	}

	if err := writer.Flush(); err != nil {
		return fmt.Errorf("error flushing writer: %w", err)
	}

	return nil
}
package utils

import (
	"fmt"
	"path/filepath"
	"runtime"
	"sync"
	consts "tubarr/internal/domain/constants"
	keys "tubarr/internal/domain/keys"

	"github.com/spf13/viper"
)

var (
	Level int = -1 // Pre initialization
	muD   sync.Mutex
	muE   sync.Mutex
	muI   sync.Mutex
	muP   sync.Mutex
	muS   sync.Mutex
)

func E(l int, format string, args ...interface{}) string {

	muE.Lock()
	defer muE.Unlock()
	var msg string

	_, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	tag := fmt.Sprintf("[File: %s : Line: %d] ", file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) {

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.RedError+format+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.RedError + format + tag + "\n")
		}
		fmt.Print(msg)

		Write(consts.LogError, msg, nil)
	}

	return msg
}

func S(l int, format string, args ...interface{}) string {

	muS.Lock()
	defer muS.Unlock()
	var msg string

	_, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	tag := fmt.Sprintf("[File: %s : Line: %d] ", file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) {

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.GreenSuccess+format+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.GreenSuccess + format + tag + "\n")
		}
		fmt.Print(msg)

		Write(consts.LogSuccess, msg, nil)
	}

	return msg
}

func D(l int, format string, args ...interface{}) string {

	muD.Lock()
	defer muD.Unlock()
	var msg string

	_, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	tag := fmt.Sprintf("[File: %s : Line: %d] ", file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) && l != 0 { // Debug messages don't appear by default

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.YellowDebug+format+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.YellowDebug + format + tag + "\n")
		}
		fmt.Print(msg)

		Write(consts.LogSuccess, msg, nil)
	}

	return msg
}

func I(format string, args ...interface{}) string {

	muI.Lock()
	defer muI.Unlock()
	var msg string

	if len(args) != 0 && args != nil {
		msg = fmt.Sprintf(consts.BlueInfo+format+"\n", args...)
	} else {
		msg = fmt.Sprintf(consts.BlueInfo + format + "\n")
	}
	fmt.Print(msg)
	Write(consts.LogInfo, msg, nil)

	return msg
}

func P(format string, args ...interface{}) string {

	muP.Lock()
	defer muP.Unlock()
	var msg string

	if len(args) != 0 && args != nil {
		msg = fmt.Sprintf(format+"\n", args...)
	} else {
		msg = fmt.Sprintf(format + "\n")
	}
	fmt.Print(msg)
	Write(consts.LogBasic, msg, nil)

	return msg
}
package utils

import (
	"fmt"
	"log"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"time"

	"gopkg.in/natefinch/lumberjack.v2"
)

var (
	Loggable   bool = false
	Logger     *log.Logger
	ErrorArray []error
	mu         sync.Mutex

	// Regular expression to match ANSI escape codes
	ansiEscape = regexp.MustCompile(`\x1b\[[0-9;]*m`)
)

// SetupLogging creates and/or opens the log file
func SetupLogging(targetDir string) error {

	logFile := &lumberjack.Logger{
		Filename:   filepath.Join(targetDir, "/tubarr.log"), // Log file path
		MaxSize:    1,                                       // Max size in MB before rotation
		MaxBackups: 3,                                       // Number of backups to retain
		Compress:   true,                                    // Gzip compression
	}

	// Assign lumberjack logger to standard log output
	Logger = log.New(logFile, "", log.LstdFlags)
	Loggable = true

	Logger.Printf(":\n=========== %v ===========\n\n", time.Now().Format(time.RFC1123Z))
	return nil
}

// Write writes error information to the log file
func Write(tag, infoMsg string, err error, args ...interface{}) {

	if Loggable {
		mu.Lock()
		defer mu.Unlock()

		var (
			errMsg,
			info string
		)

		if err != nil {
			if tag == "" {
				errMsg = fmt.Sprintf(err.Error()+"\n", args...)
			} else {
				errMsg = fmt.Sprintf(tag+err.Error()+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(errMsg))

		} else if infoMsg != "" {
			if tag == "" {
				info = fmt.Sprintf(infoMsg+"\n", args...)
			} else {
				info = fmt.Sprintf(tag+infoMsg+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(info))
		}
	}
}

// WriteArray writes an array of error information to the log file
func WriteArray(tag string, infoMsg []string, err []error, args ...interface{}) {
	if Loggable {
		mu.Lock()
		defer mu.Unlock()

		var (
			errMsg,
			info string
		)

		var b strings.Builder

		if len(err) != 0 && err != nil {
			b.Grow(len(err) * 50)
			defer b.Reset()

			var errOut string
			for i, errValue := range err {

				b.WriteString(errValue.Error())
				if i != len(err)-2 {
					b.WriteString("; ")
				}
			}
			errOut = b.String()

			if tag == "" {
				errMsg = fmt.Sprintf(errOut+"\n", args...)
			} else {
				errMsg = fmt.Sprintf(tag+errOut+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(errMsg))

			return
		}

		if len(infoMsg) != 0 && infoMsg != nil {
			b.Grow(len(infoMsg) * 50)
			defer b.Reset()

			var infoOut string
			for i, infoValue := range infoMsg {

				b.WriteString(infoValue)
				if i != len(infoMsg)-2 {
					b.WriteString("; ")
				}
			}
			infoOut = b.String()

			if tag == "" {
				info = fmt.Sprintf(infoOut+"\n", args...)
			} else {
				info = fmt.Sprintf(tag+infoOut+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(info))
		}
	}
}

// stripAnsiCodes removes ANSI escape codes from a string
func stripAnsiCodes(input string) string {
	return ansiEscape.ReplaceAllString(input, "")
}
package utils

import (
	"bufio"
	"context"
	"fmt"
	"os"
	"strings"
	logging "tubarr/internal/utils/logging"
)

var (
	userInputChan = make(chan string) // Channel for user input
	decisionMade  bool
)

// Initialize user input reader in a goroutine
func InitUserInputReader() {
	go func() {
		reader := bufio.NewReader(os.Stdin)
		for {
			input, _ := reader.ReadString('\n')
			userInputChan <- strings.TrimSpace(input)
		}
	}()
}

// PromptMetaReplace displays a prompt message and waits for valid user input.
// The option can be used to tell the program to overwrite all in the queue,
// preserve all in the queue, or move through value by value
func PromptMetaReplace(promptMsg, fileName string, overwriteAll, preserveAll *bool) (string, error) {

	logging.D(3, "Entering PromptUser dialogue...")
	ctx := context.Background()

	if decisionMade {
		// If overwriteAll, return "Y" without waiting
		if *overwriteAll {

			logging.D(3, "Overwrite all is set...")
			return "Y", nil
		} else if *preserveAll {

			logging.D(3, "Preserve all is set...")
			return "N", nil
		}
	}

	fmt.Println()
	logging.I(promptMsg)

	// Wait for user input
	select {
	case response := <-userInputChan:
		if response == "Y" {
			*overwriteAll = true
		}
		decisionMade = true
		return response, nil

	case <-ctx.Done():
		logging.I("Operation canceled during input.")
		return "", fmt.Errorf("operation canceled")
	}
}
package main

import (
	"fmt"
	"os"
	"strings"
	"time"
	"tubarr/internal/cfg"
	build "tubarr/internal/command/builder"
	execute "tubarr/internal/command/execute"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/process"
	browser "tubarr/internal/utils/browser"
	logging "tubarr/internal/utils/logging"

	"github.com/spf13/viper"
)

var startTime time.Time

func init() {
	startTime = time.Now()
	logging.I("tubarr started at: %v", startTime.Format("2006-01-02 15:04:05.00 MST"))
}

// main is the program entrypoint (duh!)
func main() {
	if err := cfg.Execute(); err != nil {
		fmt.Fprintln(os.Stderr, err)
		fmt.Println()
		os.Exit(1)
	}

	if !viper.GetBool("execute") {
		fmt.Println()
		return // Exit early if not meant to execute
	}

	var (
		vDir, jDir string
	)

	// Video directory setup
	if cfg.IsSet(keys.VideoDir) {
		vDir = cfg.GetString(keys.VideoDir)
		if !strings.HasSuffix(vDir, "/") {
			vDir += "/"
		}
		// Create directory if it doesn't exist
		if err := os.MkdirAll(vDir, 0755); err != nil {
			fmt.Println("Failed to create directory structure:", err)
			fmt.Println()
			os.Exit(1)
		}
	} else {
		fmt.Println("No video directory sent in. Skipping logging")
	}

	// Json directory setup
	if cfg.IsSet(keys.JsonDir) {
		jDir = cfg.GetString(keys.JsonDir)
		if !strings.HasSuffix(jDir, "/") {
			jDir += "/"
		}
		// Create directory if it doesn't exist
		if err := os.MkdirAll(jDir, 0755); err != nil {
			fmt.Println("Failed to create directory structure:", err)
			fmt.Println()
			os.Exit(1)
		}
	} else {
		fmt.Println("No video directory sent in. Skipping logging")
	}

	// Setup logging
	if vDir != "" {
		if err := logging.SetupLogging(vDir); err != nil {
			fmt.Printf("\n\nNotice: Log file was not created\nReason: %s\n\n", err)
		}
	} else if jDir != "" {
		if err := logging.SetupLogging(jDir); err != nil {
			fmt.Printf("\n\nNotice: Log file was not created\nReason: %s\n\n", err)
		}
	} else {
		fmt.Println("Directory and file strings were entered empty. Exiting...")
		fmt.Println()
		os.Exit(1)
	}

	// Begin processing
	if err := initProcess(vDir, jDir); err != nil {
		logging.E(0, err.Error())
		os.Exit(1)
	}

	endTime := time.Now()
	logging.I("tubarr finished at: %v", endTime.Format("2006-01-02 15:04:05.00 MST"))
	logging.I("Time elapsed: %.2f seconds", endTime.Sub(startTime).Seconds())
}

// process begins the main tubarr program
func initProcess(vDir, jDir string) error {
	if !cfg.IsSet(keys.ChannelCheckNew) {
		return fmt.Errorf("no channels configured to check")
	}

	requests := browser.GetNewReleases(vDir, jDir)

	if len(requests) == 0 {
		logging.I("No new requests received from crawl")
		return nil
	}

	// Returns DLs that pass checks, should be furnished with JSON directories and paths
	dls := process.ProcessMetaDownloads(requests)

	dlFiles, err := execute.DownloadVideos(dls)
	if err != nil {
		return fmt.Errorf("error downloading new videos: %w", err)
	}

	if cfg.IsSet(keys.MetarrPreset) && len(dlFiles) > 0 {
		mcb := build.NewMetarrCommandBuilder()
		commands, err := mcb.MakeMetarrCommands(dlFiles)
		if err != nil {
			return fmt.Errorf("failed to build metarr commands: %w", err)
		}

		if err := execute.RunMetarr(commands); err != nil {
			return fmt.Errorf("failed to run metarr commands: %w", err)
		}
	}

	return nil
}
