package cfg

import (
	"fmt"
	"strconv"
	"strings"
	"time"
	"tubarr/internal/domain/consts"
	"tubarr/internal/domain/keys"
	"tubarr/internal/interfaces"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"

	"github.com/spf13/cobra"
)

// InitChannelCmds is the entrypoint for initializing channel commands
func initChannelCmds(s interfaces.Store) *cobra.Command {
	channelCmd := &cobra.Command{
		Use:   "channel",
		Short: "Channel commands",
		Long:  "Manage channels with various subcommands like add, delete, and list.",
		RunE: func(cmd *cobra.Command, args []string) error {
			return fmt.Errorf("please specify a subcommand. Use --help to see available subcommands")
		},
	}

	cs := s.GetChannelStore()

	// Add subcommands with dependencies
	channelCmd.AddCommand(addChannelCmd(cs))
	channelCmd.AddCommand(crawlChannelCmd(cs, s))
	channelCmd.AddCommand(deleteChannelCmd(cs))
	channelCmd.AddCommand(listChannelCmd(cs))

	return channelCmd
}

// addChannelCmd adds a new channel into the database
func addChannelCmd(cs interfaces.ChannelStore) *cobra.Command {
	var (
		url, name, vDir, jDir, cookieSource,
		externalDownloader, externalDownloaderArgs, dateFmt, renameFlag string
		filterInput, metaOps, fileSfxReplace []string
		crawlFreq, concurrency               int
	)

	now := time.Now()
	addCmd := &cobra.Command{
		Use:   "add",
		Short: "Add a channel",
		Long:  "Add channel adds a new channel to the database using inputted URLs, names, etc.",
		RunE: func(cmd *cobra.Command, args []string) error {
			switch {
			case vDir == "", url == "":
				return fmt.Errorf("must enter both a video directory and url")
			}

			// Infer empty fields
			if jDir == "" {
				jDir = vDir
			}

			if name == "" {
				name = url
			}

			// Verify filters
			filters, err := verifyChannelOps(filterInput)
			if err != nil {
				return err
			}

			if dateFmt != "" {
				if !dateFormat(dateFmt) {
					return fmt.Errorf("invalid Metarr filename date tag format")
				}
			}

			if len(metaOps) > 0 {
				if metaOps, err = validateMetaOps(metaOps); err != nil {
					return err
				}
			}

			if len(fileSfxReplace) > 0 {
				if fileSfxReplace, err = validateFilenameSuffixReplace(fileSfxReplace); err != nil {
					return err
				}
			}

			if renameFlag != "" {
				if err := setRenameFlag(renameFlag); err != nil {
					return err
				}
			}

			c := &models.Channel{
				URL:  url,
				Name: name,
				VDir: vDir,
				JDir: jDir,

				Settings: models.ChannelSettings{
					CrawlFreq:              crawlFreq,
					Filters:                filters,
					CookieSource:           cookieSource,
					ExternalDownloader:     externalDownloader,
					ExternalDownloaderArgs: externalDownloaderArgs,
					Concurrency:            concurrency,
				},

				MetarrArgs: models.MetarrArgs{
					MetaOps:            metaOps,
					FileDatePfx:        dateFmt,
					RenameStyle:        renameFlag,
					FilenameReplaceSfx: strings.Join(fileSfxReplace, ","),
				},

				LastScan:  now,
				CreatedAt: now,
				UpdatedAt: now,
			}

			id, err := cs.AddChannel(c)
			if err != nil {
				return err
			}

			fmt.Println()
			logging.S(0, "Successfully added channel (ID: %d)\n\nName: %s\nURL: %s\nCrawl Frequency: %d minutes\nFilters: %v\nSettings: %v\nMetarr Operations: %v",
				id, c.Name, c.URL, c.Settings.CrawlFreq, c.Settings.Filters, c.Settings, c.MetarrArgs)
			fmt.Println()
			return nil
		},
	}

	// Primary channel elements
	addCmd.Flags().StringVarP(&url, "url", "u", "", "Channel URL")
	addCmd.Flags().StringVarP(&name, "name", "n", "", "Channel name")
	addCmd.Flags().StringVarP(&vDir, keys.VideoDir, "v", "", "Output directory (videos will be saved here)")
	addCmd.Flags().StringVarP(&jDir, keys.JSONDir, "j", "", "Output directory (videos will be saved here)")

	// Channel settings
	addCmd.Flags().IntVar(&crawlFreq, keys.CrawlFreq, 30, "How often to check for new videos (in minutes)")
	addCmd.Flags().IntVarP(&concurrency, keys.Concurrency, "l", 3, "Output directory (videos will be saved here)")
	addCmd.Flags().StringSliceVar(&filterInput, keys.FilterOpsInput, []string{}, "Filter video downloads (e.g. 'title:contains:frogs' ignores downloads without 'frogs' in the title metafield)")
	addCmd.Flags().StringVar(&cookieSource, keys.CookieSource, "", "Please enter the browser to grab cookies from for sites requiring authentication (e.g. 'firefox')")
	addCmd.Flags().StringVar(&externalDownloader, keys.ExternalDownloader, "", "External downloader option (e.g. 'aria2c')")
	addCmd.Flags().StringVar(&externalDownloaderArgs, keys.ExternalDownloaderArgs, "", "External downloader arguments (e.g. '\"-x 16 -s 16\"')")

	// Metarr operations
	addCmd.Flags().StringSliceVar(&fileSfxReplace, keys.InputFilenameReplaceSfx, nil, "Replace a filename suffix element in Metarr")
	addCmd.Flags().StringVar(&renameFlag, keys.RenameStyle, "", "Rename style for Metarr (e.g. 'spaces')")
	addCmd.Flags().StringVar(&dateFmt, keys.InputFileDatePfx, "", "Prefix a filename with a particular date tag (ymd format where Y means yyyy and y means yy)")
	addCmd.Flags().StringSliceVar(&metaOps, keys.MetaOps, nil, "Meta operations to perform in Metarr")

	return addCmd
}

// deleteChannelCmd deletes a channel from the database
func deleteChannelCmd(cs interfaces.ChannelStore) *cobra.Command {
	var (
		url, name string
	)

	delCmd := &cobra.Command{
		Use:   "delete",
		Short: "Delete channels",
		Long:  "Delete a channel by name or URL",
		RunE: func(cmd *cobra.Command, args []string) error {
			if url == "" && name == "" {
				return fmt.Errorf("must enter both a video directory and url")
			}

			var key, val string
			if url != "" {
				key = consts.QChanURL
				val = url
			} else if name != "" {
				key = consts.QChanName
				val = name
			}

			if err := cs.DeleteChannel(key, val); err != nil {
				return err
			}
			logging.S(0, "Successfully deleted channel with key '%s' and value '%s'", key, val)
			return nil
		},
	}

	// Primary channel elements
	delCmd.Flags().StringVarP(&url, "url", "u", "", "Channel URL")
	delCmd.Flags().StringVarP(&name, "name", "n", "", "Channel name")

	return delCmd
}

// listChannelCmd returns a list of channels in the database
func listChannelCmd(cs interfaces.ChannelStore) *cobra.Command {
	listCmd := &cobra.Command{
		Use:   "list",
		Short: "List all channels",
		Long:  "Lists all channels currently saved in the database",
		RunE: func(cmd *cobra.Command, args []string) error {
			channels, err, hasRows := cs.ListChannels()
			if !hasRows {
				logging.I("No entries in the database")
				return nil
			}
			if err != nil {
				return err
			}

			for _, c := range channels {
				fmt.Printf("\nChannel ID: %d\n\nName: %s\nURL: %s\nCrawl Frequency: %d minutes\nFilters: %v\n",
					c.ID, c.Name, c.URL, c.Settings.CrawlFreq, c.Settings.Filters)

				// Display Metarr operations if they exist
				if len(c.MetarrArgs.MetaOps) > 0 {
					fmt.Printf("Metarr Operations:\n")
					for _, op := range c.MetarrArgs.MetaOps {
						fmt.Printf("  - %s\n", op)
					}
				}
				if c.MetarrArgs.FileDatePfx != "" {
					fmt.Printf("Filename Date Format: %s\n", c.MetarrArgs.FileDatePfx)
				}
				if c.MetarrArgs.RenameStyle != "" {
					fmt.Printf("Rename Style: %s\n", c.MetarrArgs.RenameStyle)
				}
				if c.MetarrArgs.FilenameReplaceSfx != "" {
					fmt.Printf("Filename Suffix Replace: %s\n", c.MetarrArgs.FilenameReplaceSfx)
				}
			}
			return nil
		},
	}

	return listCmd
}

// crawlChannelCmd initiates a crawl of a given channel
func crawlChannelCmd(cs interfaces.ChannelStore, s interfaces.Store) *cobra.Command {
	var (
		url, name string
		id        int
		key, val  string
	)

	crawlCmd := &cobra.Command{
		Use:   "crawl",
		Short: "Crawl a channel for new URLs",
		Long:  "Initiate a crawl for new URLs of a channel that have not yet been downloaded",
		RunE: func(cmd *cobra.Command, args []string) error {

			switch {
			case url != "":
				key = consts.QChanURL
				val = url
			case name != "":
				key = consts.QChanName
				val = name
			case id != 0:
				key = consts.QChanID
				val = strconv.Itoa(id)
			default:
				return fmt.Errorf("please enter either a URL or name")
			}

			if err := cs.CrawlChannel(key, val, s); err != nil {
				return err
			}
			return nil
		},
	}

	// Primary channel elements
	crawlCmd.Flags().StringVarP(&url, "url", "u", "", "Channel URL")
	crawlCmd.Flags().StringVarP(&name, "name", "n", "", "Channel name")
	crawlCmd.Flags().IntVarP(&id, "id", "i", 0, "Channel ID in the DB")

	return crawlCmd
}

// Private //////////////////////////////////////////////////////////////////////////////////////////

// verifyChannelOps verifies that the user inputted filters are valid
func verifyChannelOps(ops []string) ([]models.DLFilters, error) {

	var filters = make([]models.DLFilters, 0, len(ops))
	for _, op := range ops {
		split := strings.Split(op, ":")
		if len(split) < 3 {
			return nil, fmt.Errorf("please enter filters in the format 'field:filter_type:value' (e.g. 'title:omit:frogs' ignores videos with frogs in the metatitle)")
		}
		switch len(split) {
		case 3:
			switch split[1] {
			case "contains", "omit":
				filters = append(filters, models.DLFilters{
					Field: split[0],
					Type:  split[1],
					Value: split[2],
				})
			default:
				return nil, fmt.Errorf("please enter a filter type of either 'contains' or 'omit'")
			}
		case 2:
			switch split[1] {
			case "contains", "omit":
				filters = append(filters, models.DLFilters{
					Field: split[0],
					Type:  split[1],
				})
			default:
				return nil, fmt.Errorf("please enter a filter type of either 'contains' or 'omit'")
			}
		default:
			return nil, fmt.Errorf("invalid filter. Valid examples: 'title:contains:frogs','date:omit' (contains only metatitles with frogs, and omits downloads including a date metafield)")

		}
	}
	return filters, nil
}
package cfg

import (
	"fmt"
	"tubarr/internal/domain/consts"
	"tubarr/internal/interfaces"
	"tubarr/internal/utils/logging"

	"github.com/spf13/cobra"
)

// InitChannelCmds is the entrypoint for initializing channel commands
func initVideoCmds(s interfaces.Store) *cobra.Command {
	vidCmd := &cobra.Command{
		Use:   "video",
		Short: "Video commands",
		Long:  "Manage videos with various subcommands like delete and list.",
		RunE: func(cmd *cobra.Command, args []string) error {
			return fmt.Errorf("please specify a subcommand. Use --help to see available subcommands")
		},
	}

	vs := s.GetVideoStore()

	// Add subcommands with dependencies
	vidCmd.AddCommand(deleteVideoCmd(vs))

	return vidCmd
}

// deleteVideoCmd deletes a channel from the database
func deleteVideoCmd(vs interfaces.VideoStore) *cobra.Command {
	var url string

	delCmd := &cobra.Command{
		Use:   "delete",
		Short: "Delete video entry",
		Long:  "Delete a video entry from the database by URL",
		RunE: func(cmd *cobra.Command, args []string) error {
			if url == "" {
				return fmt.Errorf("must enter a URL")
			}

			if err := vs.DeleteVideo(consts.QVidURL, url); err != nil {
				return err
			}
			logging.S(0, "Successfully deleted video with URL '%s'", url)
			return nil
		},
	}

	// Primary channel elements
	delCmd.Flags().StringVarP(&url, "url", "u", "", "Channel URL")

	return delCmd
}
package cfg

import (
	"tubarr/internal/domain/keys"

	"github.com/spf13/viper"
)

// initAllFileTransformers initializes user flag settings for transformations applying to all files
func initAllFileTransformers() {

	// Prefix file with metafield
	rootCmd.PersistentFlags().StringSlice(keys.MFilenamePfx, nil, "Adds a specified metatag's value onto the start of the filename")
	viper.BindPFlag(keys.MFilenamePfx, rootCmd.PersistentFlags().Lookup(keys.MFilenamePfx))

	// Prefix files with date tag
	rootCmd.PersistentFlags().String(keys.InputFileDatePfx, "", "Looks for dates in metadata to prefix the video with. (date:format [e.g. Ymd for yyyy-mm-dd])")
	viper.BindPFlag(keys.InputFileDatePfx, rootCmd.PersistentFlags().Lookup(keys.InputFileDatePfx))

	// Rename convention
	rootCmd.PersistentFlags().StringP(keys.RenameStyle, "r", "fixes-only", "Rename flag (spaces, underscores, fixes-only, or skip)")
	viper.BindPFlag(keys.RenameStyle, rootCmd.PersistentFlags().Lookup(keys.RenameStyle))

	// Replace filename suffix
	rootCmd.PersistentFlags().StringSliceVar(&filenameReplaceSuffixInput, keys.InputFilenameReplaceSfx, nil, "Replaces a specified suffix on filenames. (suffix:replacement)")
	viper.BindPFlag(keys.InputFilenameReplaceSfx, rootCmd.PersistentFlags().Lookup(keys.InputFilenameReplaceSfx))

	// Output directory (can be external)
	rootCmd.PersistentFlags().StringP(keys.MoveOnComplete, "o", "", "Move files to given directory on program completion")
	viper.BindPFlag(keys.MoveOnComplete, rootCmd.PersistentFlags().Lookup(keys.MoveOnComplete))
}

// initMetaTransformers initializes user flag settings for manipulation of metadata
func initMetaTransformers() {

	// Metadata transformations
	rootCmd.PersistentFlags().StringSlice(keys.MetaOps, nil, "Metadata operations (field:operation:value) - e.g. title:set:New Title, description:prefix:Draft-, tags:append:newtag")
	viper.BindPFlag(keys.MetaOps, rootCmd.PersistentFlags().Lookup(keys.MetaOps))

	// Prefix or append description fields with dates
	rootCmd.PersistentFlags().Bool(keys.MDescDatePfx, false, "Adds the date to the start of the description field.")
	viper.BindPFlag(keys.MDescDatePfx, rootCmd.PersistentFlags().Lookup(keys.MDescDatePfx))

	rootCmd.PersistentFlags().Bool(keys.MDescDateSfx, false, "Adds the date to the end of the description field.")
	viper.BindPFlag(keys.MDescDateSfx, rootCmd.PersistentFlags().Lookup(keys.MDescDateSfx))

	rootCmd.PersistentFlags().String(keys.MetaPurge, "", "Delete metadata files (e.g. .json, .nfo) after the video is successfully processed")
	viper.BindPFlag(keys.MetaPurge, rootCmd.PersistentFlags().Lookup(keys.MetaPurge))
}

// initVideoTransformers initializes user flag settings for transformation of video files
func initVideoTransformers() {

	// Output extension type
	rootCmd.PersistentFlags().String(keys.OutputFiletypeInput, "", "File extension to output files as (mp4 works best for most media servers)")
	viper.BindPFlag(keys.OutputFiletypeInput, rootCmd.PersistentFlags().Lookup(keys.OutputFiletypeInput))
}
package cfg

import (
	"fmt"
	"tubarr/internal/domain/keys"
	"tubarr/internal/interfaces"

	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

var rootCmd = &cobra.Command{
	Use:   "tubarr",
	Short: "Tubarr is a video and metatagging tool",
	RunE: func(cmd *cobra.Command, args []string) error {
		if cmd.Flags().Lookup("help").Changed {
			return nil // Stop further execution if help is invoked
		}
		if len(args) == 0 {
			viper.Set("check_channels", true)
		}
		viper.Set("execute", true)
		return nil
	},
}

// Execute adds all child commands to the root command and sets flags appropriately.
func Execute() error {

	initAllFileTransformers()
	initMetaTransformers()
	initVideoTransformers()

	verify()

	return rootCmd.Execute()
}

// InitCommands initializes all commands and their flags
func InitCommands(s interfaces.Store) {

	// Add channel commands as a subcommand of root
	rootCmd.AddCommand(initChannelCmds(s))
	rootCmd.AddCommand(initVideoCmds(s))

	// Set up any root-level flags here if needed
	rootCmd.PersistentFlags().Int("debug", 0, "Debug level (0-5)")
	viper.BindPFlag("debug", rootCmd.PersistentFlags().Lookup("debug"))
}

// verify verifies that the user input flags are valid
func verify() error {
	if viper.IsSet(keys.OutputFiletype) {
		ext := viper.GetString(keys.OutputFiletype)
		if !verifyOutputFiletype(ext) {
			return fmt.Errorf("invalid output filetype '%s'", ext)
		}
	}

	if viper.IsSet(keys.MetaPurge) {
		purge := viper.GetString(keys.MetaPurge)
		if !verifyPurgeMetafiles(purge) {
			return fmt.Errorf("invalid meta purge type '%s'", purge)
		}
	}

	verifyConcurrencyLimit()
	return nil
}
package cfg

import (
	"fmt"
	"strings"
	"tubarr/internal/utils/logging"
)

var (
	filenameReplaceSuffixInput []string
)

// validateMetaOps parses the meta transformation operations
func validateMetaOps(metaOps []string) ([]string, error) {
	if len(metaOps) == 0 {
		logging.I("No meta operations passed in to verification")
		return metaOps, nil
	}

	logging.D(1, "Validating meta operations...")
	valid := make([]string, 0, len(metaOps))

	for _, m := range metaOps {
		split := strings.Split(m, ":")
		switch len(split) {
		case 3:
			switch split[1] {
			case "append", "copy-to", "paste-from", "prefix", "trim-prefix", "trim-suffix", "replace", "set":
				valid = append(valid, m)
			default:
				return nil, fmt.Errorf("invalid meta operation '%s'", split[1])
			}
		case 4:
			switch split[1] {
			case "date-tag":
				if split[2] == "prefix" || split[2] == "suffix" {
					if dateFormat(split[3]) {
						valid = append(valid, m)
					}
				} else {
					return nil, fmt.Errorf("invalid date tag location '%s', use prefix or suffix", split[2])
				}
			}
		default:
			return nil, fmt.Errorf("invalid meta op '%s'", m)
		}
	}
	if len(valid) != 0 {
		return valid, nil
	} else {
		return nil, fmt.Errorf("no valid meta operations")
	}
}

// validateFilenameSuffixReplace checks if the input format for filename suffix replacement is valid
func validateFilenameSuffixReplace(fileSfxReplace []string) ([]string, error) {
	valid := make([]string, 0, len(fileSfxReplace))

	for _, pair := range fileSfxReplace {
		parts := strings.Split(pair, ":")
		if len(parts) < 2 {
			return nil, fmt.Errorf("invalid use of filename-replace-suffix, values must be written as (suffix:replacement)")
		}
		valid = append(valid, pair)
	}
	return valid, nil
}

// setRenameFlag sets the rename style to apply
func setRenameFlag(flag string) error {

	// Trim whitespace for more robust validation
	flag = strings.TrimSpace(flag)
	flag = strings.ToLower(flag)

	switch flag {
	case "spaces", "space", "underscores", "underscore", "fixes", "fix", "fixes-only", "fixesonly":
		return nil
	default:
		return fmt.Errorf("'spaces', 'underscores' or 'fixes-only' not selected for renaming style, skipping these modifications")
	}
}

// dateEnum returns the date format enum type
func dateFormat(dateFmt string) bool {
	if len(dateFmt) > 2 {
		switch dateFmt {
		case "Ymd", "ymd", "Ydm", "ydm", "dmY", "dmy", "mdY", "mdy", "md", "dm":
			return true
		}
	}
	logging.E(0, "Invalid date format entered as '%s', please enter up to three characters (where 'Y' is yyyy and 'y' is yy)")
	return false
}
package cfg

import (
	"strings"
	"tubarr/internal/domain/consts"
	"tubarr/internal/domain/keys"
	"tubarr/internal/utils/logging"

	"github.com/spf13/viper"
)

// verifyConcurrencyLimit checks and ensures correct concurrency limit input
func verifyConcurrencyLimit() {
	maxConcurrentProcesses := viper.GetInt(keys.Concurrency)

	switch {
	case maxConcurrentProcesses < 1:
		maxConcurrentProcesses = 1
		logging.E(2, "Max concurrency set too low, set to minimum value: %d", maxConcurrentProcesses)
	default:
		logging.I("Max concurrency: %d", maxConcurrentProcesses)
	}
	viper.Set(keys.Concurrency, maxConcurrentProcesses)
}

// Verify the output filetype is valid for FFmpeg
func verifyOutputFiletype(o string) bool {
	o = strings.TrimSpace(o)

	if !strings.HasPrefix(o, ".") {
		o = "." + o
		viper.Set(keys.OutputFiletype, o)
	}

	valid := false
	for _, ext := range consts.AllVidExtensions {
		if o != ext {
			continue
		} else {
			valid = true
			break
		}
	}

	if valid {
		logging.I("Outputting files as %s", o)
		return true
	}
	return false
}

// verifyPurgeMetafiles checks and sets the type of metafile purge to perform
func verifyPurgeMetafiles(purgeType string) bool {

	purgeType = strings.TrimSpace(purgeType)
	purgeType = strings.ToLower(purgeType)
	purgeType = strings.ReplaceAll(purgeType, ".", "")

	switch purgeType {
	case "all", "json", "nfo":
		return true
	}
	return false
}
package cfg

import (
	"github.com/spf13/viper"
)

// Set sets the value for the key in the override register. Set is case-insensitive for a key. Will be used instead of values obtained via flags, config file, ENV, default, or key/value store.
func Set(key string, value any) {
	viper.Set(key, value)
}

// Get can retrieve any value given the key to use. Get is case-insensitive for a key. Get has the behavior of returning the value associated with the first place from where it is set. Viper will check in the following order: override, flag, env, config file, key/value store, default
// Get returns an interface. For a specific value use one of the Get____ methods.
func Get(key string) any {
	return viper.Get(key)
}

// GetBool returns the value associated with the key as a boolean.
func GetBool(key string) bool {
	return viper.GetBool(key)
}

// GetInt returns the value associated with the key as an integer.
func GetInt(key string) int {
	return viper.GetInt(key)
}

// GetUint64 returns the value associated with the key as an unsigned integer.
func GetUint64(key string) uint64 {
	return viper.GetUint64(key)
}

// GetFloat64 returns the value associated with the key as a float64.
func GetFloat64(key string) float64 {
	return viper.GetFloat64(key)
}

// GetString returns the value associated with the key as a string.
func GetString(key string) string {
	return viper.GetString(key)
}

// GetStringSlice returns the value associated with the key as a slice of strings.
func GetStringSlice(key string) []string {
	return viper.GetStringSlice(key)
}

// IsSet checks to see if the key has been set in any of the data locations.
// IsSet is case-insensitive for a key.
func IsSet(key string) bool {
	return viper.IsSet(key)
}
package command

import (
	"bytes"
	"fmt"
	"os"
	"os/exec"
	"strings"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

// ExecuteMetaDownload initiates a yt-dlp meta download command
func ExecuteMetaDownload(v *models.Video, cmd *exec.Cmd) error {
	if cmd == nil {
		return fmt.Errorf("no command built for URL %s", v.URL)
	}

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	err := cmd.Run()
	if err != nil {
		return fmt.Errorf("yt-dlp error for %s: %v\nStderr: %s", v.URL, err, stderr.String())
	}

	// Find the line containing the JSON path
	outputLines := strings.Split(strings.TrimSpace(stdout.String()), "\n")
	var jsonPath string

	fileLine := outputLines[len(outputLines)-1]
	logging.D(1, "File line captured as: %v", fileLine)

	_, jsonPath, found := strings.Cut(fileLine, ": ")
	if !found || jsonPath == "" {
		logging.D(1, "Full stdout: %s", stdout.String())
		logging.D(1, "Full stderr: %s", stderr.String())
		return fmt.Errorf("could not find JSON file path in output for %s", v.URL)
	}

	v.JPath = jsonPath

	// Verify the file exists
	if _, err := os.Stat(v.JPath); err != nil {
		return fmt.Errorf("JSON file not found at %s: %v", v.JPath, err)
	}

	logging.I("Successfully saved JSON file to '%s'", v.JPath)
	return nil
}
package command

import (
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"time"
	"tubarr/internal/domain/consts"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

// ExecuteVideoDownload takes in a URL and downloads it
func ExecuteVideoDownload(v *models.Video, cmd *exec.Cmd) (bool, error) {
	if v == nil {
		return false, fmt.Errorf("request model received nil")
	}

	if cmd == nil {
		return false, fmt.Errorf("command is nil for model with URL '%s'", v.URL)
	}

	// Create pipes for stdout and stderr
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		logging.E(0, "Failed to create stdout pipe: %v", err)
		return false, err
	}
	stderr, err := cmd.StderrPipe()
	if err != nil {
		logging.E(0, "Failed to create stderr pipe: %v", err)
		return false, err
	}

	// Channel to receive the output filename
	filenameChan := make(chan string, 1)
	doneChan := make(chan struct{})
	errChan := make(chan error, 1)

	// Start output scanner in goroutine
	go func() {
		defer close(doneChan)
		scanner := bufio.NewScanner(io.MultiReader(stdout, stderr))
		for scanner.Scan() {
			line := scanner.Text()
			fmt.Println(line)

			// Capture the actual output filename
			if strings.HasPrefix(line, "/") {
				lineExt := filepath.Ext(line)

				for _, ext := range consts.AllVidExtensions {
					logging.D(2, "Comparing extension %s to %s", ext, lineExt)
					if lineExt == ext {
						select {
						case filenameChan <- line:
						default:
							logging.D(1, "Channel already has a filename")
						}
						break
					}
				}
			}
		}
		if err := scanner.Err(); err != nil {
			errChan <- fmt.Errorf("scanner error: %v", err)
		}
	}()

	// Start command
	logging.I("Executing download command: %s", cmd.String())
	if err := cmd.Start(); err != nil {
		close(filenameChan)
		return false, fmt.Errorf("failed to start download: %v", err)
	}

	// Wait for command to complete
	if err := cmd.Wait(); err != nil {
		close(filenameChan)
		return false, fmt.Errorf("download failed: %v", err)
	}

	// Wait for scanner to finish
	<-doneChan

	// Check for scanner errors
	select {
	case err := <-errChan:
		if err != nil {
			return false, err
		}
	default:
	}

	// Get output filename
	var outputFilename string
	select {
	case filename := <-filenameChan:
		outputFilename = filename
		close(filenameChan)
	default:
		close(filenameChan)
		return false, fmt.Errorf("no output filename captured for URL: %s", v.URL)
	}

	// Short wait time for filesystem sync
	time.Sleep(1 * time.Second)

	// Set filenames
	v.VPath = outputFilename

	// Verify the download
	if err := verifyDownload(v.VPath, v.JPath); err != nil {
		return false, fmt.Errorf("download verification failed: %v", err)
	}

	logging.S(0, "Successfully downloaded files:\nVideo: %s\nJSON: %s",
		v.VPath, v.JPath)

	return true, nil
}

// verifyDownload checks if the specified files exist and are non-empty
func verifyDownload(videoPath, jsonPath string) error {
	// Check video file
	videoInfo, err := os.Stat(videoPath)
	if err != nil {
		return fmt.Errorf("video file verification failed: %w", err)
	}
	if videoInfo.Size() == 0 {
		return fmt.Errorf("video file is empty: %s", videoPath)
	}

	// Check JSON file
	jsonData, err := os.ReadFile(jsonPath)
	if err != nil {
		return fmt.Errorf("failed to read JSON file: %w", err)
	}

	if !json.Valid(jsonData) {
		return fmt.Errorf("invalid JSON content in file: %s", jsonPath)
	}

	return nil
}
package command

import (
	"os/exec"
	"strconv"
	"strings"
	"tubarr/internal/cfg"
	"tubarr/internal/domain/keys"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"
)

type MetarrCommand struct {
	Video *models.Video
}

// NewMetarrCommandBuilder returns a new command builder to build and run Metarr commands
func NewMetarrCommandBuilder(v *models.Video) *MetarrCommand {
	return &MetarrCommand{
		Video: v,
	}
}

// MakeMetarrCommands builds the command list for Metarr
func (mc *MetarrCommand) MakeMetarrCommands() (*exec.Cmd, error) {
	// Get merged arguments from both sources
	args := mc.mergeArguments()

	cmd := exec.Command("metarr", args...)
	return cmd, nil
}

// mergeArguments combines arguments from both Viper config and model settings
func (mc *MetarrCommand) mergeArguments() []string {

	baseArgs := []string{
		"-V", mc.Video.VPath,
		"-J", mc.Video.JPath,
	}

	// Map to deduplicate meta
	metaOpsMap := make(map[string]struct{})

	// Helper to add meta operations with deduplication
	addMetaOps := func(ops []string) {
		for _, op := range ops {
			metaOpsMap[op] = struct{}{}
		}
	}

	// Add model-based meta operations
	if mc.Video.MetarrArgs.MetaOps != nil {
		logging.D(2, "Adding MetarrArgs meta-ops: %v", mc.Video.MetarrArgs.MetaOps)
		addMetaOps(mc.Video.MetarrArgs.MetaOps)
	}

	// Add viper meta operations
	if cfg.IsSet(keys.MetaOps) {
		viperOps := cfg.GetStringSlice(keys.MetaOps)
		logging.D(2, "Adding Viper meta-ops: %v", viperOps)
		addMetaOps(viperOps)
	}

	// Use map for other unique arguments
	argMap := make(map[string]string)

	// Add other model-based arguments
	if mc.Video.MetarrArgs.FileDatePfx != "" {
		argMap["--filename-date-tag"] = mc.Video.MetarrArgs.FileDatePfx
	}
	if mc.Video.MetarrArgs.RenameStyle != "" {
		argMap["-r"] = mc.Video.MetarrArgs.RenameStyle
	}
	if mc.Video.MetarrArgs.FilenameReplaceSfx != "" {
		argMap["--filename-replace-suffix"] = mc.Video.MetarrArgs.FilenameReplaceSfx
	}

	// Add Viper config arguments
	if cfg.IsSet(keys.InputFileDatePfx) {
		argMap["--filename-date-tag"] = cfg.GetString(keys.InputFileDatePfx)
	}

	if cfg.IsSet(keys.RenameStyle) {
		argMap["-r"] = cfg.GetString(keys.RenameStyle)
	}

	if cfg.IsSet(keys.InputFilenameReplaceSfx) {
		replacements := cfg.GetStringSlice(keys.InputFilenameReplaceSfx)
		if len(replacements) > 0 {
			argMap["--filename-replace-suffix"] = replacements[len(replacements)-1]
		}
	}

	if cfg.IsSet(keys.MoveOnComplete) {
		argMap["-o"] = cfg.GetString(keys.MoveOnComplete)
	}

	if cfg.IsSet(keys.OutputFiletype) {
		argMap["--ext"] = cfg.GetString(keys.OutputFiletype)
	}

	if cfg.IsSet(keys.DebugLevel) {
		argMap["--debug"] = strconv.Itoa(cfg.GetInt(keys.DebugLevel))
	}

	// Build final argument list
	args := baseArgs

	// Add regular arguments from map
	for flag, value := range argMap {
		args = append(args, flag, value)
	}

	var uniqueMetaOps []string
	for op := range metaOpsMap {
		uniqueMetaOps = append(uniqueMetaOps, op)
	}

	// Add all unique meta operations
	for _, op := range uniqueMetaOps {
		args = append(args, "--meta-ops", op)
	}

	logging.D(1, "Final Metarr arguments: %s", strings.Join(args, " "))
	logging.D(2, "Unique meta operations: %v", uniqueMetaOps)

	return args
}
package command

import (
	"fmt"
	"os"
	"os/exec"
	logging "tubarr/internal/utils/logging"
)

// RunMetarr runs a Metarr command with a built argument list
func RunMetarr(cmd *exec.Cmd) error {
	var err error = nil
	if len(cmd.String()) == 0 {
		return fmt.Errorf("command string is empty? %s", cmd.String())
	}
	logging.I("Running command: %s", cmd.String())

	cmd.Stderr = os.Stderr
	cmd.Stdout = os.Stdout
	cmd.Stdin = os.Stdin

	if err = cmd.Run(); err != nil {
		logging.E(0, "Encountered error running command '%s': %w", cmd.String(), err)
	}
	return err // Returns nil by default unless an error is grabbed
}
package command

import (
	"os/exec"
	"strconv"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

type MetaDLRequest struct {
	Videos *models.Video
}

func NewMetaDLRequest(videos *models.Video) *MetaDLRequest {
	return &MetaDLRequest{
		Videos: videos,
	}
}

// RequestMetaCommand builds and returns the argument for downloading metadata
// files for the given URL
func (mdl *MetaDLRequest) RequestMetaCommand() *exec.Cmd {

	v := mdl.Videos
	var buildArgs []string
	buildArgs = append(buildArgs, "--skip-download", "--write-info-json", "-P", v.JDir)

	if v.Settings.CookieSource != "" {
		buildArgs = append(buildArgs, "--cookies-from-browser", v.Settings.CookieSource)
	}

	if v.Settings.Retries != 0 {
		buildArgs = append(buildArgs, "--retries", strconv.Itoa(v.Settings.Retries))
	}

	if v.Settings.ExternalDownloader != "" {
		buildArgs = append(buildArgs, "--external-downloader", v.Settings.ExternalDownloader)
	}

	if v.Settings.ExternalDownloaderArgs != "" {
		buildArgs = append(buildArgs, "--external-downloader-args", v.Settings.ExternalDownloaderArgs)
	}

	//buildArgs = append(buildArgs, "--quiet")
	buildArgs = append(buildArgs, "--restrict-filenames", "-o", "%(title)s.%(ext)s")

	args := buildArgs
	args = append(args, v.URL)

	cmd := exec.Command("yt-dlp", args...)
	logging.D(3, "Built command for URL '%s':\n%v", v.URL, cmd.String())

	return cmd
}
package command

import (
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"tubarr/internal/cfg"
	keys "tubarr/internal/domain/keys"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"
)

type VideoDLRequest struct {
	Video *models.Video
}

func NewVideoDLRequest(v *models.Video) *VideoDLRequest {
	return &VideoDLRequest{
		Video: v,
	}
}

// BuildVideoFetchCommand builds the command for yt-dlp
func (vf *VideoDLRequest) VideoFetchCommand() (*exec.Cmd, error) {
	if vf.Video == nil {
		return nil, fmt.Errorf("model passed in null, returning no command")
	}

	if vf.Video.VDir == "" {
		return nil, fmt.Errorf("output directory entered blank")
	}

	v := vf.Video

	if _, err := exec.LookPath("yt-dlp"); err != nil {
		logging.E(0, "yt-dlp command not found: %w", err)
		os.Exit(1)
	}

	if v.URL == "" {
		return nil, fmt.Errorf("url passed in blank")
	}

	var args []string
	args = append(args, "--restrict-filenames", "-o", filepath.Join(v.VDir, "%(title)s.%(ext)s"))

	if v.Settings.Retries > 0 {
		args = append(args, "--retries", cfg.GetString(keys.DLRetries))
	}

	args = append(args, "--print", "after_move:%(filepath)s")

	if v.Settings.CookieSource != "" {
		args = append(args, "--cookies-from-browser", v.Settings.CookieSource)
	}

	if v.Settings.ExternalDownloader != "" {
		args = append(args, "--external-downloader", v.Settings.ExternalDownloader)
	}

	if v.Settings.ExternalDownloaderArgs != "" {
		args = append(args, "--external-downloader-args", v.Settings.ExternalDownloaderArgs)
	}

	args = append(args, v.URL)

	logging.D(1, "Built argument list: %v", args)
	cmd := exec.Command("yt-dlp", args...)

	logging.D(1, "Created download command for URL '%s', for command %s", v.URL, cmd)

	return cmd, nil
}
package database

import (
	"database/sql"
	"fmt"
	"log"
	"os"
	"path/filepath"

	_ "github.com/mattn/go-sqlite3"
)

var db *sql.DB

func init() {
	const (
		tDir  = ".tubarr"
		tFile = "tubarr.db"
	)

	dir, err := os.UserHomeDir()
	if err != nil {
		log.Fatalf("failed to get home directory")
	}

	dir = filepath.Join(dir, tDir)
	if err := os.MkdirAll(dir, 0755); err != nil {
		log.Fatalf("failed to make directories: %v", err)
	}

	path := filepath.Join(dir, tFile)

	db, err = sql.Open("sqlite3", path)
	if err != nil {
		log.Fatalf("failed to open database at path '%s': %v", path, err)
	}

	if err := initTables(db); err != nil {
		log.Fatalf("failed to initialize tables: %v", err)
	}
}

// GrabDB returns the database
func GrabDB() *sql.DB {
	return db
}

// initTables initializes the SQL tables
func initTables(db *sql.DB) error {
	tx, err := db.Begin()
	if err != nil {
		return fmt.Errorf("failed to begin transaction: %w", err)
	}
	defer tx.Rollback()

	if err := initChannelsTable(tx); err != nil {
		return err
	}

	if err := initVideosTable(tx); err != nil {
		return err
	}

	if err := initDownloadsTable(tx); err != nil {
		return err
	}

	return tx.Commit()
}
package database

import (
	"database/sql"
	"fmt"
)

// initChannelsTable intializes channel tables
func initChannelsTable(tx *sql.Tx) error {
	query := `
    CREATE TABLE IF NOT EXISTS channels (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        url TEXT NOT NULL UNIQUE,
        name TEXT UNIQUE,
        video_directory TEXT,
        json_directory TEXT,
        settings JSON,
        metarr JSON,
        last_scan TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    CREATE INDEX IF NOT EXISTS idx_channels_url ON channels(url);
    CREATE INDEX IF NOT EXISTS idx_channels_video_directory ON channels(video_directory);
    CREATE INDEX IF NOT EXISTS idx_channels_json_directory ON channels(json_directory);
    CREATE INDEX IF NOT EXISTS idx_channels_name ON channels(name);
    CREATE INDEX IF NOT EXISTS idx_channels_settings ON channels(settings);
    CREATE INDEX IF NOT EXISTS idx_channels_last_scan ON channels(last_scan);
    `
	if _, err := tx.Exec(query); err != nil {
		return fmt.Errorf("failed to create channels table: %w", err)
	}
	return nil
}

// initVideosTable initializes videos tables
func initVideosTable(tx *sql.Tx) error {
	query := `
    CREATE TABLE IF NOT EXISTS videos (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        channel_id INTEGER REFERENCES channels(id),
        downloaded INTEGER DEFAULT 0,
        url TEXT NOT NULL UNIQUE,
        title TEXT,
        description TEXT,
        video_directory TEXT,
        json_directory TEXT,
        upload_date TIMESTAMP,
        metadata JSON,
        metarr JSON,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    CREATE INDEX IF NOT EXISTS idx_videos_channel ON videos(channel_id);
    CREATE INDEX IF NOT EXISTS idx_videos_url ON videos(url);
    CREATE INDEX IF NOT EXISTS idx_videos_upload_date ON videos(upload_date);
    `
	if _, err := tx.Exec(query); err != nil {
		return fmt.Errorf("failed to create videos table: %w", err)
	}
	return nil
}

// initDownloadsTable initializes downloads table
func initDownloadsTable(tx *sql.Tx) error {
	query := `
    CREATE TABLE IF NOT EXISTS downloads (
        id INTEGER PRIMARY KEY,
        video_id INTEGER REFERENCES videos(id),
        status TEXT NOT NULL CHECK(status IN ('pending', 'downloading', 'completed', 'failed')),
        file_path TEXT,
        file_size INTEGER,
        started_at TIMESTAMP,
        completed_at TIMESTAMP,
        error_message TEXT,
        settings_used JSON,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    CREATE INDEX IF NOT EXISTS idx_downloads_status ON downloads(status);
    CREATE INDEX IF NOT EXISTS idx_downloads_video ON downloads(video_id);
    `
	if _, err := tx.Exec(query); err != nil {
		return fmt.Errorf("failed to create downloads table: %w", err)
	}
	return nil
}
package consts

// Colors
const (
	ColorReset  = "\033[0m"
	ColorRed    = "\033[91m"
	ColorGreen  = "\033[92m"
	ColorYellow = "\033[93m"
	ColorBlue   = "\033[34m"
	ColorPurple = "\033[35m"
	ColorCyan   = "\033[96m"
	ColorWhite  = "\033[37m"
)

const (
	RedError     string = ColorRed + "[ERROR] " + ColorReset
	GreenSuccess string = ColorGreen + "[SUCCESS] " + ColorReset
	YellowDebug  string = ColorYellow + "[DEBUG] " + ColorReset
	BlueInfo     string = ColorCyan + "[Info] " + ColorReset
)
package consts

// File prefix and suffix
const (
	OldTag  = "_metarrbackup"
	TempTag = "tmp_"
	IDTag   = "id_"
)

// Webpage tags
var (
	WebDateTags        = []string{"release-date", "upload-date", "date", "date-text", "text-date"}
	WebDescriptionTags = []string{"description", "longdescription", "long-description", "summary", "synopsis", "check-for-urls"}
	WebCreditsTags     = []string{"creator", "uploader", "uploaded-by", "uploaded_by"}
	WebTitleTags       = []string{"video-title", "video-name"}
)

// Video files
var (
	AllVidExtensions = []string{".3gp", ".avi", ".f4v", ".flv", ".m4v", ".mkv",
		".mov", ".mp4", ".mpeg", ".mpg", ".ogm", ".ogv",
		".ts", ".vob", ".webm", ".wmv"}
)

// Op types
const (
	FilterContains = "contains"
	FilterOmit     = "omit"
)
package consts

// Tables
const (
	DBChannels  = "channels"
	DBVideos    = "videos"
	DBDownloads = "downloads"
)

// Channel
const (
	QChanID        = "id"
	QChanURL       = "url"
	QChanName      = "name"
	QChanVDir      = "video_directory"
	QChanJDir      = "json_directory"
	QChanSettings  = "settings"
	QChanMetarr    = "metarr"
	QChanLastScan  = "last_scan"
	QChanCreatedAt = "created_at"
	QChanUpdatedAt = "updated_at"
)

// Videos
const (
	QVidChanID      = "channel_id"
	QVidDownloaded  = "downloaded"
	QVidURL         = "url"
	QVidTitle       = "title"
	QVidDescription = "description"
	QVidVDir        = "video_directory"
	QVidJDir        = "json_directory"
	QVidSettings    = "settings"
	QVidMetarr      = "metarr"
	QVidUploadDate  = "upload_date"
	QVidMetadata    = "metadata"
	QVidCreatedAt   = "created_at"
	QVidUpdatedAt   = "updated_at"
)

// DL status
const (
	DLStatusPending     = "pending"
	DLStatusDownloading = "downloading"
	DLStatusCompleted   = "finished"
	DLStatusFailed      = "failed"
)
package enums

type LineSelectType int

const (
	L_SINGLE LineSelectType = iota
	L_MULTI
)

type DLFilterType int

const (
	DLFILTER_OMIT DLFilterType = iota
	DLFILTER_CONTAINS
	DLFILTER_OMIT_FIELD
	DLFILTER_CONTAINS_FIELD
)
package keys

// Primary program
const (
	Context    string = "Context"
	WaitGroup  string = "WaitGroup"
	SingleFile string = "SingleFile"
)

// Check channels for new uploads
const (
	ChannelCheckNew string = "CheckChannelsForNew"
)

// Download operations
const (
	FilterOps   string = "filterOps"
	Concurrency string = "concurrency"
)

// Logging
const (
	DebugLevel string = "debug"
)

// Web related
const (
	Configuration string = "configuration"
	ValidURLs     string = "validUrls"
)
package keys

// Terminal keys:
// Files and directories
const (
	VideoDir       string = "video-dir"
	JSONDir        string = "json-dir"
	MetarrPreset   string = "metarr-preset"
	OutputFiletype string = "ext"
)

// Web inputs
const (
	CookieSource           string = "cookie-source"
	DLRetries              string = "dl-retries"
	ExternalDownloader     string = "external-downloader"
	ExternalDownloaderArgs string = "external-downloader-args"
)

// Program inputs
const (
	ConcurrencyLimitInput string = "concurrency-limit"
	MoveOnComplete        string = "move-on-complete"
)

// Settings
const (
	FilterOpsInput string = "filter-ops"
	CrawlFreq      string = "crawl-freq"
)

// Database operations
const (
	DBOpsInput   string = "db-ops"
	ChanOpsInput string = "channel-ops"
)

// Metarr operations
const (
	InputFileDatePfx        string = "filename-date-tag"
	InputFilenameReplaceSfx string = "filename-replace-suffix"
	MDescDatePfx            string = "desc-date-prefix"
	MDescDateSfx            string = "desc-date-suffix"
	MetaOps                 string = "meta-ops"
	MetaPurge               string = "purge-metafile"
	MFilenamePfx            string = "metadata-filename-prefix"
	OutputFiletypeInput     string = "ext"
	RenameStyle             string = "rename-style"
)
package regex

import (
	"regexp"
)

var (
	AnsiEscape   *regexp.Regexp
	ExtraSpaces  *regexp.Regexp
	InvalidChars *regexp.Regexp
	SpecialChars *regexp.Regexp
)

// AnsiEscapeCompile compiles regex for ANSI escape codes
func AnsiEscapeCompile() *regexp.Regexp {
	if AnsiEscape == nil {
		AnsiEscape = regexp.MustCompile(`\x1b\[[0-9;]*m`)
	}
	return AnsiEscape
}

// ExtraSpacesCompile compiles regex for extra spaces
func ExtraSpacesCompile() *regexp.Regexp {
	if ExtraSpaces == nil {
		ExtraSpaces = regexp.MustCompile(`\s+`)
	}
	return ExtraSpaces
}

// InvalidCharsCompile compiles regex for invalid characters
func InvalidCharsCompile() *regexp.Regexp {
	if InvalidChars == nil {
		InvalidChars = regexp.MustCompile(`[<>:"/\\|?*\x00-\x1F]`)
	}
	return InvalidChars
}

// SpecialCharsCompile compiles regex for special characters
func SpecialCharsCompile() *regexp.Regexp {
	if SpecialChars == nil {
		SpecialChars = regexp.MustCompile(`[^\w\s-]`)
	}
	return SpecialChars
}
package tags

// Preset tag in file
const (
	MetarrFilenameDate       = "[filename-date-tag]"
	MetarrFilenameReplaceSfx = "[filename-replace-suffix]"
	MetarrMetaOps            = "[meta-ops]"
	MetarrRenameStyle        = "[rename-style]"
	MetarrOutputDir          = "[output-directory]"
	MetarrOutputExt          = "[output-extension]"
)
package interfaces

import (
	"database/sql"
	"tubarr/internal/models"
)

type Store interface {
	GetChannelStore() ChannelStore
	GetVideoStore() VideoStore
}

type ChannelStore interface {
	AddChannel(c *models.Channel) (int64, error)
	CrawlChannel(key, val string, s Store) error
	DeleteChannel(key, val string) error
	ListChannels() (channels []models.Channel, err error, hasRows bool)
	LoadGrabbedURLs(c *models.Channel) (urls []string, err error)
	GetDB() *sql.DB
}

type VideoStore interface {
	AddVideo(v *models.Video) (int64, error)
	DeleteVideo(key, val string) error
	GetDB() *sql.DB
}
package models

type ChannelSettings struct {
	CookieSource           string      `json:"cookie_source"`
	CrawlFreq              int         `json:"crawl_freq"`
	Filters                []DLFilters `json:"filters"`
	Retries                int         `json:"download_retries"`
	ExternalDownloader     string      `json:"external_downloader"`
	ExternalDownloaderArgs string      `json:"external_downloader_args"`
	Concurrency            int         `json:"max_concurrency"`
}

type DLFilters struct {
	Field string `json:"filter_field"`
	Type  string `json:"filter_type"`
	Value string `json:"filter_value"`
}

type MetarrArgs struct {
	FilenameReplaceSfx string   `json:"filename_replace_suffix"`
	RenameStyle        string   `json:"rename_style"`
	FileDatePfx        string   `json:"filename_date_prefix"`
	MetaOps            []string `json:"meta_ops"`
}
package models

import (
	"encoding/json"
	"os/exec"
	"time"
)

// Matches the order of the DB table, do not alter
type Channel struct {
	ID   int64  `db:"id"`
	URL  string `db:"url"`
	Name string `db:"name"`
	VDir string `db:"video_directory"`
	JDir string `db:"json_directory"`

	Settings   ChannelSettings `json:"settings" db:"settings"`
	MetarrArgs MetarrArgs      `json:"metarr" db:"metarr"`

	LastScan  time.Time `db:"last_scan"`
	CreatedAt time.Time `db:"created_at"`
	UpdatedAt time.Time `db:"updated_at"`
}

type Video struct {
	ID          int64
	ChannelID   int64                  `db:"channel_id"`
	Downloaded  bool                   `db:"downloaded"`
	VDir        string                 `db:"video_directory"`
	VPath       string                 `db:"video_path"`
	JDir        string                 `db:"json_directory"`
	JPath       string                 `db:"json_path"`
	URL         string                 `db:"url"`
	Title       string                 `db:"title"`
	UploadDate  time.Time              `db:"upload_date"`
	MetadataMap map[string]interface{} `db:"-"`

	Channel    *Channel        `db:"-"`
	Settings   ChannelSettings `json:"settings" db:"settings"`
	MetarrArgs MetarrArgs      `json:"metarr" db:"metarr"`

	CreatedAt time.Time `db:"created_at"`
	UpdatedAt time.Time `db:"updated_at"`

	//Other
	DLMetaCommand  *exec.Cmd
	DLVideoCommand *exec.Cmd
}

type Download struct {
	ID           int64           `db:"id"`
	VideoID      int64           `db:"video_id"`
	Status       string          `db:"status"` // pending, downloading, completed, failed
	FilePath     string          `db:"file_path"`
	FileSize     int64           `db:"file_size"`
	StartedAt    time.Time       `db:"started_at"`
	CompletedAt  time.Time       `db:"completed_at"`
	ErrorMessage string          `db:"error_message"`
	SettingsUsed json.RawMessage `db:"settings_used"`
	CreatedAt    time.Time       `db:"created_at"`
	UpdatedAt    time.Time       `db:"updated_at"`

	VDir  string `db:"video_directory"`
	JDir  string `db:"json_directory"`
	JPath string `db:"json_path"`
	URL   string
}
package process

import (
	"fmt"
	"os/exec"
	"sync"
	"time"
	"tubarr/internal/cfg"
	"tubarr/internal/domain/keys"
	"tubarr/internal/interfaces"
	"tubarr/internal/models"
	"tubarr/internal/utils/browser"
	"tubarr/internal/utils/logging"
)

// CheckChannels checks channels and whether they are due for a crawl
func CheckChannels(s interfaces.Store) error {
	cs := s.GetChannelStore()
	channels, err, hasRows := cs.ListChannels()
	if !hasRows {
		logging.I("No channels in database")
	} else if err != nil {
		return err
	}

	var (
		wg sync.WaitGroup
	)

	conc := cfg.GetInt(keys.Concurrency)
	if conc < 1 {
		conc = 1
	}

	sem := make(chan struct{}, conc)
	errChan := make(chan error, len(channels))

	for _, channel := range channels {

		timeSinceLastScan := time.Since(channel.LastScan)
		crawlFreqDuration := time.Duration(channel.Settings.CrawlFreq) * time.Minute

		logging.I("Time since last check: %v\nCrawl frequency: %d minutes", timeSinceLastScan, crawlFreqDuration)

		if timeSinceLastScan < crawlFreqDuration {
			logging.I("%v minutes since last check. Set to wait for %v...", crawlFreqDuration-timeSinceLastScan, crawlFreqDuration)
			continue
		}

		wg.Add(1)
		go func(c models.Channel) {
			defer wg.Done()

			sem <- struct{}{}
			defer func() {
				<-sem
			}()

			if err := ChannelCrawl(s, c); err != nil {
				errChan <- err
			}
		}(channel)
	}

	wg.Wait()
	close(errChan)

	var errors []error
	for err := range errChan {
		errors = append(errors, err)
	}

	if len(errors) > 0 {
		return fmt.Errorf("encountered %d errors during processing: %v", len(errors), errors)
	}

	return nil
}

// ChannelCrawl crawls a channel for new URLs
func ChannelCrawl(s interfaces.Store, c models.Channel) error {
	logging.I("Initiating crawl for URL %s...\n\nVideo destination: %s\nJSON destination: %s\nFilters: %v\nCookies source: %s", c.URL, c.VDir, c.JDir, c.Settings.Filters, c.Settings.CookieSource)

	switch {
	case c.URL == "":
		return fmt.Errorf("channel URL is blank")
	case c.VDir == "", c.JDir == "":
		return fmt.Errorf("output directories are blank")
	}

	cs := s.GetChannelStore()

	videos, err := browser.GetNewReleases(cs, &c)
	if err != nil {
		return err
	}

	if len(videos) == 0 {
		logging.I("No new releases for channel '%s'", c.URL)
		return nil
	}

	if err := InitProcess(s.GetVideoStore(), c, videos); err != nil {
		return err
	}
	return nil
}

// InitProcess begins the process for processing metadata/videos and respective downloads
func InitProcess(vs interfaces.VideoStore, c models.Channel, videos []*models.Video) error {
	var (
		wg      sync.WaitGroup
		errChan = make(chan error, len(videos))
	)

	logging.I("Starting meta/video processing for %d videos", len(videos))

	conc := c.Settings.Concurrency
	if conc < 1 {
		conc = 1
	}
	sem := make(chan struct{}, conc)

	for _, video := range videos {
		wg.Add(1)

		go func(v *models.Video) {
			defer wg.Done()

			sem <- struct{}{}
			defer func() { <-sem }()

			if err := processJSON(v, vs); err != nil {
				errChan <- fmt.Errorf("JSON processing error for %s: %w", v.URL, err)
				return
			}

			if logging.Level > 1 {
				fmt.Println()
				logging.I("Got requests for '%s'", v.URL)
				logging.P("Channel ID=%d", v.ChannelID)
				logging.P("Uploaded=%s", v.UploadDate)
			}

			if err := processVideo(v, vs); err != nil {
				errChan <- fmt.Errorf("video processing error for %s: %w", v.URL, err)
				return
			}

			// Check if Metarr exists on system (proceed if yes)
			if _, err := exec.LookPath("metarr"); err != nil {
				logging.I("Skipping Metarr process... 'metarr' not available: %v", err)
				return
			}
			InitMetarr(v)
		}(video)
	}

	wg.Wait()
	close(errChan)

	var errors []error
	for err := range errChan {
		errors = append(errors, err)
	}

	if len(errors) > 0 {
		return fmt.Errorf("encountered %d errors during processing: %v", len(errors), errors)
	}

	return nil
}
package process

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"tubarr/internal/domain/consts"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"
)

// validateAndStoreJSON checks if the JSON is valid and if it passes filter checks
func validateAndStoreJSON(v *models.Video) (valid bool, err error) {
	if v == nil {
		return false, fmt.Errorf("dl model is null")
	}

	if v.JPath == "" {
		return false, fmt.Errorf("json path cannot be empty")
	}

	jInfo, err := os.Stat(v.JPath)
	if err != nil {
		return false, err
	}

	switch {
	case jInfo.IsDir():
		return false, fmt.Errorf("json path should be path to json file, not directory")
	case filepath.Ext(jInfo.Name()) != ".json":
		return false, fmt.Errorf("json file should end in .json")
	case !jInfo.Mode().IsRegular():
		return false, fmt.Errorf("json not a regular file")
	}

	f, err := os.Open(v.JPath)
	if err != nil {
		return false, err
	}
	defer f.Close()

	logging.D(1, "About to decode JSON to metamap")

	m := make(map[string]interface{})
	decoder := json.NewDecoder(f)
	if err := decoder.Decode(&m); err != nil {
		return false, fmt.Errorf("failed to decode JSON: %w", err)
	}

	if len(m) > 0 {
		v.MetadataMap = m
	} else {
		return false, nil
	}

	if valid, err = filterRequests(v); err != nil {
		return false, err
	}
	if !valid {
		return false, nil
	}

	return valid, nil
}

// filterRequests uses user input filters to check if the video should be downloaded
func filterRequests(v *models.Video) (valid bool, err error) {
	// Check if filters are set and validate if so
	if len(v.Settings.Filters) == 0 {
		logging.D(2, "No filters to check for '%s'", v.URL)
		return true, nil
	}

	// Apply filters if any match metadata content
	for _, filter := range v.Settings.Filters {
		val, exists := v.MetadataMap[filter.Field]

		if filter.Value == "" {
			if !exists {
				switch filter.Type {
				case consts.FilterContains:

					logging.I("Filtering: Field '%s' not found in metadata for URL '%s' and filter is set to require it, filtering out", filter.Field, v.URL)
					if err := removeUnwantedJSON(v.JPath); err != nil {
						logging.E(0, err.Error())
					}
					return false, nil

				case consts.FilterOmit:
					logging.D(2, "Passed check: Field '%s' does not exist", filter.Field)
					continue
				}
			}
			if exists {
				switch filter.Type {
				case consts.FilterOmit:

					logging.I("Filtering: Field '%s' found in metadata for URL '%s' and filter is set to omit it, filtering out", filter.Field, v.URL)
					if err := removeUnwantedJSON(v.JPath); err != nil {
						logging.E(0, err.Error())
					}
					return false, nil

				case consts.FilterContains:
					logging.D(2, "Passed check: Field '%s' exists", filter.Field)
					continue
				}
			}
		}

		// Performing field contents checks
		if filter.Value != "" {

			strVal, ok := val.(string)
			if !ok {
				logging.E(0, "Unexpected type for field %s: expected string, got %T", filter.Field, val)
				continue
			}

			lowerStrVal := strings.ToLower(strVal)
			lowerFilterVal := strings.ToLower(filter.Value)

			// Apply the filter logic
			switch filter.Type {
			case consts.FilterOmit:
				if strings.Contains(lowerStrVal, lowerFilterVal) {

					logging.D(1, "Filtering out video '%s' which contains '%s' in field '%s'", v.URL, filter.Value, filter.Field)
					if err := removeUnwantedJSON(v.JPath); err != nil {
						logging.E(0, err.Error())
					}
					return false, nil
				}

			case consts.FilterContains:
				if !strings.Contains(lowerStrVal, lowerFilterVal) {

					logging.D(1, "Filtering out video '%s' which does not contain '%s' in field '%s'", v.URL, filter.Value, filter.Field)
					if err := removeUnwantedJSON(v.JPath); err != nil {
						logging.E(0, err.Error())
					}
					return false, nil
				}

			default:
				logging.D(1, "Unrecognized filter type, skipping...")
				continue
			}
		}
	}
	logging.D(1, "Video '%s' passed filter checks", v.URL)
	return true, nil
}

// removeUnwantedJSON removes filtered out JSON files
func removeUnwantedJSON(path string) error {
	if path == "" {
		return fmt.Errorf("path sent in empty, not removing")
	}

	check, err := os.Stat(path)
	if err != nil {
		return fmt.Errorf("not deleting unwanted JSON file, got error: %w", err)
	}

	switch {
	case check.IsDir():
		return fmt.Errorf("JSON path sent in as a directory '%s', not deleting", path)
	case !check.Mode().IsRegular():
		return fmt.Errorf("JSON file '%s' is not a regular file, not deleting", path)
	}

	if err := os.Remove(path); err != nil {
		return fmt.Errorf("failed to remove unwanted JSON file '%s' due to error %w", path, err)
	} else {
		logging.S(0, "Removed unwanted JSON file '%s'", path)
	}

	return nil
}
package process

import (
	"fmt"
	"tubarr/internal/command"
	"tubarr/internal/interfaces"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"
)

// processJSON downloads and processes JSON for a video
func processJSON(v *models.Video, vs interfaces.VideoStore) error {
	if v == nil {
		logging.I("Nil video")
		return nil
	}

	// Create metadata download command
	mdl := command.NewMetaDLRequest(v)
	cmd := mdl.RequestMetaCommand()
	if cmd == nil {
		return fmt.Errorf("failed to create meta DL command for '%s'", v.URL)
	}

	// Execute metadata download
	if err := command.ExecuteMetaDownload(v, cmd); err != nil {
		logging.E(0, "Failed downloading metadata for '%s': %v", v.URL, err)
		// Add to database even if metadata download fails
		if _, err := vs.AddVideo(v); err != nil {
			return fmt.Errorf("failed to add video to database: %v", err)
		}
		return nil
	}

	// Validate JSON
	valid, err := validateAndStoreJSON(v)
	if err != nil {
		logging.E(0, "JSON validation failed for '%s': %v", v.URL, err)
	}

	// Add to database regardless of validation
	if _, err := vs.AddVideo(v); err != nil {
		return fmt.Errorf("failed to add video to database: %v", err)
	}

	if !valid {
		logging.D(1, "JSON validation failed but video added to database: %s", v.URL)
		return nil
	}

	logging.S(0, "Successfully processed metadata for: %s", v.URL)
	return nil
}
package process

import (
	"tubarr/internal/command"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"
)

// InitMetarr begins processing with Metarr
func InitMetarr(v *models.Video) error {
	mc := command.NewMetarrCommandBuilder(v)
	cmd, err := mc.MakeMetarrCommands()
	if err != nil {
		return err
	}

	if err := command.RunMetarr(cmd); err != nil {
		return err
	}
	logging.S(1, "Finished Metarr command for '%s'", v.VPath)
	return nil
}
package process

import (
	"fmt"
	"tubarr/internal/command"
	"tubarr/internal/interfaces"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"
)

// processVideo processes video downloads
func processVideo(v *models.Video, vs interfaces.VideoStore) error {
	if v == nil {
		logging.I("No videos to download")
		return nil
	}

	logging.D(2, "Processing download for URL: %s", v.URL)

	vcb := command.NewVideoDLRequest(v)
	cmd, err := vcb.VideoFetchCommand()
	if err != nil {
		return err
	}

	success, err := command.ExecuteVideoDownload(v, cmd)
	if err != nil {
		return err
	}

	if success {
		v.Downloaded = true
		vs.AddVideo(v)
		logging.D(1, "Successfully processed: %s", v.URL)
		return nil
	}
	return fmt.Errorf("video download was unsuccessful")
}
package repo

import (
	"database/sql"
	"tubarr/internal/interfaces"
)

type Store struct {
	db           *sql.DB
	videoStore   *VideoStore
	channelStore *ChannelStore
}

func InitStores(db *sql.DB) *Store {
	return &Store{
		db:           db,
		videoStore:   GetVideoStore(db),
		channelStore: GetChannelStore(db),
	}
}

// GetChannelStore with pointer receiver
func (s *Store) GetChannelStore() interfaces.ChannelStore {
	return s.channelStore
}

// GetVideoStore with pointer receiver
func (s *Store) GetVideoStore() interfaces.VideoStore {
	return s.videoStore
}
package repo

import (
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"time"
	"tubarr/internal/domain/consts"
	"tubarr/internal/interfaces"
	"tubarr/internal/models"
	"tubarr/internal/process"
	"tubarr/internal/utils/logging"

	"github.com/Masterminds/squirrel"
)

type ChannelStore struct {
	DB *sql.DB
}

func GetChannelStore(db *sql.DB) *ChannelStore {
	return &ChannelStore{
		DB: db,
	}
}

// GetDB returns the database
func (cs *ChannelStore) GetDB() *sql.DB {
	return cs.DB
}

// AddChannel adds a new channel to the database
func (cs ChannelStore) AddChannel(c *models.Channel) (int64, error) {
	switch {
	case c.URL == "":
		return 0, fmt.Errorf("must enter a url for channel")
	case c.VDir == "":
		return 0, fmt.Errorf("must enter a video directory where downloads will be stored")
	}

	if cs.channelExists(consts.QChanURL, c.URL) {
		return 0, fmt.Errorf("channel with URL '%s' already exists", c.URL)
	}

	// JSON dir
	if c.JDir == "" {
		c.JDir = c.VDir
	}
	now := time.Now()

	// Convert settings to JSON
	settingsJSON, err := json.Marshal(c.Settings)
	if err != nil {
		return 0, fmt.Errorf("failed to marshal settings: %w", err)
	}

	// Convert metarr settings to JSON
	metarrJSON, err := json.Marshal(c.MetarrArgs)
	if err != nil {
		return 0, fmt.Errorf("failed to marshal metarr settings: %w", err)
	}

	query := squirrel.
		Insert(consts.DBChannels).
		Columns(
			consts.QChanURL,
			consts.QChanName,
			consts.QChanVDir,
			consts.QChanJDir,
			consts.QChanSettings,
			consts.QChanMetarr, // Add this column
			consts.QChanLastScan,
			consts.QChanCreatedAt,
			consts.QChanUpdatedAt,
		).
		Values(
			c.URL,
			c.Name,
			c.VDir,
			c.JDir,
			settingsJSON,
			metarrJSON, // Add this value
			now,
			now,
			now,
		).
		RunWith(cs.DB)

	result, err := query.Exec()
	if err != nil {
		return 0, fmt.Errorf("failed to insert channel: %w", err)
	}

	id, err := result.LastInsertId()
	if err != nil {
		return 0, fmt.Errorf("failed to get last insert ID: %w", err)
	}

	logging.S(0, "Successfully added channel with metarr operations: %+v", c.MetarrArgs)
	return id, nil
}

// DeleteChannel deletes a channel from the database with a given key/value
func (cs *ChannelStore) DeleteChannel(key, val string) error {
	if !cs.channelExists(key, val) {
		return fmt.Errorf("channel with key '%s' and value '%s' does not exist", key, val)
	}

	query := squirrel.
		Delete(consts.DBChannels).
		Where(squirrel.Eq{key: val}).
		RunWith(cs.DB)

	if _, err := query.Exec(); err != nil {
		return err
	}
	return nil
}

// CrawlChannel crawls a channel and finds video URLs which have not yet been downloaded
func (cs *ChannelStore) CrawlChannel(key, val string, s interfaces.Store) error {
	var (
		c                    models.Channel
		settings, metarrJSON json.RawMessage
	)

	query := squirrel.
		Select(
			consts.QChanID,
			consts.QChanURL,
			consts.QChanName,
			consts.QChanVDir,
			consts.QChanJDir,
			consts.QChanSettings,
			consts.QChanMetarr,
			consts.QChanLastScan,
			consts.QChanCreatedAt,
			consts.QChanUpdatedAt,
		).
		From(consts.DBChannels).
		Where(squirrel.Eq{key: val})

	if err := query.
		RunWith(cs.DB).
		QueryRow().
		Scan(
			&c.ID,
			&c.URL,
			&c.Name,
			&c.VDir,
			&c.JDir,
			&settings,
			&metarrJSON,
			&c.LastScan,
			&c.CreatedAt,
			&c.UpdatedAt,
		); err != nil {
		return fmt.Errorf("failed to scan channel: %w", err)
	}

	// Unmarshal settings
	if err := json.Unmarshal(settings, &c.Settings); err != nil {
		return fmt.Errorf("parsing channel settings: %w", err)
	}

	// Unmarshal metarr settings
	if len(metarrJSON) > 0 {
		if err := json.Unmarshal(metarrJSON, &c.MetarrArgs); err != nil {
			return fmt.Errorf("parsing metarr settings: %w", err)
		}
	}

	logging.D(1, "Retrieved channel with Metarr args: %+v", c.MetarrArgs)
	return process.ChannelCrawl(s, c)
}

// ListChannels lists all channels in the database
func (cs *ChannelStore) ListChannels() (channels []models.Channel, err error, hasRows bool) {
	query := squirrel.
		Select(
			consts.QChanID,
			consts.QChanURL,
			consts.QChanName,
			consts.QChanVDir,
			consts.QChanJDir,
			consts.QChanSettings,
			consts.QChanMetarr,
			consts.QChanLastScan,
			consts.QChanCreatedAt,
			consts.QChanUpdatedAt,
		).
		From(consts.DBChannels).
		OrderBy(consts.QChanName).
		RunWith(cs.DB)

	rows, err := query.Query()
	if err == sql.ErrNoRows {
		return nil, nil, false
	} else if err != nil {
		return nil, fmt.Errorf("failed to query channels: %w", err), true
	}
	defer rows.Close()

	for rows.Next() {
		var c models.Channel
		var settingsJSON, metarrJSON []byte
		err := rows.Scan(
			&c.ID,
			&c.URL,
			&c.Name,
			&c.VDir,
			&c.JDir,
			&settingsJSON,
			&metarrJSON, // Scan Metarr JSON
			&c.LastScan,
			&c.CreatedAt,
			&c.UpdatedAt,
		)
		if err != nil {
			return nil, fmt.Errorf("failed to scan channel: %w", err), true
		}

		// Unmarshal settings JSON
		if len(settingsJSON) > 0 {
			if err := json.Unmarshal(settingsJSON, &c.Settings); err != nil {
				return nil, fmt.Errorf("failed to unmarshal settings: %w", err), true
			}
		}

		// Unmarshal Metarr JSON
		if len(metarrJSON) > 0 {
			if err := json.Unmarshal(metarrJSON, &c.MetarrArgs); err != nil {
				return nil, fmt.Errorf("failed to unmarshal metarr settings: %w", err), true
			}
		}

		channels = append(channels, c)
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("error iterating rows: %w", err), true
	}

	return channels, nil, true
}

// LoadGrabbedURLs adds a new channel to the database
func (cs ChannelStore) LoadGrabbedURLs(c *models.Channel) (urls []string, err error) {
	if c.ID == 0 {
		return nil, fmt.Errorf("model entered has no ID")
	}

	// Select only URLs where channel_id matches and downloaded is true
	query := squirrel.
		Select(consts.QVidURL).
		From(consts.DBVideos).
		Where(squirrel.And{
			squirrel.Eq{consts.QVidChanID: c.ID},
			squirrel.Eq{consts.QVidDownloaded: 1}, // SQLite uses 1 for true
		}).
		RunWith(cs.DB)

	logging.D(2, "Executing query: %v for channel ID %d", query, c.ID)

	rows, err := query.Query()
	if err != nil {
		return nil, fmt.Errorf("failed to execute query: %w", err)
	}
	defer rows.Close()

	for rows.Next() {
		var url string
		if err := rows.Scan(&url); err != nil {
			return nil, fmt.Errorf("failed to scan row: %w", err)
		}
		urls = append(urls, url)
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("row iteration error: %w", err)
	}

	logging.D(2, "Found %d downloaded URLs for channel ID %d", len(urls), c.ID)

	return urls, nil
}

// Private /////////////////////////////////////////////////////////////////////

// channelExists returns true if the channel exists in the database
func (cs ChannelStore) channelExists(key, val string) bool {
	var exists bool
	query := squirrel.
		Select("1").
		From(consts.DBChannels).
		Where(squirrel.Eq{key: val}).
		RunWith(cs.DB)

	if err := query.QueryRow().Scan(&exists); err == sql.ErrNoRows {
		return false
	} else if err != nil {
		log.Fatalf("error querying row, aborting program")
	}
	return exists
}
package repo

import (
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"time"
	"tubarr/internal/domain/consts"
	"tubarr/internal/models"
	"tubarr/internal/utils/logging"

	"github.com/Masterminds/squirrel"
)

type VideoStore struct {
	DB *sql.DB
}

func GetVideoStore(db *sql.DB) *VideoStore {
	return &VideoStore{
		DB: db,
	}
}

// GetDB returns the database
func (vs *VideoStore) GetDB() *sql.DB {
	return vs.DB
}

// AddVideo adds a new video to the database
func (vs VideoStore) AddVideo(v *models.Video) (int64, error) {
	switch {
	case v.URL == "":
		return 0, fmt.Errorf("must enter a url for video")
	case v.VDir == "":
		return 0, fmt.Errorf("must enter a video directory where downloads will be stored")
	}

	if vs.videoExists(consts.QVidURL, v.URL) {
		logging.D(2, "Video with URL '%s' already exists, skipping", v.URL)
		return 0, nil // Return gracefully instead of error
	}

	// JSON dir
	if v.JDir == "" {
		v.JDir = v.VDir
	}
	now := time.Now()

	// Convert metadata map to JSON string
	metadataJSON, err := json.Marshal(v.MetadataMap)
	if err != nil {
		return 0, fmt.Errorf("failed to marshal metadata to JSON: %w", err)
	}

	// Convert settings to JSON
	settingsJSON, err := json.Marshal(v.Settings)
	if err != nil {
		return 0, fmt.Errorf("failed to marshal settings to JSON: %w", err)
	}

	// Convert metarr settings to JSON
	metarrJSON, err := json.Marshal(v.MetarrArgs)
	if err != nil {
		return 0, fmt.Errorf("failed to marshal metarr settings to JSON: %w", err)
	}

	query := squirrel.
		Insert(consts.DBVideos).
		Columns(
			consts.QVidChanID,
			consts.QVidDownloaded,
			consts.QVidURL,
			consts.QVidTitle,
			consts.QVidVDir,
			consts.QVidJDir,
			consts.QVidUploadDate,
			consts.QVidMetadata,
			consts.QVidSettings,
			consts.QVidMetarr,
			consts.QVidCreatedAt,
			consts.QVidUpdatedAt,
		).
		Values(
			v.ChannelID,
			v.Downloaded,
			v.URL,
			v.Title,
			v.VDir,
			v.JDir,
			v.UploadDate,
			metadataJSON,
			settingsJSON,
			metarrJSON,
			now,
			now,
		).
		RunWith(vs.DB)

	result, err := query.Exec()
	if err != nil {
		return 0, fmt.Errorf("failed to insert video: %w", err)
	}

	id, err := result.LastInsertId()
	if err != nil {
		return 0, fmt.Errorf("failed to get last insert ID: %w", err)
	}
	return id, nil
}

// DeleteVideo deletes an existent downloaded video from the database
func (vs VideoStore) DeleteVideo(key, val string) error {
	if key == "" || val == "" {
		return fmt.Errorf("please pass in a key and value to delete a video entry")
	}

	query := squirrel.
		Delete(consts.DBVideos).
		Where(squirrel.Eq{key: val}).
		RunWith(vs.DB)

	if _, err := query.Exec(); err != nil {
		if err == sql.ErrNoRows {
			fmt.Printf("No video exists with key '%s' and value '%s'", key, val)
		} else {
			return err
		}
	}

	return nil
}

// Private /////////////////////////////////////////////////////////////////////

// channelExists returns true if the channel exists in the database
func (vs VideoStore) videoExists(key, val string) bool {
	var exists bool
	query := squirrel.
		Select("1").
		From(consts.DBVideos).
		Where(squirrel.Eq{key: val}).
		RunWith(vs.DB)

	if err := query.QueryRow().Scan(&exists); err == sql.ErrNoRows {
		return false
	} else if err != nil {
		log.Fatalf("error querying row, aborting program")
	}
	return exists
}
package browser

import (
	"fmt"
	"net/http"
	"net/url"
	"strings"
	"tubarr/internal/utils/logging"

	"github.com/browserutils/kooky"
	_ "github.com/browserutils/kooky/browser/all"
)

// GetBrowserCookies sets cookies input by the user. Useful for getting URLs
// from websites which require authentication!

var (
	allStores  []kooky.CookieStore
	allCookies []*http.Cookie
)

// initializeCookies initializes all browser cookie stores
func initializeCookies() {
	allStores = kooky.FindAllCookieStores()
	allCookies = []*http.Cookie{}
}

// GetBrowserCookies retrieves cookies for a given URL, using a specified cookie file if provided.
func getBrowserCookies(url string) ([]*http.Cookie, error) {
	baseURL, err := extractBaseDomain(url)
	if err != nil {
		return nil, fmt.Errorf("failed to extract base domain: %v", err)
	}

	// Otherwise, proceed to use browser cookie stores
	if allStores == nil || allCookies == nil || len(allCookies) == 0 {
		initializeCookies()
	}

	attemptedBrowsers := make(map[string]bool, len(allStores))

	for _, store := range allStores {
		browserName := store.Browser()
		logging.D(2, "Attempting to read cookies from %s", browserName)
		attemptedBrowsers[browserName] = true

		cookies, err := store.ReadCookies(kooky.Valid, kooky.Domain(baseURL))
		if err != nil {
			logging.D(2, "Failed to read cookies from %s: %v", browserName, err)
			continue
		}

		if len(cookies) > 0 {
			logging.I("Successfully read %d cookies from %s for domain %s", len(cookies), browserName, baseURL)
			allCookies = append(allCookies, convertToHTTPCookies(cookies)...)
		} else {
			logging.D(2, "No cookies found for %s", browserName)
		}
	}

	// Log summary of attempted browsers
	logging.I("Attempted to read cookies from the following browsers: %v", keysFromMap(attemptedBrowsers))

	if len(allCookies) == 0 {
		logging.I("No cookies found for '%s', proceeding without cookies", url)
	} else {
		logging.I("Found a total of %d cookies for '%s'", len(allCookies), url)
	}

	return allCookies, nil
}

// convertToHTTPCookies converts kooky cookies to http.Cookie format
func convertToHTTPCookies(kookyCookies []*kooky.Cookie) []*http.Cookie {
	httpCookies := make([]*http.Cookie, len(kookyCookies))
	for i, c := range kookyCookies {
		httpCookies[i] = &http.Cookie{
			Name:   c.Name,
			Value:  c.Value,
			Path:   c.Path,
			Domain: c.Domain,
			Secure: c.Secure,
		}
	}
	return httpCookies
}

// extractBaseDomain parses a URL and extracts its base domain
func extractBaseDomain(urlString string) (string, error) {
	parsedURL, err := url.Parse(urlString)
	if err != nil {
		return "", err
	}

	parts := strings.Split(parsedURL.Hostname(), ".")
	if len(parts) > 2 {
		return strings.Join(parts[len(parts)-2:], "."), nil
	}
	return parsedURL.Hostname(), nil
}

// keysForMap helper function to get keys from a map
func keysFromMap(m map[string]bool) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}
package browser

import (
	"fmt"
	"net/http"
	"strings"
	"tubarr/internal/interfaces"
	"tubarr/internal/models"
	logging "tubarr/internal/utils/logging"

	"github.com/gocolly/colly"
)

// GetNewReleases checks a channel URL for URLs which have not yet been recorded as downloaded
func GetNewReleases(cs interfaces.ChannelStore, c *models.Channel) ([]*models.Video, error) {

	uniqueURLs := make(map[string]struct{})

	existingURLs, err := cs.LoadGrabbedURLs(c)
	if err != nil {
		return nil, err
	}

	if len(existingURLs) > 0 {
		fmt.Println()
		logging.I("Found existing downloaded video URLs:")
		count := 1
		for _, u := range existingURLs {
			logging.P("Entry %d: %v", count, u)
			count++
		}
		fmt.Println()
	}

	if c.URL == "" {
		return nil, fmt.Errorf("channel url is blank")
	}

	cookies, err := getBrowserCookies(c.URL)
	if err != nil {
		return nil, err
	}

	newURLs, err := newEpisodeURLs(c.URL, existingURLs, cookies)
	if err != nil {
		return nil, err
	}

	// Add unique URLs to map
	for _, newURL := range newURLs {
		if newURL != "" {
			uniqueURLs[newURL] = struct{}{}
		}
	}

	// Convert map to slice
	var newRequests = make([]*models.Video, 0, len(uniqueURLs))

	for url := range uniqueURLs {
		newRequests = append(newRequests, &models.Video{
			ChannelID:  c.ID,
			URL:        url,
			VDir:       c.VDir,
			JDir:       c.JDir,
			Channel:    c,
			Settings:   c.Settings,
			MetarrArgs: c.MetarrArgs,
		})
	}

	// Display results
	if len(newRequests) > 0 {
		logging.I("Grabbed %d new download requests: %v", len(newRequests), uniqueURLs)
	}

	return newRequests, nil
}

// newEpisodeURLs checks for new episode URLs that are not yet in grabbed-urls.txt
func newEpisodeURLs(targetURL string, existingURLs []string, cookies []*http.Cookie) ([]string, error) {

	c := colly.NewCollector()
	uniqueEpisodeURLs := make(map[string]struct{})

	for _, cookie := range cookies {
		c.SetCookies(targetURL, []*http.Cookie{cookie})
	}

	// Video URL link pattern
	switch {
	case strings.Contains(targetURL, "bitchute.com"):
		logging.I("Detected bitchute.com link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/video/") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})

	case strings.Contains(targetURL, "censored.tv"):
		logging.I("Detected censored.tv link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/episode/") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})

	case strings.Contains(targetURL, "odysee.com"):
		logging.I("Detected Odysee link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			parts := strings.Split(link, "/")
			if len(parts) > 1 {
				lastPart := parts[len(parts)-1]
				if strings.Contains(link, "@") && strings.Contains(link, lastPart+"/") {
					uniqueEpisodeURLs[link] = struct{}{}
				}
			}
		})

	case strings.Contains(targetURL, "rumble.com"):
		logging.I("Detected Rumble link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/v") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})

	default:
		logging.I("Using default link detection")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/watch") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})
	}

	// Visit the target URL
	err := c.Visit(targetURL)
	if err != nil {
		return nil, fmt.Errorf("error visiting webpage (%s): %v", targetURL, err)
	}
	c.Wait()

	// Convert unique URLs map to slice
	var episodeURLs = make([]string, 0, len(uniqueEpisodeURLs))
	for url := range uniqueEpisodeURLs {
		episodeURLs = append(episodeURLs, url)
	}

	// Filter out URLs that are already in grabbed-urls.txt
	var newURLs = make([]string, 0, len(episodeURLs))
	for _, url := range episodeURLs {
		normalizedURL := normalizeURL(url)
		exists := false

		for _, existingURL := range existingURLs {
			if normalizeURL(existingURL) == normalizedURL {
				exists = true
				break
			}
		}
		if !exists {
			newURLs = append(newURLs, url)
		}
	}
	if len(newURLs) == 0 {
		logging.I("No new videos at %s", targetURL)
		return nil, nil
	}
	return newURLs, nil
}

// normalizeURL standardizes URLs for comparison by removing protocol and any trailing slashes
func normalizeURL(inputURL string) string {
	// Remove http:// or https://
	cleanURL := strings.TrimPrefix(inputURL, "https://")
	cleanURL = strings.TrimPrefix(cleanURL, "http://")

	// Remove any trailing slash
	cleanURL = strings.TrimSuffix(cleanURL, "/")

	return cleanURL
}
package logging

import (
	"fmt"
	"path/filepath"
	"runtime"
	"sync"
	"tubarr/internal/domain/consts"
	"tubarr/internal/domain/keys"

	"github.com/spf13/viper"
)

var (
	Level int = -1 // Pre initialization
	mu    sync.Mutex
)

func E(l int, format string, args ...interface{}) string {

	mu.Lock()
	defer mu.Unlock()
	var msg string

	pc, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	funcName := filepath.Base(runtime.FuncForPC(pc).Name())
	tag := fmt.Sprintf("["+consts.ColorBlue+"Function:"+consts.ColorReset+" %s - "+consts.ColorBlue+"File:"+consts.ColorReset+" %s : "+consts.ColorBlue+"Line:"+consts.ColorReset+" %d] ", funcName, file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) {

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.RedError+format+" "+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.RedError + format + " " + tag + "\n")
		}
		fmt.Print(msg)
		writeLog(msg, l)
	}

	return msg
}

func S(l int, format string, args ...interface{}) string {

	mu.Lock()
	defer mu.Unlock()
	var msg string

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) {

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.GreenSuccess+format+" \n", args...)
		} else {
			msg = fmt.Sprintf(consts.GreenSuccess + format + " \n")
		}
		fmt.Print(msg)
		writeLog(msg, l)
	}
	return msg
}

func D(l int, format string, args ...interface{}) string {

	mu.Lock()
	defer mu.Unlock()
	var msg string

	pc, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	funcName := filepath.Base(runtime.FuncForPC(pc).Name())
	tag := fmt.Sprintf("["+consts.ColorBlue+"Function:"+consts.ColorReset+" %s - "+consts.ColorBlue+"File:"+consts.ColorReset+" %s : "+consts.ColorBlue+"Line:"+consts.ColorReset+" %d] ", funcName, file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) && l != 0 { // Debug messages don't appear by default

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.YellowDebug+format+" "+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.YellowDebug + format + " " + tag + "\n")
		}
		fmt.Print(msg)
		writeLog(msg, l)
	}
	return msg
}

func I(format string, args ...interface{}) string {

	mu.Lock()
	defer mu.Unlock()
	var msg string

	if len(args) != 0 && args != nil {
		msg = fmt.Sprintf(consts.BlueInfo+format+"\n", args...)
	} else {
		msg = fmt.Sprintf(consts.BlueInfo + format + "\n")
	}
	fmt.Print(msg)
	writeLog(msg, 0)

	return msg
}

func P(format string, args ...interface{}) string {

	mu.Lock()
	defer mu.Unlock()
	var msg string

	if len(args) != 0 && args != nil {
		msg = fmt.Sprintf(format+"\n", args...)
	} else {
		msg = fmt.Sprintf(format + "\n")
	}
	fmt.Print(msg)
	writeLog(msg, 0)

	return msg
}
package logging

import (
	"log"
	"path/filepath"
	"strings"
	"time"
	"tubarr/internal/domain/regex"

	"gopkg.in/natefinch/lumberjack.v2"
)

var (
	ErrorArray []error
	Loggable   bool = false
	Logger     *log.Logger

	// Matches ANSI escape codes
	ansiEscape = regex.AnsiEscapeCompile()
)

// SetupLogging creates and/or opens the log file
func SetupLogging(targetDir string) error {

	logFile := &lumberjack.Logger{
		Filename:   filepath.Join(targetDir, "/metarr.log"), // Log file path
		MaxSize:    1,                                       // Max size in MB before rotation
		MaxBackups: 3,                                       // Number of backups to retain
		Compress:   true,                                    // Gzip compression
	}

	// Assign lumberjack logger to standard log output
	Logger = log.New(logFile, "", log.LstdFlags)
	Loggable = true

	Logger.Printf(":\n=========== %v ===========\n\n", time.Now().Format(time.RFC1123Z))
	return nil
}

// Write writes error information to the log file
func writeLog(msg string, level int) {
	// Do not add mutex
	if Loggable && level < 2 {
		if !strings.HasPrefix(msg, "\n") {
			msg += "\n"
		}

		if ansiEscape == nil {
			ansiEscape = regex.AnsiEscapeCompile()
		}

		Logger.Print(ansiEscape.ReplaceAllString(msg, ""))
	}
}
package main

import (
	"fmt"
	"os"
	"time"
	"tubarr/internal/cfg"
	"tubarr/internal/database"
	"tubarr/internal/process"
	"tubarr/internal/repo"
	"tubarr/internal/utils/logging"
)

var startTime time.Time

func init() {
	startTime = time.Now()
	logging.I("tubarr started at: %v", startTime.Format("2006-01-02 15:04:05.00 MST"))
}

// main is the program entrypoint (duh!)
func main() {

	// Initialize database and channel store
	db := database.GrabDB()
	store := repo.InitStores(db)

	// Initialize commands with dependencies
	cfg.InitCommands(store)

	// Execute root command
	if err := cfg.Execute(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}

	if cfg.GetBool("check_channels") {
		if err := process.CheckChannels(store); err != nil {
			fmt.Fprintf(os.Stderr, "Error checking channels: %v\n", err)
			os.Exit(1)
		}
	}

	endTime := time.Now()
	logging.I("metarr finished at: %v", endTime.Format("2006-01-02 15:04:05.00 MST"))
	logging.I("Time elapsed: %.2f seconds", endTime.Sub(startTime).Seconds())
	fmt.Println()
}
