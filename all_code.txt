package command

import (
	"Tubarr/internal/models"
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"os/exec"
	"strings"
)

type VideoDLCommandBuilder struct {
	Model *models.DownloadedFiles
}

func NewVideoDLCommandBuilder(d *models.DownloadedFiles) *VideoDLCommandBuilder {
	return &VideoDLCommandBuilder{
		Model: d,
	}
}

// BuildVideoFetchCommand builds the command for yt-dlp
func (vf *VideoDLCommandBuilder) VideoFetchCommand() (*exec.Cmd, error) {
	if vf.Model == nil {
		return nil, fmt.Errorf("model passed in null, returning no command")
	}

	m := vf.Model
	var args []string

	switch {
	case strings.Contains(m.URL, "censored.tv"):
		// Not implemented
	default:
		// Use default
	}
	args = append(args, writeJsonLocation(m.VideoDirectory)...)
	args = append(args, "--restrict-filenames", "-o", "%(title)s.%(ext)s")
	args = append(args, "--retries", "999", "--retry-sleep", "10")
	args = append(args, "--print", "after_move:%(filepath)s")

	if len(m.CookieSource) > 0 {
		args = append(args, "--cookies-from-browser", m.CookieSource)
	}
	if len(m.ExternalDler) > 0 {
		args = append(args, "--external-downloader", m.ExternalDler)
	}
	if len(m.ExternalDlerArgs) > 0 {
		args = append(args, "--external-downloader-args", m.ExternalDlerArgs)
	}
	if len(m.URL) != 0 {
		args = append(args, m.URL)
	}

	logging.PrintD(1, "Built argument list: %v", args)

	return exec.Command("yt-dlp", args...), nil
}

// writeJsonLocation writes the target directory for the JSON file
func writeJsonLocation(s string) []string {
	if s != "" {
		return []string{"--write-info-json", "-P", s}
	}
	return nil
}
package command

import (
	"Tubarr/internal/config"
	preset "Tubarr/internal/config/presets"
	keys "Tubarr/internal/domain/keys"
	"Tubarr/internal/models"
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"os"
	"os/exec"
	"strings"
)

type MetarrCommand struct {
	Commands map[string][]string
}

// NewMetarrCommandBuilder returns a new command builder to build and run Metarr commands
func NewMetarrCommandBuilder() *MetarrCommand {
	return &MetarrCommand{}
}

func (mc *MetarrCommand) MakeMetarrCommands(d []*models.DownloadedFiles) ([]*exec.Cmd, error) {
	if len(d) == 0 {
		return nil, fmt.Errorf("no downloaded file models")
	}
	if err := mc.ParsePresets(d); err != nil {
		return nil, fmt.Errorf("failed to parse command presets")
	}
	commands := make([]*exec.Cmd, 0)
	for _, args := range mc.Commands {
		command := exec.Command("metarr", args...)
		commands = append(commands, command)
	}
	return commands, nil
}

// ParseMetarrPreset parses the Metarr from a preset file
func (mc *MetarrCommand) ParsePresets(d []*models.DownloadedFiles) error {

	logging.PrintI("Sending to Metarr for metadata insertion")

	mPresetFilepath := config.GetString(keys.MetarrPreset)
	var fileCommandMap = make(map[string][]string)

	for _, model := range d {
		args := make([]string, 0)

		args = append(args, "-V", model.VideoFilename)
		args = append(args, "-J", model.JSONFilename)

		if mPresetFilepath != "" { // Parse preset file if the path exists
			content, err := os.ReadFile(mPresetFilepath)
			if err != nil {
				return fmt.Errorf("error reading file '%s': %w", mPresetFilepath, err)
			}
			cStr := string(content)

			args = append(args, mc.filenameReplaceSuffix(cStr)...)
			args = append(args, mc.metaReplaceSuffix(cStr)...)
			args = append(args, mc.metaReplacePrefix(cStr)...)
			args = append(args, mc.metaAddField(cStr)...)
			args = append(args, mc.dateTagFormat(cStr)...)
			args = append(args, mc.renameStyle(cStr)...)
		} else { // Fallback to auto-preset detection
			args = preset.AutoPreset(model.URL)
		}
		args = append(args, "--meta-overwrite")

		if config.IsSet(keys.MoveOnComplete) {
			args = append(args, "--move-on-complete", config.GetString(keys.MoveOnComplete))
		}
		fileCommandMap[model.VideoFilename] = args
	}
	mc.Commands = fileCommandMap
	return nil
}

// dateTagFormat builds the date tag format to prefix filenames with
func (mc *MetarrCommand) dateTagFormat(c string) []string {
	var args []string
	if fDateTag := strings.Index(c, "[filename-date-tag]"); fDateTag != -1 {

		content := c[fDateTag+len("[filename-date-tag]")+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx-1]
		}
		lines := strings.Split(content, "\n")

		lines = mc.removeEmptyLines(lines)

		if len(lines) > 0 {
			args = append(args, "--filename-date-tag")
		}
		for i, line := range lines {
			if line == "" {
				continue
			}
			if i == 0 {
				switch line {
				case "Ymd", "ymd", "mdY", "mdy", "dmY", "dmy":
					args = append(args, line)
				default:
					logging.PrintE(0, "Date tag format entry syntax is incorrect, should be in a format such as Ymd (for yyyy-mm-dd) or ymd (for yy-mm-dd) and so on...")
					args = append(args, "")
				}
			}
		}
	}
	return args
}

// metaAddField builds the argument for insertion of a new metafield
func (mc *MetarrCommand) metaAddField(c string) []string {
	var args []string
	if mAddField := strings.Index(c, "[meta-add-field]"); mAddField != -1 {

		content := c[mAddField+len("[meta-add-field]")+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx-1]
		}
		lines := strings.Split(content, "\n")

		lines = mc.removeEmptyLines(lines)

		for i, line := range lines {
			if line == "" {
				continue
			}
			entry := strings.SplitN(line, ":", 2)
			if len(entry) != 2 {
				logging.PrintE(0, "Error in meta-add-field entry, please use syntax 'metatag:value'")
			} else {
				if i == 0 {
					args = append(args, "--meta-add-field")
				}
				args = append(args, line)
			}
		}
	}
	return args
}

// filenameReplaceSuffix builds the metadata suffix replacement argument for Metarr
func (mc *MetarrCommand) filenameReplaceSuffix(c string) []string {
	var args []string
	if fReplaceSfxIdx := strings.Index(c, "[filename-replace-suffix]"); fReplaceSfxIdx != -1 {

		content := c[fReplaceSfxIdx+len("[filename-replace-suffix]")+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx-1]
		}
		lines := strings.Split(content, "\n")

		lines = mc.removeEmptyLines(lines)

		for i, line := range lines {
			if line == "" {
				continue
			}
			entry := strings.SplitN(line, ":", 2)
			if len(entry) != 2 {
				logging.PrintE(0, "Error in filename-replace-suffix entry, please use syntax 'suffix:replacement'")
			} else {
				if i == 0 {
					args = append(args, "--filename-replace-suffix")
				}
				switch {
				case i < len(lines)-1:
					args = append(args, line)
				default:
					args = append(args, line)
				}
			}
		}
	}
	return args
}

// metaReplaceSuffix builds the metadata suffix replacement argument for Metarr
func (mc *MetarrCommand) metaReplaceSuffix(c string) []string {
	var args []string
	if mReplaceSfxIdx := strings.Index(c, "[meta-replace-suffix]"); mReplaceSfxIdx != -1 {

		content := c[mReplaceSfxIdx+len("[meta-replace-suffix]")+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx-1]
		}
		lines := strings.Split(content, "\n")

		lines = mc.removeEmptyLines(lines)

		for i, line := range lines {
			if line == "" {
				continue
			}
			entry := strings.SplitN(line, ":", 3)
			if len(entry) != 3 {
				logging.PrintE(0, "Error in meta-replace-suffix entry, please use syntax 'metatag:suffix:replacement'")
			} else {
				if i == 0 {
					args = append(args, "--meta-replace-suffix")
				}
				switch {
				case i < len(lines)-1:
					args = append(args, line)
				default:
					args = append(args, line)
				}
			}
		}
	}
	return args
}

// metaReplacePrefix builds the metadata suffix replacement argument for Metarr
func (mc *MetarrCommand) metaReplacePrefix(c string) []string {
	var args []string
	if mReplacePfxIdx := strings.Index(c, "[meta-replace-prefix]"); mReplacePfxIdx != -1 {

		content := c[mReplacePfxIdx+len("[meta-replace-prefix]")+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx-1]
		}
		lines := strings.Split(content, "\n")

		lines = mc.removeEmptyLines(lines)

		for i, line := range lines {
			if line == "" {
				continue
			}
			entry := strings.SplitN(line, ":", 3)
			if len(entry) != 3 {
				logging.PrintE(0, "Error in meta-replace-suffix entry, please use syntax 'metatag:prefix:replacement'")
			} else {
				if i == 0 {
					args = append(args, "--meta-replace-prefix")
				}
				switch {
				case i < len(lines)-1:
					args = append(args, line)
				default:
					args = append(args, line)
				}
			}
		}
	}
	return args
}

// renameStyle is the chosen style of renaming, e.g. spaces, underscores
func (mc *MetarrCommand) renameStyle(c string) []string {
	var args []string
	if rStyle := strings.Index(c, "[rename-style]"); rStyle != -1 {

		content := c[rStyle+len("[rename-style]")+1:]

		endIdx := strings.Index(content, "[")
		if endIdx != -1 {
			content = content[:endIdx-1]
		}
		lines := strings.Split(content, "\n")

		lines = mc.removeEmptyLines(lines)

		if len(lines) > 0 {
			args = append(args, "-r")
		}
		for i, line := range lines {
			if line == "" {
				continue
			}
			if i == 0 {
				switch line {
				case "spaces", "underscores", "skip":
					args = append(args, line)
				default:
					logging.PrintE(0, "Rename style entry syntax is incorrect, should be spaces, underscores, or skip.")
					args = append(args, "skip")
				}
			}
		}
	}
	return args
}

// removeEmptyLines strips empty lines from the result
func (mc *MetarrCommand) removeEmptyLines(lines []string) []string {
	var rtn []string
	for _, line := range lines {
		if line == "" || line == "\n" {
			continue
		}
		rtn = append(rtn, line)
	}
	switch {
	case len(rtn) > 0:
		return rtn
	default:
		rtn = append(rtn, "")
		return rtn
	}
}
package command

import (
	builder "Tubarr/internal/command/builder"
	"Tubarr/internal/config"
	keys "Tubarr/internal/domain/keys"
	"Tubarr/internal/models"
	utils "Tubarr/internal/utils/fs/write"
	logging "Tubarr/internal/utils/logging"
	"bufio"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
)

var (
	muDl sync.Mutex
)

// DownloadVideos takes in a list of URLs
func DownloadVideos(urls []string) ([]*models.DownloadedFiles, error) {
	muDl.Lock()
	defer muDl.Unlock()

	cookieSource := config.GetString(keys.CookieSource)
	if len(urls) == 0 {
		return nil, nil
	}

	vDir := config.GetString(keys.VideoDir)
	eDl := config.GetString(keys.ExternalDownloader)
	eDlArgs := config.GetString(keys.ExternalDownloaderArgs)

	var dlFiles []*models.DownloadedFiles
	var successfulURLs []string

	for _, entry := range urls {
		if entry == "" {
			continue
		}

		dlFile := models.DownloadedFiles{
			CookieSource:     cookieSource,
			ExternalDler:     eDl,
			ExternalDlerArgs: eDlArgs,
			URL:              entry,
			VideoDirectory:   vDir,
		}

		vcb := builder.NewVideoDLCommandBuilder(&dlFile)
		cmd, err := vcb.VideoFetchCommand()
		if err != nil {
			logging.PrintE(0, "Failed to build command for URL '%s': %v", dlFile.URL, err)
		}

		// Create pipes for stdout and stderr
		stdout, err := cmd.StdoutPipe()
		if err != nil {
			logging.PrintE(0, "Failed to create stdout pipe: %v", err)
			continue
		}
		stderr, err := cmd.StderrPipe()
		if err != nil {
			logging.PrintE(0, "Failed to create stderr pipe: %v", err)
			continue
		}

		// Start command
		logging.PrintI("Executing download command: %s", cmd.String())
		if err := cmd.Start(); err != nil {
			logging.PrintE(0, "Failed to start download: %v", err)
			continue
		}

		// Create output scanner
		scanner := bufio.NewScanner(io.MultiReader(stdout, stderr))
		var outputFilename string

		// Read output in real-time
		go func() {
			for scanner.Scan() {
				line := scanner.Text()
				fmt.Println(line)

				// Capture the actual output filename
				if strings.HasPrefix(line, "/") {
					switch {
					case strings.HasSuffix(line, ".3gp"),
						strings.HasSuffix(line, ".avi"),
						strings.HasSuffix(line, ".f4v"),
						strings.HasSuffix(line, ".flv"),
						strings.HasSuffix(line, ".m4v"),
						strings.HasSuffix(line, ".mkv"),
						strings.HasSuffix(line, ".mov"),
						strings.HasSuffix(line, ".mp4"),
						strings.HasSuffix(line, ".mpeg"),
						strings.HasSuffix(line, ".mpg"),
						strings.HasSuffix(line, ".ogm"),
						strings.HasSuffix(line, ".ogv"),
						strings.HasSuffix(line, ".ts"),
						strings.HasSuffix(line, ".vob"),
						strings.HasSuffix(line, ".webm"),
						strings.HasSuffix(line, ".wmv"):

						outputFilename = line

					default:
						logging.PrintD(1, "Did not find yt-dlp supported video format in output %s", line)
					}
				}
			}
		}()

		// Wait for command to complete...
		if err := cmd.Wait(); err != nil {
			logging.PrintE(0, "Download failed: %v", err)
			continue
		}

		// Short wait time for filesystem sync
		time.Sleep(1 * time.Second)

		if outputFilename == "" {
			logging.PrintE(0, "No output filename captured for URL: %s", entry)
			continue
		}

		dlFile.VideoFilename = outputFilename
		baseName := strings.TrimSuffix(filepath.Base(outputFilename), filepath.Ext(outputFilename))
		dlFile.JSONFilename = filepath.Join(vDir, baseName+".info.json")

		// Verify the download
		if err := verifyDownload(dlFile.VideoFilename, dlFile.JSONFilename); err != nil {
			logging.PrintE(0, "Download verification failed: %v", err)
			continue
		}

		logging.PrintS(0, "Successfully downloaded files:\nVideo: %s\nJSON: %s",
			dlFile.VideoFilename, dlFile.JSONFilename)
		dlFiles = append(dlFiles, &dlFile)
		successfulURLs = append(successfulURLs, entry)
	}

	if len(dlFiles) == 0 {
		return nil, fmt.Errorf("no files successfully downloaded")
	}

	grabbedURLsPath := filepath.Join(vDir, "grabbed-urls.txt")
	if err := utils.AppendURLsToFile(grabbedURLsPath, successfulURLs); err != nil {
		logging.PrintE(0, "Failed to update grabbed-urls.txt: %v", err)
		// Don't return error because downloads were successful at least
	}

	return dlFiles, nil
}

// verifyDownload checks if the specified files exist and are non-empty
func verifyDownload(videoPath, jsonPath string) error {
	// Check video file
	videoInfo, err := os.Stat(videoPath)
	if err != nil {
		return fmt.Errorf("video file verification failed: %w", err)
	}
	if videoInfo.Size() == 0 {
		return fmt.Errorf("video file is empty: %s", videoPath)
	}

	// Check JSON file
	jsonInfo, err := os.Stat(jsonPath)
	if err != nil {
		return fmt.Errorf("JSON file verification failed: %w", err)
	}
	if jsonInfo.Size() == 0 {
		return fmt.Errorf("JSON file is empty: %s", jsonPath)
	}

	return nil
}
package command

import (
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"os"
	"os/exec"
)

// RunMetarr runs a Metarr command with a built argument list
func RunMetarr(commands []*exec.Cmd) error {
	if len(commands) == 0 {
		return fmt.Errorf("no commands passed in")
	}

	var err error = nil
	for _, command := range commands {
		if len(command.String()) == 0 {
			logging.PrintE(0, "Command string is empty? %s", command.String())
			continue
		}
		logging.PrintI("Running command: %s", command.String())

		command.Stderr = os.Stderr
		command.Stdout = os.Stdout
		command.Stdin = os.Stdin

		if err = command.Run(); err != nil {
			logging.PrintE(0, "Encountered error running command '%s': %w", command.String(), err)
		}
		if err := command.Wait(); err != nil {
			return err
		}
	}
	return err // Returns nil by default unless an error is grabbed
}
package config

import (
	"strings"

	"golang.org/x/text/cases"
	"golang.org/x/text/language"
)

// AutoPreset is the entrypoint for command presets
func AutoPreset(url string) []string {
	args := make([]string, 0)
	switch {
	case strings.Contains(url, "censored.tv"):
		return censoredTvPreset(args, url)
	default:
		return defaultArgs(args)
	}
}

// censoredTvPreset sets common presets for censored.tv links
func censoredTvPreset(args []string, url string) []string {

	// Titles come appended with " (1)"
	// Ids come appended with "-1"
	// Filenames come appended with " 1"

	splitUrl := strings.Split(url, "/")
	creator := ""

	for i, entry := range splitUrl {
		if !strings.HasSuffix(entry, ".com") {
			continue
		}
		if len(splitUrl) >= i+1 {
			creator = strings.ReplaceAll(splitUrl[i+1], "-", " ")
		}
	}

	if creator != "" { // Should ensure the segment directly after .com/ was grabbed

		titleCase := cases.Title(language.English)
		creator = titleCase.String(creator)

		switch strings.ToLower(creator) {
		case "atheism is unstoppable": // Special case for Atheism-is-Unstoppable
			creator = "Atheism-is-Unstoppable"
		}

		args = append(args, "--meta-add-field", "author:"+creator, "actor:"+creator, "publisher:"+creator)
	}

	args = append(args, "--filename-date-tag", "ymd")
	args = append(args, "--meta-replace-suffix", "title: (1):", "fulltitle: (1):", "id:-1:", "display_id:-1:")
	args = append(args, "-r", "spaces")
	args = append(args, "--filename-replace-suffix", " 1:")
	args = append(args, "--meta-overwrite")

	return args
}

// defaultArgs provides default Metarr arguments
func defaultArgs(args []string) []string {

	// Currently returns no arguments

	return args
}
package config

import (
	keys "Tubarr/internal/domain/keys"
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"os"
	"strings"

	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

var rootCmd = &cobra.Command{
	Use:   "metarr",
	Short: "Metarr is a video and metatagging tool",
	RunE: func(cmd *cobra.Command, args []string) error {
		if cmd.Flags().Lookup("help").Changed {
			return nil // Stop further execution if help is invoked
		}
		viper.Set("execute", true)
		return execute()
	},
}

// init sets the initial Viper settings
func init() {

	// Video directory
	rootCmd.PersistentFlags().StringP(keys.VideoDir, "v", ".", "Video directory")
	viper.BindPFlag(keys.VideoDir, rootCmd.PersistentFlags().Lookup(keys.VideoDir))

	// Metadata directory
	rootCmd.PersistentFlags().StringP(keys.MetaDir, "m", ".", "Metadata directory location")
	viper.BindPFlag(keys.MetaDir, rootCmd.PersistentFlags().Lookup(keys.MetaDir))

	// Channels to check
	rootCmd.PersistentFlags().StringP(keys.ChannelFile, "c", "", "File of channels to check for new videos")
	viper.BindPFlag(keys.ChannelFile, rootCmd.PersistentFlags().Lookup(keys.ChannelFile))

	// Cookie source
	rootCmd.PersistentFlags().String(keys.CookieSource, "", "Browser to grab cookies from for sites requiring authentication (e.g. firefox)")
	viper.BindPFlag(keys.CookieSource, rootCmd.PersistentFlags().Lookup(keys.CookieSource))

	// Metarr preset file
	rootCmd.PersistentFlags().String(keys.MetarrPreset, "", "Metarr preset file location")
	viper.BindPFlag(keys.MetarrPreset, rootCmd.PersistentFlags().Lookup(keys.MetarrPreset))

	rootCmd.PersistentFlags().String(keys.ExternalDownloader, "", "External downloader to use for yt-dlp (e.g. aria2c)")
	viper.BindPFlag(keys.ExternalDownloader, rootCmd.PersistentFlags().Lookup(keys.ExternalDownloader))

	rootCmd.PersistentFlags().String(keys.ExternalDownloaderArgs, "", "Arguments for external downloader (e.g. \"-x 16 -s 16\")")
	viper.BindPFlag(keys.ExternalDownloader, rootCmd.PersistentFlags().Lookup(keys.ExternalDownloader))

	rootCmd.PersistentFlags().String(keys.MoveOnComplete, "", "Move files to given directory on program completion")
	viper.BindPFlag(keys.MoveOnComplete, rootCmd.PersistentFlags().Lookup(keys.MoveOnComplete))

	rootCmd.PersistentFlags().IntP(keys.DebugLevel, "d", 0, "Set the logging level")
	viper.BindPFlag(keys.DebugLevel, rootCmd.PersistentFlags().Lookup(keys.DebugLevel))
}

// Execute is the primary initializer of Viper
func Execute() error {

	fmt.Println()

	err := rootCmd.Execute()
	if err != nil {
		logging.PrintE(0, "Failed to execute cobra")
		return err

	}
	return nil
}

// execute more thoroughly handles settings created in the Viper init
func execute() error {
	if metarrPreset := viper.GetString(keys.MetarrPreset); metarrPreset != "" {

		if info, err := os.Stat(metarrPreset); err != nil {
			return fmt.Errorf("metarr preset does not exist")
		} else {
			if info.IsDir() {
				return fmt.Errorf("metarr preset must be a file")
			}
		}
	}
	channelFile := GetString(keys.ChannelFile)

	cFile, err := os.OpenFile(channelFile, os.O_RDWR, 0644)
	if err != nil {
		logging.PrintE(0, "Failed to open file '%s'", channelFile)
	}
	defer cFile.Close()

	content, err := os.ReadFile(channelFile)
	if err != nil {
		logging.PrintE(0, "Unable to read file '%s'", channelFile)
	}
	channelsCheckNew := strings.Split(string(content), "\n")
	viper.Set(keys.ChannelCheckNew, channelsCheckNew)

	if IsSet(keys.CookieSource) {
		cookieSource := GetString(keys.CookieSource)

		switch cookieSource {
		case "brave", "chrome", "edge", "firefox", "opera", "safari", "vivaldi", "whale":
			logging.PrintI("Using %s for cookies", cookieSource)
		default:
			return fmt.Errorf("invalid cookie source set. yt-dlp supports firefox, chrome, vivaldi, opera, edge, and brave")
		}
	}

	dLevel := GetInt(keys.DebugLevel)
	switch {
	case dLevel <= 0:
		logging.Level = 0
	case dLevel >= 3:
		logging.Level = 3
	default:
		logging.Level = dLevel
	}

	return nil
}
package config

import (
	"github.com/spf13/viper"
)

// Set sets the value for the key in the override register. Set is case-insensitive for a key. Will be used instead of values obtained via flags, config file, ENV, default, or key/value store.
func Set(key string, value any) {

	viper.Set(key, value)
}

// Get can retrieve any value given the key to use. Get is case-insensitive for a key. Get has the behavior of returning the value associated with the first place from where it is set. Viper will check in the following order: override, flag, env, config file, key/value store, default
// Get returns an interface. For a specific value use one of the Get____ methods.
func Get(key string) any {
	return viper.Get(key)
}

// GetBool returns the value associated with the key as a boolean.
func GetBool(key string) bool {
	return viper.GetBool(key)
}

// GetInt returns the value associated with the key as an integer.
func GetInt(key string) int {
	return viper.GetInt(key)
}

// GetUint64 returns the value associated with the key as an unsigned integer.
func GetUint64(key string) uint64 {
	return viper.GetUint64(key)
}

// GetFloat64 returns the value associated with the key as a float64.
func GetFloat64(key string) float64 {
	return viper.GetFloat64(key)
}

// GetString returns the value associated with the key as a string.
func GetString(key string) string {
	return viper.GetString(key)
}

// GetStringSlice returns the value associated with the key as a slice of strings.
func GetStringSlice(key string) []string {
	return viper.GetStringSlice(key)
}

// IsSet checks to see if the key has been set in any of the data locations.
// IsSet is case-insensitive for a key.
func IsSet(key string) bool {
	return viper.IsSet(key)
}
package domain

import "fmt"

// Colors
const (
	ColorReset  = "\033[0m"
	ColorRed    = "\033[91m"
	ColorGreen  = "\033[92m"
	ColorYellow = "\033[93m"
	ColorBlue   = "\033[34m"
	ColorPurple = "\033[35m"
	ColorCyan   = "\033[96m"
	ColorWhite  = "\033[37m"
)

var RedError string = fmt.Sprintf("%v[ERROR] %v", ColorRed, ColorReset)
var YellowDebug string = fmt.Sprintf("%v[DEBUG] %v", ColorYellow, ColorReset)
var GreenSuccess string = fmt.Sprintf("%v[SUCCESS] %v", ColorGreen, ColorReset)
var BlueInfo string = fmt.Sprintf("%v[Info] %v", ColorCyan, ColorReset)
package domain

// File prefix and suffix
const (
	OldTag  = "_metarrbackup"
	TempTag = "tmp_"
)

// Webpage tags
var WebDateTags = []string{"release-date", "upload-date", "date", "date-text", "text-date"}
var WebDescriptionTags = []string{"description", "longdescription", "long-description", "summary", "synopsis", "check-for-urls"}
var WebCreditsTags = []string{"creator", "uploader", "uploaded-by", "uploaded_by"}
var WebTitleTags = []string{"video-title", "video-name"}
package domain

var ContractionsSpaced map[string]string = map[string]string{
	"ain t":     "aint",
	"can t":     "cant",
	"don t":     "dont",
	"didn t":    "didnt",
	"hasn t":    "hasnt",
	"haven t":   "havent",
	"won t":     "wont",
	"wouldn t":  "wouldnt",
	"shouldn t": "shouldnt",
	"couldn t":  "couldnt",
	"wasn t":    "wasnt",
	"weren t":   "werent",
	"let s":     "lets",
	"hadn t":    "hadnt",
	"who s":     "whos",
	"what s":    "whats",
	"when s":    "whens",
	"where s":   "wheres",
	"why s":     "whys",
	"how s":     "hows",
	"there s":   "theres",
	"that s":    "thats",
	"it d":      "itd",
	"she d":     "shed",
	"she s":     "shes",
	"he d":      "hed",
	"he s":      "hes",
	"it ll":     "itll",
	"should ve": "shouldve",
	"could ve":  "couldve",
	"would ve":  "wouldve",
}

var ContractionsUnderscored map[string]string = map[string]string{
	"ain_t":     "aint",
	"can_t":     "cant",
	"don_t":     "dont",
	"didn_t":    "didnt",
	"hasn_t":    "hasnt",
	"haven_t":   "havent",
	"won_t":     "wont",
	"wouldn_t":  "wouldnt",
	"shouldn_t": "shouldnt",
	"couldn_t":  "couldnt",
	"wasn_t":    "wasnt",
	"weren_t":   "werent",
	"let_s":     "lets",
	"hadn_t":    "hadnt",
	"who_s":     "whos",
	"what_s":    "whats",
	"when_s":    "whens",
	"where_s":   "wheres",
	"why_s":     "whys",
	"how_s":     "hows",
	"there_s":   "theres",
	"that_s":    "thats",
	"it_d":      "itd",
	"she_d":     "shed",
	"she_s":     "shes",
	"he_d":      "hed",
	"he_s":      "hes",
	"it_ll":     "itll",
	"should_ve": "shouldve",
	"could_ve":  "couldve",
	"would_ve":  "wouldve",
}
package domain

// AV copy
var (
	AVCodecCopy    = []string{"-codec", "copy"}
	VideoCodecCopy = []string{"-c:v", "copy"}
	AudioCodecCopy = []string{"-c:a", "copy"}
)

var (
	AudioToAAC          = []string{"-c:a", "aac"}
	VideoToH264Balanced = []string{"-c:v", "libx264", "-crf", "23", "-profile:v", "main"}
	AudioBitrate        = []string{"-b:a", "256k"}
)

var (
	PixelFmtYuv420p  = []string{"-pix_fmt", "yuv420p"}
	KeyframeBalanced = []string{"-g", "50", "-keyint_min", "30"}
)

var (
	OutputExt = []string{"-f", "mp4"}
)

var (
	NvidiaAccel = []string{"-hwaccel", "nvdec"}
	AMDAccel    = []string{"-hwaccel", "vulkan"}
	IntelAccel  = []string{"-hwaccel", "qsv"}
)
package domain

const (
	JActor     = "actor"
	JAuthor    = "author"
	JArtist    = "artist"
	JComposer  = "composer"
	JCreator   = "creator"
	JDirector  = "director"
	JPerformer = "performer"
	JProducer  = "producer"
	JPublisher = "publisher"
	JStudio    = "studio"
	JUploader  = "uploader"
	JWriter    = "writer"
)

const (
	JComment          = "comment"
	JDescription      = "description"
	JFallbackTitle    = "title"
	JLongDescription  = "longdescription"
	JLong_Description = "long_description"
	JSubtitle         = "subtitle"
	JSummary          = "summary"
	JSynopsis         = "synopsis"
	JTitle            = "fulltitle"
)

const (
	JCreationTime        = "creation_time"
	JDate                = "date"
	JFormattedDate       = "formatted_date"
	JOriginallyAvailable = "originally_available_at"
	JReleaseDate         = "release_date"
	JUploadDate          = "upload_date"
	JYear                = "year"
	JReleaseYear         = "release_year"
)

const (
	JDomain        = "domain"
	JReferer       = "referer"
	JURL           = "url"
	JWebpageDomain = "webpage_url_domain"
	JWebpageURL    = "webpage_url"
)
package domain

// Log file keys
const (
	LogFinished = "FINISHED: "
	LogError    = "ERROR: "
	LogFailure  = "FAILED: "
	LogSuccess  = "Success: "
	LogInfo     = "Info: "
	LogWarning  = "Warning: "
	LogBasic    = ""
)
package domain

const (
	// Core Descriptive Metadata
	NTitle         = "title"
	NOriginalTitle = "originaltitle"
	NSortTitle     = "sorttitle"
	NTagline       = "tagline"
	NDescription   = "description"
	NPlot          = "plot"
	NOutline       = "outline"
	NShowTitle     = "showtitle"
	NSubtitle      = "subtitle"

	// Cast and Crew Metadata
	NActors   = "actor"
	NDirector = "director"
	NWriter   = "writer"
	NComposer = "composer"
	NProducer = "producer"

	// Genre, Category, and Rating Metadata
	NGenre      = "genre"
	NMood       = "mood"
	NMPAA       = "mpaa"
	NVotes      = "votes"
	NRatingsURL = "ratingurl"

	// Date and Release Metadata
	NAired        = "aired"
	NPremiereDate = "premiered"
	NYear         = "year"

	// Episodic Metadata
	NSeason       = "season"
	NEpisode      = "episode"
	NEpisodeTitle = "episodetitle"

	// Technical Information
	NCountry   = "country"
	NLanguage  = "language"
	NRated     = "rated"
	NEncodedBy = "encodedby"
	NRuntime   = "runtime"
	NRating    = "rating"

	// Production Metadata
	NProductionCompany = "productioncompany"
	NStudio            = "studio"
	NCoverArtist       = "coverartist"
	NPublisher         = "publisher"
	NCompilation       = "compilation"

	// Artwork, Media Assets, and Related Links
	NThumb    = "thumb"
	NFanart   = "fanart"
	NTrailer  = "trailer"
	NCoverArt = "cover_art"

	// Sorting and Alternate Display Titles
	NShowSortTitle = "showsorttitle"

	// Miscellaneous
	NComment = "comment"
	NTop250  = "top250"
	NTrack   = "track"
	NAlbum   = "album"
	NLicence = "license"
	NRights  = "rights"
	NURL     = "url"
)
package domain

// Terminal keys
const (
	VideoDir               string = "video-dir"
	MetaDir                string = "metadata-dir"
	InputExts              string = "input-exts"
	InputPreset            string = "preset"
	MetarrPreset           string = "metarr-preset"
	ChannelFile            string = "check-channels"
	CookieSource           string = "cookie-source"
	ExternalDownloader     string = "external-downloader"
	ExternalDownloaderArgs string = "external-downloader-args"
	MoveOnComplete         string = "move-on-complete"
)

// Primary program
const (
	Context    string = "Context"
	WaitGroup  string = "WaitGroup"
	SingleFile string = "SingleFile"
)

const (
	ChannelCheckNew string = "CheckChannelsForNew"
)

// Filename edits
const (
	FileNaming string = "ytdlp-naming-style"
)

// Logging
var (
	DebugLevel string = "debug-level"
)
package models

import "os/exec"

type DownloadedFiles struct {
	CookieSource     string
	DownloadCommand  *exec.Cmd
	ExternalDler     string
	ExternalDlerArgs string
	JSONFilename     string
	URL              string
	VideoDirectory   string
	VideoFilename    string
}
package utils

import (
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"net/http"
	"net/url"
	"strings"

	"github.com/browserutils/kooky"
	_ "github.com/browserutils/kooky/browser/all"
)

// GetBrowserCookies sets cookies input by the user. Useful for getting URLs
// from websites which require authentication!
func GetBrowserCookies(url string) ([]*http.Cookie, error) {

	baseURL, err := extractBaseDomain(url)
	if err != nil {
		return nil, fmt.Errorf("failed to extract base domain: %v", err)
	}

	allCookies := []*http.Cookie{}
	attemptedBrowsers := make(map[string]bool)

	// Find all cookie stores
	allStores := kooky.FindAllCookieStores()
	for _, store := range allStores {
		browserName := store.Browser()
		logging.PrintD(2, "Attempting to read cookies from %s", browserName)
		attemptedBrowsers[browserName] = true

		cookies, err := store.ReadCookies(kooky.Valid, kooky.Domain(baseURL))
		if err != nil {
			logging.PrintD(2, "Failed to read cookies from %s: %v", browserName, err)
			continue
		}

		if len(cookies) > 0 {
			logging.PrintI("Successfully read %d cookies from %s for domain %s", len(cookies), browserName, baseURL)
			// Append to the Go http.Cookie structure
			for _, c := range cookies {
				allCookies = append(allCookies, &http.Cookie{
					Name:   c.Name,
					Value:  c.Value,
					Path:   c.Path,
					Domain: c.Domain,
					Secure: c.Secure,
				})
			}
		} else {
			logging.PrintD(2, "No cookies found for %s", browserName)
		}
	}

	// Log summary of attempted browsers
	logging.PrintI("Attempted to read cookies from the following browsers: %v", keysFromMap(attemptedBrowsers))

	if len(allCookies) == 0 {
		logging.PrintI("No cookies found for '%s', proceeding without cookies", url)
	} else {
		logging.PrintI("Found a total of %d cookies for '%s'", len(allCookies), url)
	}

	return allCookies, nil
}

// extractBaseDomain helper function to parse a domain as just it's base.
// Useful for the purpose of scraping for cookies.
func extractBaseDomain(urlString string) (string, error) {
	parsedURL, err := url.Parse(urlString)
	if err != nil {
		return "", err
	}

	parts := strings.Split(parsedURL.Hostname(), ".")
	if len(parts) > 2 {
		return strings.Join(parts[len(parts)-2:], "."), nil
	}
	return parsedURL.Hostname(), nil
}

// keysForMap helper function to get keys from a map
func keysFromMap(m map[string]bool) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}
package utils

import (
	"Tubarr/internal/config"
	keys "Tubarr/internal/domain/keys"
	logging "Tubarr/internal/utils/logging"
	"bufio"
	"fmt"
	"net/http"
	"os"
	"strings"

	"github.com/gocolly/colly"
)

// GetNewReleases checks a channel URL for URLs which have not yet been recorded as downloaded
func GetNewReleases() []string {
	// Use a map to ensure URL uniqueness
	uniqueURLs := make(map[string]struct{})
	urlsToCheck := config.GetStringSlice(keys.ChannelCheckNew)

	for _, url := range urlsToCheck {
		if url == "" {
			continue
		}
		if cookies, err := GetBrowserCookies(url); err != nil {
			logging.PrintE(0, "Could not get cookies (%v)", err)
		} else if urls, err := newEpisodeURLs(url, cookies); err != nil {
			logging.PrintE(0, "Could not grab new episode (%v)", err)
		} else {
			// Add to map to ensure uniqueness
			for _, newURL := range urls {
				uniqueURLs[newURL] = struct{}{}
			}
		}
	}

	// Convert map back to slice
	var newURLs []string
	for url := range uniqueURLs {
		newURLs = append(newURLs, url)
	}

	if len(newURLs) > 0 {
		logging.PrintI("Grabbed new episode URLs: %v", newURLs)
	} else {
		logging.PrintD(1, "No new URLs found...")
	}
	return newURLs
}

// newEpisodeURLs checks for new episode URLs that are not yet in grabbed-urls.txt
func newEpisodeURLs(targetURL string, cookies []*http.Cookie) ([]string, error) {
	c := colly.NewCollector()

	// Use a map for collecting URLs to ensure uniqueness during scraping
	uniqueEpisodeURLs := make(map[string]struct{})

	for _, cookie := range cookies {
		c.SetCookies(targetURL, []*http.Cookie{cookie})
	}
	// Video URL link pattern
	switch {
	case strings.Contains(targetURL, "bitchute.com"):
		logging.PrintI("Detected bitchute.com link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/video/") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})
	case strings.Contains(targetURL, "censored.tv"):
		logging.PrintI("Detected censored.tv link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/episode/") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})
	case strings.Contains(targetURL, "odysee.com"):
		logging.PrintI("Detected Odysee link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			parts := strings.Split(link, "/")
			if len(parts) > 1 {
				lastPart := parts[len(parts)-1]
				if strings.Contains(link, "@") && strings.Contains(link, lastPart+"/") {
					uniqueEpisodeURLs[link] = struct{}{}
				}
			}
		})
	case strings.Contains(targetURL, "rumble.com"):
		logging.PrintI("Detected Rumble link")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/v") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})
	default:
		logging.PrintI("Using default link detection")
		c.OnHTML("a[href]", func(e *colly.HTMLElement) {
			link := e.Request.AbsoluteURL(e.Attr("href"))
			if strings.Contains(link, "/watch") {
				uniqueEpisodeURLs[link] = struct{}{}
			}
		})
	}

	// Visit the target URL
	err := c.Visit(targetURL)
	if err != nil {
		return nil, fmt.Errorf("error visiting webpage (%s): %v", targetURL, err)
	}

	// Convert unique URLs map to slice
	var episodeURLs []string
	for url := range uniqueEpisodeURLs {
		episodeURLs = append(episodeURLs, url)
	}

	// Load existing URLs from grabbed-urls.txt
	existingURLs, err := loadGrabbedURLsFromFile("grabbed-urls.txt")
	if err != nil {
		return nil, fmt.Errorf("error reading grabbed URLs file: %v", err)
	}

	// Filter out URLs that are already in grabbed-urls.txt
	var newURLs []string
	for _, url := range episodeURLs {
		normalizedURL := normalizeURL(url)
		exists := false

		for existingURL := range existingURLs {
			if normalizeURL(existingURL) == normalizedURL {
				exists = true
				break
			}
		}
		if !exists {
			newURLs = append(newURLs, url)
		}
	}
	if len(newURLs) == 0 {
		logging.PrintI("No new videos at %s", targetURL)
		return nil, nil
	}
	return newURLs, nil
}

// loadGrabbedURLsFromFile reads URLs from a file and returns them as a map for quick lookup
func loadGrabbedURLsFromFile(filename string) (map[string]struct{}, error) {
	videoDir := config.GetString(keys.VideoDir)
	var filepath string

	switch strings.HasSuffix(videoDir, "/") {
	case false:
		filepath = videoDir + "/" + filename
	default:
		filepath = videoDir + filename
	}

	file, err := os.Open(filepath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	urlMap := make(map[string]struct{})
	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		url := scanner.Text()
		urlMap[url] = struct{}{}
	}

	if err := scanner.Err(); err != nil {
		return nil, err
	}

	return urlMap, nil
}

// normalizeURL standardizes URLs for comparison by removing protocol and any trailing slashes
func normalizeURL(inputURL string) string {
	// Remove http:// or https://
	cleanURL := strings.TrimPrefix(inputURL, "https://")
	cleanURL = strings.TrimPrefix(cleanURL, "http://")

	// Remove any trailing slash
	cleanURL = strings.TrimSuffix(cleanURL, "/")

	return cleanURL
}
package utils

import (
	consts "Tubarr/internal/domain/constants"
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
)

// BackupFile creates a backup copy of the original file before modifying it.
// helps save important data if the program fails in some way
func BackupFile(file *os.File) error {

	// Get the original filename
	originalFilePath := file.Name()

	backupFilePath := generateBackupFilename(originalFilePath)
	logging.PrintD(3, "Creating backup of file '%s' as '%s'", originalFilePath, backupFilePath)

	// Open the backup file for writing
	backupFile, err := os.Create(backupFilePath)
	if err != nil {
		return fmt.Errorf("failed to create backup file: %w", err)
	}
	defer backupFile.Close()

	// Seek to the beginning of the original file
	_, err = file.Seek(0, io.SeekStart)
	if err != nil {
		return fmt.Errorf("failed to seek to beginning of original file: %w", err)
	}

	// Copy the content of the original file to the backup file
	_, err = io.Copy(backupFile, file)
	if err != nil {
		return fmt.Errorf("failed to copy content to backup file: %w", err)
	}

	logging.PrintD(3, "Backup successfully created at '%s'", backupFilePath)
	return nil
}

// generateBackupFilename creates a backup filename by appending "_backup" to the original filename
func generateBackupFilename(originalFilePath string) string {
	ext := filepath.Ext(originalFilePath)
	base := strings.TrimSuffix(originalFilePath, ext)
	return fmt.Sprintf(base + consts.OldTag + ext)
}

// RenameToBackup renames the passed in file
func RenameToBackup(filename string) error {

	if filename == "" {
		logging.PrintE(0, "filename was passed in to backup empty")
	}

	backupName := generateBackupFilename(filename)

	if err := os.Rename(filename, backupName); err != nil {
		return fmt.Errorf("failed to backup filename '%s' to '%s'", filename, backupName)
	}
	return nil
}
package utils

import (
	logging "Tubarr/internal/utils/logging"
	"bufio"
	"fmt"
	"os"
	"path/filepath"
)

// appendURLsToFile appends new URLs to the specified file
func AppendURLsToFile(filename string, urls []string) error {
	if len(urls) == 0 {
		return nil
	}

	logging.PrintD(2, "Appending URLs to file %s: %v", filename, urls)

	// Ensure the directory exists
	dir := filepath.Dir(filename)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return fmt.Errorf("failed to create directory for %s: %w", filename, err)
	}

	file, err := os.OpenFile(filename, os.O_APPEND|os.O_WRONLY|os.O_CREATE, 0644)
	if err != nil {
		return fmt.Errorf("failed to open file %s: %w", filename, err)
	}
	defer file.Close()

	written := make(map[string]bool)

	// Load existing URLs from the file into the map
	existingFile, err := os.Open(filename)
	if err == nil {
		defer existingFile.Close()
		scanner := bufio.NewScanner(existingFile)
		for scanner.Scan() {
			written[scanner.Text()] = true
		}
		if err := scanner.Err(); err != nil {
			return fmt.Errorf("error reading existing URLs: %w", err)
		}
	}

	// Append only new URLs to the file
	writer := bufio.NewWriter(file)
	for _, url := range urls {
		if url != "" && !written[url] {
			if _, err := writer.WriteString(url + "\n"); err != nil {
				return fmt.Errorf("error writing URL to file: %w", err)
			}
			written[url] = true
		}
	}

	if err := writer.Flush(); err != nil {
		return fmt.Errorf("error flushing writer: %w", err)
	}

	return nil
}
package utils

import (
	consts "Tubarr/internal/domain/constants"
	keys "Tubarr/internal/domain/keys"
	"fmt"
	"path/filepath"
	"runtime"
	"sync"

	"github.com/spf13/viper"
)

var (
	Level int = -1 // Pre initialization
	muD   sync.Mutex
	muE   sync.Mutex
	muI   sync.Mutex
	muP   sync.Mutex
	muS   sync.Mutex
)

func PrintE(l int, format string, args ...interface{}) string {

	muE.Lock()
	defer muE.Unlock()
	var msg string

	_, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	tag := fmt.Sprintf("[File: %s : Line: %d] ", file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) {

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.RedError+format+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.RedError + format + tag + "\n")
		}
		fmt.Print(msg)

		Write(consts.LogError, msg, nil)
	}

	return msg
}

func PrintS(l int, format string, args ...interface{}) string {

	muS.Lock()
	defer muS.Unlock()
	var msg string

	_, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	tag := fmt.Sprintf("[File: %s : Line: %d] ", file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) {

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.GreenSuccess+format+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.GreenSuccess + format + tag + "\n")
		}
		fmt.Print(msg)

		Write(consts.LogSuccess, msg, nil)
	}

	return msg
}

func PrintD(l int, format string, args ...interface{}) string {

	muD.Lock()
	defer muD.Unlock()
	var msg string

	_, file, line, _ := runtime.Caller(1)
	file = filepath.Base(file)
	tag := fmt.Sprintf("[File: %s : Line: %d] ", file, line)

	if Level < 0 {
		Level = viper.GetInt(keys.DebugLevel)
	}
	if l <= viper.GetInt(keys.DebugLevel) && l != 0 { // Debug messages don't appear by default

		if len(args) != 0 && args != nil {
			msg = fmt.Sprintf(consts.YellowDebug+format+tag+"\n", args...)
		} else {
			msg = fmt.Sprintf(consts.YellowDebug + format + tag + "\n")
		}
		fmt.Print(msg)

		Write(consts.LogSuccess, msg, nil)
	}

	return msg
}

func PrintI(format string, args ...interface{}) string {

	muI.Lock()
	defer muI.Unlock()
	var msg string

	if len(args) != 0 && args != nil {
		msg = fmt.Sprintf(consts.BlueInfo+format+"\n", args...)
	} else {
		msg = fmt.Sprintf(consts.BlueInfo + format + "\n")
	}
	fmt.Print(msg)
	Write(consts.LogInfo, msg, nil)

	return msg
}

func Print(format string, args ...interface{}) string {

	muP.Lock()
	defer muP.Unlock()
	var msg string

	if len(args) != 0 && args != nil {
		msg = fmt.Sprintf(format+"\n", args...)
	} else {
		msg = fmt.Sprintf(format + "\n")
	}
	fmt.Print(msg)
	Write(consts.LogBasic, msg, nil)

	return msg
}
package utils

import (
	"fmt"
	"log"
	"os"
	"regexp"
	"sync"
	"time"
)

var ErrorArray []error
var Loggable bool = false
var Logger *log.Logger
var mu sync.Mutex

// Regular expression to match ANSI escape codes
var ansiEscape = regexp.MustCompile(`\x1b\[[0-9;]*m`)

// SetupLogging creates and/or opens the log file
func SetupLogging(logFile *os.File) error {

	Logger = log.New(logFile, "", log.LstdFlags)
	Loggable = true

	Logger.Printf(":\n=========== %v ===========\n\n", time.Now().Format(time.RFC1123Z))
	return nil
}

// Write writes error information to the log file
func Write(tag, infoMsg string, err error, args ...interface{}) {

	if Loggable {
		mu.Lock()
		defer mu.Unlock()

		var errMsg string
		var info string

		if err != nil {
			if tag == "" {
				errMsg = fmt.Sprintf(err.Error()+"\n", args...)
			} else {
				errMsg = fmt.Sprintf(tag+err.Error()+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(errMsg))

		} else if infoMsg != "" {
			if tag == "" {
				info = fmt.Sprintf(infoMsg+"\n", args...)
			} else {
				info = fmt.Sprintf(tag+infoMsg+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(info))
		}
	}
}

// WriteArray writes an array of error information to the log file
func WriteArray(tag string, infoMsg []string, err []error, args ...interface{}) {
	if Loggable {
		mu.Lock()
		defer mu.Unlock()

		var errMsg, info string

		if len(err) != 0 && err != nil {

			var errOut string

			for _, errValue := range err {
				errOut += errValue.Error()
			}

			if tag == "" {
				errMsg = fmt.Sprintf(errOut+"\n", args...)
			} else {
				errMsg = fmt.Sprintf(tag+errOut+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(errMsg))

		} else if len(infoMsg) != 0 && infoMsg != nil {

			var infoOut string

			for _, infoValue := range err {
				infoOut += infoValue.Error()
			}

			if tag == "" {
				info = fmt.Sprintf(infoOut+"\n", args...)
			} else {
				info = fmt.Sprintf(tag+infoOut+"\n", args...)
			}
			Logger.Print(stripAnsiCodes(info))
		}
	}
}

// stripAnsiCodes removes ANSI escape codes from a string
func stripAnsiCodes(input string) string {
	return ansiEscape.ReplaceAllString(input, "")
}
package utils

import (
	logging "Tubarr/internal/utils/logging"
	"bufio"
	"context"
	"fmt"
	"os"
	"strings"
)

var (
	userInputChan = make(chan string) // Channel for user input
	decisionMade  bool
)

// Initialize user input reader in a goroutine
func InitUserInputReader() {
	go func() {
		reader := bufio.NewReader(os.Stdin)
		for {
			input, _ := reader.ReadString('\n')
			userInputChan <- strings.TrimSpace(input)
		}
	}()
}

// PromptMetaReplace displays a prompt message and waits for valid user input.
// The option can be used to tell the program to overwrite all in the queue,
// preserve all in the queue, or move through value by value
func PromptMetaReplace(promptMsg, fileName string, overwriteAll, preserveAll *bool) (string, error) {

	logging.PrintD(3, "Entering PromptUser dialogue...")
	ctx := context.Background()

	if decisionMade {
		// If overwriteAll, return "Y" without waiting
		if *overwriteAll {

			logging.PrintD(3, "Overwrite all is set...")
			return "Y", nil
		} else if *preserveAll {

			logging.PrintD(3, "Preserve all is set...")
			return "N", nil
		}
	}

	fmt.Println()
	logging.PrintI(promptMsg)

	// Wait for user input
	select {
	case response := <-userInputChan:
		if response == "Y" {
			*overwriteAll = true
		}
		decisionMade = true
		return response, nil

	case <-ctx.Done():
		logging.PrintI("Operation canceled during input.")
		return "", fmt.Errorf("operation canceled")
	}
}
package main

import (
	build "Tubarr/internal/command/builder"
	execute "Tubarr/internal/command/execute"
	"Tubarr/internal/config"
	keys "Tubarr/internal/domain/keys"
	"Tubarr/internal/models"
	browser "Tubarr/internal/utils/browser"
	logging "Tubarr/internal/utils/logging"
	"fmt"
	"os"
	"strings"

	"github.com/spf13/viper"
)

// main is the program entrypoint (duh!)
func main() {
	if err := config.Execute(); err != nil {
		fmt.Fprintln(os.Stderr, err)
		fmt.Println()
		os.Exit(1)
	}

	if !viper.GetBool("execute") {
		fmt.Println()
		return // Exit early if not meant to execute
	}

	if config.IsSet(keys.VideoDir) {
		vDir := config.GetString(keys.VideoDir)
		if !strings.HasSuffix(vDir, "/") {
			vDir += "/"
		}

		// Create directory if it doesn't exist
		if err := os.MkdirAll(vDir, 0755); err != nil {
			logging.PrintE(0, "Failed to create directory structure: %v", err)
			os.Exit(1)
		}

		// Open file with create flag
		logFile, err := os.OpenFile(vDir+"tubarr-log.txt", os.O_RDWR|os.O_CREATE|os.O_APPEND, 0644)
		if err != nil {
			logging.PrintE(0, "Encountered an error opening/creating the log file: %v", err)
			os.Exit(1)
		}
		defer logFile.Close()

		if err := logging.SetupLogging(logFile); err != nil {
			logging.PrintE(0, "Encountered error setting up logging: %v", err)
			os.Exit(1)
		}
	} else {
		logging.Print("No video directory sent in. Skipping logging")
	}

	if err := process(); err != nil {
		logging.PrintE(0, err.Error())
		os.Exit(1)
	}
}

// process begins the main Tubarr program:
// Grabs and downloads new releases and
// sends to Metarr for post-processing
func process() error {

	var dlFiles []*models.DownloadedFiles
	var err error

	// Get new releases and download videos
	if config.IsSet(keys.ChannelCheckNew) {
		urls := browser.GetNewReleases()
		if len(urls) > 0 {
			logging.PrintD(2, "Got URLs: %v", urls)
		} else {
			logging.PrintI("No new URLs received from crawl, exiting...")
			os.Exit(0)
		}

		dlFiles, err = execute.DownloadVideos(urls)
		if err != nil {
			return fmt.Errorf("error downloading new videos: %w", err)
		}
	}
	// Send to Metarr for tagging (or conversion to desired format)
	mcb := build.NewMetarrCommandBuilder()
	if config.IsSet(keys.MetarrPreset) {
		if commands, err := mcb.MakeMetarrCommands(dlFiles); err != nil {
			return err
		} else if err := execute.RunMetarr(commands); err != nil {
			return err
		}
	}
	return nil
}
